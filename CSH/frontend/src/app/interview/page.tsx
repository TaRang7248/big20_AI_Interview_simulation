"use client";
import { useState, useEffect, useRef, useCallback, Suspense } from "react";
import { useRouter, useSearchParams } from "next/navigation";
import { useAuth } from "@/contexts/AuthContext";
import Header from "@/components/common/Header";
import EventToastContainer from "@/components/common/EventToast";
import InterviewReportCharts, { ReportData } from "@/components/report/InterviewReportCharts";
import { sessionApi, interviewApi, ttsApi, interventionApi, resumeApi, didApi } from "@/lib/api";
import { useToast } from "@/contexts/ToastContext";
import { Mic, MicOff, Camera, CameraOff, PhoneOff, SkipForward, Volume2, Loader2, FileText, Download, LayoutDashboard, AlertTriangle, Upload } from "lucide-react";

/* Web Speech API íƒ€ì… (ë¸Œë¼ìš°ì € ì „ìš©) */
type SpeechRecognitionType = typeof window extends { SpeechRecognition: infer T } ? T : unknown;
declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition;
    webkitSpeechRecognition: new () => SpeechRecognition;
  }
  interface SpeechRecognition extends EventTarget {
    lang: string; continuous: boolean; interimResults: boolean;
    start(): void; stop(): void; abort(): void;
    onresult: ((ev: SpeechRecognitionEvent) => void) | null;
    onerror: ((ev: Event) => void) | null;
    onend: (() => void) | null;
  }
  interface SpeechRecognitionEvent extends Event {
    readonly resultIndex: number;
    readonly results: SpeechRecognitionResultList;
  }
  interface SpeechRecognitionResultList { readonly length: number; item(index: number): SpeechRecognitionResult; [index: number]: SpeechRecognitionResult; }
  interface SpeechRecognitionResult { readonly length: number; readonly isFinal: boolean; item(index: number): SpeechRecognitionAlternative; [index: number]: SpeechRecognitionAlternative; }
  interface SpeechRecognitionAlternative { readonly transcript: string; readonly confidence: number; }
}

type Phase = "setup" | "interview" | "coding" | "whiteboard" | "report";
type Status = "ready" | "listening" | "speaking" | "processing";

// Next.js App Routerì—ì„œ useSearchParams ì‚¬ìš© ì‹œ Suspense boundary í•„ìš”
export default function InterviewPageWrapper() {
  return (
    <Suspense fallback={<div className="min-h-screen bg-[var(--bg-primary)] flex items-center justify-center"><div className="text-[var(--text-secondary)]">ë¡œë”© ì¤‘...</div></div>}>
      <InterviewPageInner />
    </Suspense>
  );
}

function InterviewPageInner() {
  const { user, token, loading } = useAuth();
  const { toast } = useToast();
  const router = useRouter();
  const searchParams = useSearchParams();
  // URL ì—ì„œ ê³µê³  ID ì¶”ì¶œ (ex: /interview?job_posting_id=3)
  const jobPostingId = searchParams.get("job_posting_id");

  // ìƒíƒœ
  const [phase, setPhase] = useState<Phase>("setup");
  const [status, setStatus] = useState<Status>("ready");
  const [sessionId, setSessionId] = useState("");
  const [messages, setMessages] = useState<{ role: "ai" | "user"; text: string }[]>([]);
  const [currentQuestion, setCurrentQuestion] = useState("");
  const [questionNum, setQuestionNum] = useState(0);
  const totalQuestions = 9;
  const [sttText, setSttText] = useState("");
  const [micEnabled, setMicEnabled] = useState(true);
  const [camEnabled, setCamEnabled] = useState(true);
  const [interviewStarted, setInterviewStarted] = useState(false);
  const [reportData, setReportData] = useState<ReportData | null>(null);
  const [reportLoading, setReportLoading] = useState(false);

  // ì´ë ¥ì„œ ë¯¸ì—…ë¡œë“œ ê²½ê³  ëª¨ë‹¬ ìƒíƒœ (UX ê°œì„ )
  const [showResumeWarning, setShowResumeWarning] = useState(false);
  const [resumeWarningMsg, setResumeWarningMsg] = useState("");
  const [pendingSessionId, setPendingSessionId] = useState("");
  const fileInputRef = useRef<HTMLInputElement>(null);
  const [resumeUploading, setResumeUploading] = useState(false);

  // Refs
  const videoRef = useRef<HTMLVideoElement>(null);           // setup ì¹´ë©”ë¼ í”„ë¦¬ë·°ìš©
  const interviewVideoRef = useRef<HTMLVideoElement>(null);  // interview í™”ë©´ ì‚¬ìš©ì ì˜ìƒìš©
  const streamRef = useRef<MediaStream | null>(null);
  const wsRef = useRef<WebSocket | null>(null);
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const chatEndRef = useRef<HTMLDivElement>(null);
  const interventionTimerRef = useRef<ReturnType<typeof setInterval> | null>(null);
  const pushEventRef = useRef<((raw: Record<string, unknown>) => void) | null>(null);

  // â”€â”€ D-ID AI ì•„ë°”íƒ€ ìƒíƒœ â”€â”€
  const [didAvailable, setDidAvailable] = useState(false);   // D-ID API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
  const [didConnected, setDidConnected] = useState(false);   // WebRTC ì—°ê²° ì™„ë£Œ ì—¬ë¶€
  const [didLoading, setDidLoading] = useState(false);       // D-ID ìŠ¤íŠ¸ë¦¼ ì—°ê²° ì§„í–‰ ì¤‘
  const avatarVideoRef = useRef<HTMLVideoElement>(null);     // D-ID ì•„ë°”íƒ€ ì˜ìƒ <video>
  const peerConnectionRef = useRef<RTCPeerConnection | null>(null); // WebRTC PC

  // ì¸ì¦ í™•ì¸ â€” loading ì™„ë£Œ í›„ì—ë§Œ ë¦¬ë‹¤ì´ë ‰íŠ¸ (sessionStorage ë³µì› ëŒ€ê¸°)
  useEffect(() => {
    if (!loading && !token) router.push("/");
  }, [loading, token, router]);

  // ë¦¬í¬íŠ¸ ë°ì´í„° ë¡œë“œ
  useEffect(() => {
    if (phase !== "report" || !sessionId) return;
    setReportLoading(true);
    interviewApi
      .getReport(sessionId)
      .then((data) => setReportData(data as ReportData))
      .catch((err) => console.error("ë¦¬í¬íŠ¸ ë¡œë“œ ì‹¤íŒ¨:", err))
      .finally(() => setReportLoading(false));
  }, [phase, sessionId]);

  // ì±„íŒ… ìë™ ìŠ¤í¬ë¡¤
  useEffect(() => { chatEndRef.current?.scrollIntoView({ behavior: "smooth" }); }, [messages]);

  // â”€â”€ D-ID ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ (ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ 1íšŒ) â”€â”€
  useEffect(() => {
    didApi.status()
      .then(res => {
        setDidAvailable(res.available);
        if (res.available) console.log("âœ… D-ID AI ì•„ë°”íƒ€ ì‚¬ìš© ê°€ëŠ¥");
      })
      .catch(() => setDidAvailable(false));
  }, []);

  // â”€â”€ setup í™”ë©´ ì¹´ë©”ë¼ í”„ë¦¬ë·° ìë™ ì´ˆê¸°í™” â”€â”€
  // phaseê°€ "setup"ì¼ ë•Œ ì¹´ë©”ë¼ë¥¼ ë°”ë¡œ ì¼œì„œ í”„ë¦¬ë·° ì˜ìƒì„ ë³´ì—¬ì¤Œ
  useEffect(() => {
    if (phase !== "setup" || !user) return;
    let cancelled = false;
    (async () => {
      try {
        // ì´ë¯¸ ìŠ¤íŠ¸ë¦¼ì´ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
        if (streamRef.current) {
          if (videoRef.current) videoRef.current.srcObject = streamRef.current;
          return;
        }
        const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        if (cancelled) { stream.getTracks().forEach(t => t.stop()); return; }
        streamRef.current = stream;
        if (videoRef.current) videoRef.current.srcObject = stream;
      } catch {
        // ê¶Œí•œ ê±°ë¶€ ë“± â€” setup í™”ë©´ì—ì„œëŠ” ì¡°ìš©íˆ ë¬´ì‹œ (ì‹œì‘ ë²„íŠ¼ í´ë¦­ ì‹œ ì¬ì‹œë„)
      }
    })();
    return () => { cancelled = true; };
  }, [phase, user]);

  // â”€â”€ interview í™”ë©´ ì „í™˜ ì‹œ ì‚¬ìš©ì ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì¬í• ë‹¹ â”€â”€
  // phaseê°€ "interview"ë¡œ ë°”ë€Œë©´ ìƒˆë¡œ ë§ˆìš´íŠ¸ëœ <video>ì— srcObjectë¥¼ ì—°ê²°
  // requestAnimationFrameìœ¼ë¡œ DOM ë§ˆìš´íŠ¸ ì™„ë£Œë¥¼ ë³´ì¥
  useEffect(() => {
    if (phase !== "interview" || !streamRef.current) return;
    const assignStream = () => {
      if (interviewVideoRef.current && streamRef.current) {
        interviewVideoRef.current.srcObject = streamRef.current;
      } else {
        // refê°€ ì•„ì§ ì—°ê²°ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì¬ì‹œë„
        requestAnimationFrame(assignStream);
      }
    };
    requestAnimationFrame(assignStream);
  }, [phase]);

  // í´ë¦°ì—… (ì¹´ë©”ë¼, WebSocket, ìŒì„±ì¸ì‹, D-ID WebRTC)
  useEffect(() => {
    return () => {
      streamRef.current?.getTracks().forEach(t => t.stop());
      wsRef.current?.close();
      recognitionRef.current?.stop();
      if (interventionTimerRef.current) clearInterval(interventionTimerRef.current);
      // D-ID ì •ë¦¬
      peerConnectionRef.current?.close();
      peerConnectionRef.current = null;
    };
  }, []);

  /**
   * D-ID WebRTC ì•„ë°”íƒ€ ìŠ¤íŠ¸ë¦¼ ì—°ê²°
   * â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
   * 1. /api/did/stream/create â†’ SDP Offer + ICE ì„œë²„ ì •ë³´ ìˆ˜ì‹ 
   * 2. RTCPeerConnection ìƒì„± â†’ Remote Description ì„¤ì •
   * 3. SDP Answer ìƒì„± â†’ /api/did/stream/sdp ì „ì†¡
   * 4. ICE Candidate â†’ /api/did/stream/ice ì „ì†¡
   * 5. ontrack ì´ë²¤íŠ¸ë¡œ ìˆ˜ì‹ í•œ ë¹„ë””ì˜¤ë¥¼ avatarVideoRefì— ì—°ê²°
   */
  const initDIDAvatar = async (sid: string) => {
    if (!didAvailable) return;
    setDidLoading(true);
    try {
      // 1ë‹¨ê³„: ìŠ¤íŠ¸ë¦¼ ìƒì„± ìš”ì²­
      const streamRes = await didApi.createStream(sid);
      if (!streamRes.success || !streamRes.offer) {
        console.warn("D-ID ìŠ¤íŠ¸ë¦¼ ìƒì„± ì‹¤íŒ¨:", streamRes);
        return;
      }

      // 2ë‹¨ê³„: RTCPeerConnection ìƒì„±
      const pc = new RTCPeerConnection({
        iceServers: streamRes.ice_servers || [{ urls: "stun:stun.l.google.com:19302" }],
      });
      peerConnectionRef.current = pc;

      // ìˆ˜ì‹  íŠ¸ë™ ì²˜ë¦¬ â†’ ì•„ë°”íƒ€ ë¹„ë””ì˜¤ì— ì—°ê²°
      pc.ontrack = (event) => {
        if (event.streams?.[0] && avatarVideoRef.current) {
          avatarVideoRef.current.srcObject = event.streams[0];
          setDidConnected(true);
          console.log("âœ… D-ID ì•„ë°”íƒ€ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—°ê²°ë¨");
        }
      };

      // ICE Candidate ìˆ˜ì§‘ â†’ ì„œë²„ë¡œ ì „ì†¡
      pc.onicecandidate = (event) => {
        if (event.candidate) {
          didApi.sendIceCandidate(sid, event.candidate.toJSON()).catch(() => {});
        }
      };

      pc.onconnectionstatechange = () => {
        console.log(`[D-ID WebRTC] ì—°ê²° ìƒíƒœ: ${pc.connectionState}`);
        if (pc.connectionState === "disconnected" || pc.connectionState === "failed") {
          setDidConnected(false);
        }
      };

      // 3ë‹¨ê³„: Remote SDP Offer ì„¤ì • â†’ Local SDP Answer ìƒì„±
      await pc.setRemoteDescription(new RTCSessionDescription(streamRes.offer));
      const answer = await pc.createAnswer();
      await pc.setLocalDescription(answer);

      // 4ë‹¨ê³„: SDP Answerë¥¼ D-ID ì„œë²„ì— ì „ì†¡
      await didApi.sendSdpAnswer(sid, answer);

      // 5ë‹¨ê³„: ìŠ¤íŠ¸ë¦¼ ì‹œì‘
      await didApi.startStream(sid);
      console.log("âœ… D-ID ì•„ë°”íƒ€ ìŠ¤íŠ¸ë¦¼ ì‹œì‘");
    } catch (err) {
      console.error("D-ID ì•„ë°”íƒ€ ì´ˆê¸°í™” ì‹¤íŒ¨:", err);
      // D-ID ì‹¤íŒ¨í•´ë„ ë©´ì ‘ì€ ê³„ì† ì§„í–‰ (CSS í´ë°± ì•„ë°”íƒ€ ì‚¬ìš©)
    } finally {
      setDidLoading(false);
    }
  };

  // ========== ë©´ì ‘ ì‹œì‘ ==========
  const startInterview = async () => {
    if (!user) return;
    try {
      // ì¹´ë©”ë¼ ì´ˆê¸°í™” â€” setup useEffectì—ì„œ ì´ë¯¸ ìŠ¤íŠ¸ë¦¼ì´ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
      if (!streamRef.current) {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        streamRef.current = stream;
      }

      // ì„¸ì…˜ ìƒì„± (ê³µê³  IDê°€ ìˆìœ¼ë©´ í•¨ê»˜ ì „ë‹¬)
      const createData: { user_email: string; interview_type: string; job_posting_id?: number } = {
        user_email: user.email,
        interview_type: "technical",
      };
      if (jobPostingId) {
        createData.job_posting_id = Number(jobPostingId);
      }
      const res = await sessionApi.create(createData);
      setSessionId(res.session_id);

      // ì´ë ¥ì„œ ë¯¸ì—…ë¡œë“œ ì‹œ ê²½ê³  ëª¨ë‹¬ í‘œì‹œ (UX ê°œì„ )
      if (!res.resume_uploaded && res.resume_warning) {
        setPendingSessionId(res.session_id);
        setResumeWarningMsg(res.resume_warning);
        setShowResumeWarning(true);
        return; // ê²½ê³  ëª¨ë‹¬ì—ì„œ ì„ íƒ í›„ ë©´ì ‘ ì§„í–‰
      }

      // ì´ë ¥ì„œê°€ ì´ë¯¸ ì—…ë¡œë“œëœ ê²½ìš° ë°”ë¡œ ë©´ì ‘ ì§„í–‰
      await proceedInterview(res.session_id);
    } catch (err) {
      console.error("ë©´ì ‘ ì‹œì‘ ì‹¤íŒ¨:", err);
      toast.error("ë©´ì ‘ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¹´ë©”ë¼/ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
    }
  };

  /**
   * ë©´ì ‘ ì„¸ì…˜ ì§„í–‰ (WebSocket ì—°ê²° â†’ ìŒì„±ì¸ì‹ â†’ ì²« ì§ˆë¬¸)
   * ì´ë ¥ì„œ ê²½ê³  ëª¨ë‹¬ì—ì„œ 'ì´ë ¥ì„œ ì—†ì´ ì§„í–‰' ë˜ëŠ” 'ì´ë ¥ì„œ ì—…ë¡œë“œ í›„ ì§„í–‰' ëª¨ë‘ ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
   */
  const proceedInterview = async (sid: string) => {
    try {
      // ì¹´ë©”ë¼ê°€ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° (ê²½ê³  ëª¨ë‹¬ì—ì„œ ì´ë ¥ì„œ ì—…ë¡œë“œ í›„ ì¬ì§„í–‰)
      if (!streamRef.current) {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        streamRef.current = stream;
      }

      // WebSocket ì—°ê²°
      const protocol = window.location.protocol === "https:" ? "wss:" : "ws:";
      const wsToken = sessionStorage.getItem("access_token");
      const ws = new WebSocket(`${protocol}//${window.location.host}/ws/interview/${sid}?token=${encodeURIComponent(wsToken || "")}`);
      ws.onmessage = (e) => {
        try {
          const data = JSON.parse(e.data);
          if (data.type === "stt_result" && data.is_final) {
            setSttText(prev => prev + " " + data.transcript);
          }
          if (data.type === "event" && pushEventRef.current) {
            pushEventRef.current(data);
          }
        } catch { /* ignore */ }
      };
      wsRef.current = ws;

      initSpeechRecognition();
      setPhase("interview");
      setInterviewStarted(true);
      setSessionId(sid);

      // D-ID ì•„ë°”íƒ€ ì´ˆê¸°í™” (ë¹„ë™ê¸° â€” ë©´ì ‘ ì§„í–‰ì„ ë¸”ë¡œí‚¹í•˜ì§€ ì•ŠìŒ)
      initDIDAvatar(sid);

      await getNextQuestion(sid, "[START]");
    } catch (err) {
      console.error("ë©´ì ‘ ì§„í–‰ ì‹¤íŒ¨:", err);
      toast.error("ë©´ì ‘ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
    }
  };

  /**
   * ì´ë ¥ì„œ ê²½ê³  ëª¨ë‹¬ì—ì„œ ì´ë ¥ì„œ ì—…ë¡œë“œ ì²˜ë¦¬
   */
  const handleResumeUploadInWarning = async (file: File) => {
    if (!file.name.toLowerCase().endsWith(".pdf")) {
      toast.error("PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.");
      return;
    }
    if (file.size > 10 * 1024 * 1024) {
      toast.error("íŒŒì¼ í¬ê¸°ëŠ” 10MB ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.");
      return;
    }
    setResumeUploading(true);
    try {
      await resumeApi.upload(file, pendingSessionId, user!.email);
      setShowResumeWarning(false);
      // ì´ë ¥ì„œ ì—…ë¡œë“œ ì™„ë£Œ í›„ ë©´ì ‘ ì§„í–‰
      await proceedInterview(pendingSessionId);
    } catch {
      toast.error("ì´ë ¥ì„œ ì—…ë¡œë“œ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
    } finally {
      setResumeUploading(false);
    }
  };

  /**
   * ì´ë ¥ì„œ ì—†ì´ ë©´ì ‘ ì§„í–‰
   */
  const proceedWithoutResume = async () => {
    setShowResumeWarning(false);
    await proceedInterview(pendingSessionId);
  };

  // ========== ìŒì„± ì¸ì‹ (Web Speech API) ==========
  const initSpeechRecognition = () => {
    const SR = window.webkitSpeechRecognition || window.SpeechRecognition;
    if (!SR) return;
    const recognition = new SR();
    recognition.lang = "ko-KR";
    recognition.continuous = true;
    recognition.interimResults = true;

    recognition.onresult = (e: SpeechRecognitionEvent) => {
      let final = "";
      for (let i = e.resultIndex; i < e.results.length; i++) {
        if (e.results[i].isFinal) final += e.results[i][0].transcript;
      }
      if (final) setSttText(prev => prev + " " + final);
    };

    recognition.onend = () => { if (interviewStarted && micEnabled) recognition.start(); };
    recognitionRef.current = recognition;
    recognition.start();
  };

  // ========== ì§ˆë¬¸ ìš”ì²­ ==========
  const getNextQuestion = async (sid: string, message: string) => {
    setStatus("processing");
    try {
      const res = await interviewApi.chat({ session_id: sid, message, mode: "interview" });
      const q = res.response;
      setCurrentQuestion(q);
      setQuestionNum(res.question_number || questionNum + 1);
      setMessages(prev => [...prev, { role: "ai", text: q }]);
      await speakQuestion(q);
      setStatus("listening");

      // ê°œì… ì²´í¬ ì‹œì‘
      startInterventionCheck(sid);
    } catch { setStatus("ready"); }
  };

  // ========== TTS ë°œí™” + D-ID ë¦½ì‹±í¬ ==========
  const speakQuestion = async (text: string) => {
    setStatus("speaking");

    // D-ID ì•„ë°”íƒ€ê°€ ì—°ê²°ëœ ê²½ìš°: D-ID ë¦½ì‹±í¬ë„ ë³‘ë ¬ë¡œ ìš”ì²­
    // (D-IDëŠ” ìì²´ TTSë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦½ì‹±í¬ ì˜ìƒì„ ìƒì„±)
    if (didConnected && sessionId) {
      didApi.speak(sessionId, text, "female").catch(err =>
        console.warn("D-ID speak ì‹¤íŒ¨ (ìŒì„±ì€ Hume TTSë¡œ ì¬ìƒ):", err)
      );
    }

    try {
      const blob = await ttsApi.speak(text, "professional");
      const url = URL.createObjectURL(blob);
      const audio = new Audio(url);
      await new Promise<void>((resolve) => {
        audio.onended = () => resolve();
        audio.onerror = () => resolve();
        audio.play().catch(() => resolve());
      });
      URL.revokeObjectURL(url);
    } catch {
      // TTS ì‹¤íŒ¨ ì‹œ Web Speech API í´ë°±
      try {
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = "ko-KR";
        speechSynthesis.speak(utterance);
      } catch { /* ignore */ }
    }
  };

  // ========== ê°œì… ì²´í¬ ==========
  const startInterventionCheck = (sid: string) => {
    if (interventionTimerRef.current) clearInterval(interventionTimerRef.current);
    interventionApi.startTurn(sid).catch(() => {});
    interventionTimerRef.current = setInterval(async () => {
      try {
        const res = await interventionApi.check(sid, sttText);
        if (res.should_intervene && res.message) {
          setMessages(prev => [...prev, { role: "ai", text: `ğŸ’¡ ${res.message}` }]);
          await speakQuestion(res.message);
        }
      } catch { /* ignore */ }
    }, 3000);
  };

  // ========== ë‹µë³€ ì œì¶œ ==========
  const submitAnswer = async () => {
    if (!sttText.trim()) return;
    const answer = sttText.trim();
    setSttText("");
    setMessages(prev => [...prev, { role: "user", text: answer }]);

    // ê°œì… íƒ€ì´ë¨¸ ì •ì§€
    if (interventionTimerRef.current) clearInterval(interventionTimerRef.current);
    interventionApi.endTurn(sessionId, answer).catch(() => {});

    // í‰ê°€
    setStatus("processing");
    try {
      await interviewApi.evaluate({
        session_id: sessionId,
        question: currentQuestion,
        answer,
        question_number: questionNum,
      });
    } catch { /* ignore */ }

    // ë‹¤ìŒ ì§ˆë¬¸ or ì¢…ë£Œ
    if (questionNum >= totalQuestions) {
      endInterview();
    } else {
      await getNextQuestion(sessionId, answer);
    }
  };

  // ========== ë©´ì ‘ ì¢…ë£Œ ==========
  const endInterview = async () => {
    setInterviewStarted(false);
    recognitionRef.current?.stop();
    if (interventionTimerRef.current) clearInterval(interventionTimerRef.current);

    // D-ID ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
    if (didConnected && sessionId) {
      didApi.closeStream(sessionId).catch(() => {});
      peerConnectionRef.current?.close();
      peerConnectionRef.current = null;
      setDidConnected(false);
    }

    setPhase("coding");
  };

  // ========== ë§ˆì´í¬/ì¹´ë©”ë¼ í† ê¸€ ==========
  const toggleMic = () => {
    const track = streamRef.current?.getAudioTracks()[0];
    if (track) { track.enabled = !track.enabled; setMicEnabled(track.enabled); }
  };
  const toggleCam = () => {
    const track = streamRef.current?.getVideoTracks()[0];
    if (track) { track.enabled = !track.enabled; setCamEnabled(track.enabled); }
  };

  if (!user) return null;

  // ========== ë Œë”ë§ ==========
  return (
    <div className="min-h-screen flex flex-col">
      <Header />
      {/* ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ì•Œë¦¼ (EventBus â†’ WebSocket) */}
      <EventToastContainer onPushEvent={(handler) => { pushEventRef.current = handler; }} />

      {/* ========== ì´ë ¥ì„œ ë¯¸ì—…ë¡œë“œ ê²½ê³  ëª¨ë‹¬ (UX ê°œì„ ) ========== */}
      {showResumeWarning && (
        <div className="fixed inset-0 z-50 flex items-center justify-center bg-black/60 backdrop-blur-sm">
          <div className="glass-card max-w-md w-full mx-4 p-6">
            {/* ê²½ê³  ì•„ì´ì½˜ + ì œëª© */}
            <div className="flex items-center gap-3 mb-4">
              <div className="w-12 h-12 rounded-full bg-[rgba(255,193,7,0.15)] flex items-center justify-center">
                <AlertTriangle size={24} className="text-[var(--warning)]" />
              </div>
              <h3 className="text-lg font-bold">ì´ë ¥ì„œê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤</h3>
            </div>

            {/* ê²½ê³  ë©”ì‹œì§€ */}
            <p className="text-sm text-[var(--text-secondary)] mb-2">
              {resumeWarningMsg}
            </p>
            <div className="bg-[rgba(255,193,7,0.08)] border border-[rgba(255,193,7,0.2)] rounded-xl p-3 mb-6">
              <p className="text-xs text-[var(--warning)]">
                ğŸ’¡ ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ì§€ì› ì§ë¬´Â·ê²½ë ¥ì— ë§ì¶˜ <strong>ë§ì¶¤í˜• ì§ˆë¬¸</strong>ì„ ë°›ì„ ìˆ˜ ìˆì–´ ë” íš¨ê³¼ì ì¸ ë©´ì ‘ ì—°ìŠµì´ ë©ë‹ˆë‹¤.
              </p>
            </div>

            {/* ì´ë ¥ì„œ ì—…ë¡œë“œ ì˜ì—­ */}
            <div
              className="border-2 border-dashed border-[rgba(0,217,255,0.3)] rounded-xl p-6 text-center cursor-pointer hover:border-[var(--cyan)] hover:bg-[rgba(0,217,255,0.03)] transition-all mb-4"
              onClick={() => fileInputRef.current?.click()}
            >
              {resumeUploading ? (
                <div className="flex flex-col items-center">
                  <Loader2 size={28} className="animate-spin text-[var(--cyan)] mb-2" />
                  <p className="text-sm text-[var(--text-secondary)]">ì—…ë¡œë“œ ì¤‘...</p>
                </div>
              ) : (
                <>
                  <Upload size={28} className="mx-auto mb-2 text-[var(--cyan)]" />
                  <p className="text-sm text-[var(--text-secondary)]">PDF ì´ë ¥ì„œë¥¼ í´ë¦­í•˜ì—¬ ì—…ë¡œë“œ</p>
                  <p className="text-xs text-[var(--text-secondary)] mt-1">ìµœëŒ€ 10MB</p>
                </>
              )}
            </div>
            <input
              ref={fileInputRef}
              type="file"
              accept=".pdf"
              hidden
              onChange={(e) => e.target.files?.[0] && handleResumeUploadInWarning(e.target.files[0])}
            />

            {/* ì•¡ì…˜ ë²„íŠ¼ */}
            <div className="flex gap-3">
              <button
                onClick={proceedWithoutResume}
                disabled={resumeUploading}
                className="flex-1 px-4 py-3 rounded-xl text-sm font-semibold border border-[rgba(255,255,255,0.15)] text-[var(--text-secondary)] hover:bg-[rgba(255,255,255,0.05)] transition disabled:opacity-40"
              >
                ì´ë ¥ì„œ ì—†ì´ ì§„í–‰
              </button>
              <button
                onClick={() => fileInputRef.current?.click()}
                disabled={resumeUploading}
                className="flex-1 btn-gradient px-4 py-3 rounded-xl text-sm font-semibold flex items-center justify-center gap-2 disabled:opacity-40"
              >
                <Upload size={16} /> ì´ë ¥ì„œ ì—…ë¡œë“œ
              </button>
            </div>
          </div>
        </div>
      )}

      {/* ë©´ì ‘ ì¤€ë¹„ í™”ë©´ */}
      {phase === "setup" && (
        <main className="flex-1 flex items-center justify-center p-6">
          <div className="glass-card max-w-lg w-full text-center">
            <h1 className="text-3xl font-bold gradient-text mb-4">AI ëª¨ì˜ë©´ì ‘</h1>
            <p className="text-[var(--text-secondary)] mb-8">
              ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ê°€ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸í•œ í›„<br />ë©´ì ‘ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.
            </p>
            <div className="rounded-xl overflow-hidden bg-black aspect-video mb-6">
              <video ref={videoRef} autoPlay muted playsInline className="w-full h-full object-cover" />
            </div>
            <button onClick={startInterview} className="btn-gradient text-lg px-12 py-4 rounded-2xl">
              ğŸ¤ ë©´ì ‘ ì‹œì‘
            </button>
          </div>
        </main>
      )}

      {/* ë©´ì ‘ ì§„í–‰ í™”ë©´ */}
      {phase === "interview" && (
        <main className="flex-1 flex flex-col p-4 max-w-[1400px] mx-auto w-full">
          {/* ìƒíƒœ ë°” */}
          <div className="flex items-center justify-between mb-4">
            <div className="flex items-center gap-3">
              <span className={`px-4 py-1.5 rounded-full text-sm font-semibold ${
                status === "ready" ? "bg-[rgba(0,255,136,0.2)] text-[var(--green)]" :
                status === "listening" ? "bg-[rgba(255,193,7,0.2)] text-[var(--warning)]" :
                status === "speaking" ? "bg-[rgba(0,217,255,0.2)] text-[var(--cyan)]" :
                "bg-[rgba(156,39,176,0.2)] text-purple-300"
              }`}>
                {status === "ready" && "ëŒ€ê¸°"}
                {status === "listening" && "ğŸ¤ ë“£ëŠ” ì¤‘..."}
                {status === "speaking" && "ğŸ”Š ë°œí™” ì¤‘..."}
                {status === "processing" && "â³ ì²˜ë¦¬ ì¤‘..."}
              </span>
              <span className="text-sm text-[var(--text-secondary)]">ì§ˆë¬¸ {questionNum}/{totalQuestions}</span>
            </div>
            <button onClick={endInterview} className="px-4 py-2 text-sm rounded-lg bg-[rgba(244,67,54,0.2)] text-[var(--danger)] border border-[rgba(244,67,54,0.3)] hover:bg-[rgba(244,67,54,0.3)] transition">
              ë©´ì ‘ ì¢…ë£Œ
            </button>
          </div>

          {/* ì§„í–‰ ë°” */}
          <div className="flex gap-1 mb-6">
            {Array.from({ length: totalQuestions }, (_, i) => (
              <div key={i} className={`h-1.5 flex-1 rounded-full transition-all ${
                i < questionNum ? "bg-gradient-to-r from-[var(--cyan)] to-[var(--green)]" :
                i === questionNum ? "bg-[var(--cyan)] animate-pulse" : "bg-[rgba(255,255,255,0.1)]"
              }`} />
            ))}
          </div>

          {/* 2ì—´ ë ˆì´ì•„ì›ƒ */}
          <div className="grid grid-cols-1 lg:grid-cols-2 gap-4 flex-1">
            {/* AI ë©´ì ‘ê´€ ì•„ë°”íƒ€ */}
            <div className="glass-card flex flex-col">
              <h3 className="text-sm font-semibold mb-3 flex items-center gap-2">
                <Volume2 size={16} className="text-[var(--cyan)]" /> AI ë©´ì ‘ê´€
                {/* D-ID ì—°ê²° ìƒíƒœ ë°°ì§€ */}
                {didLoading && <span className="text-xs text-[var(--warning)] animate-pulse">ì•„ë°”íƒ€ ì—°ê²° ì¤‘...</span>}
                {didConnected && <span className="text-xs text-[var(--green)]">â— LIVE</span>}
              </h3>
              <div className="flex-1 rounded-xl bg-gradient-to-br from-[#1e3a5f] to-[#0d2137] flex items-center justify-center min-h-[200px] relative overflow-hidden">

                {/* â•â• D-ID WebRTC ì•„ë°”íƒ€ ë¹„ë””ì˜¤ (ì—°ê²° ì„±ê³µ ì‹œ í‘œì‹œ) â•â• */}
                {didConnected && (
                  <video
                    ref={avatarVideoRef}
                    autoPlay
                    playsInline
                    className="absolute inset-0 w-full h-full object-cover rounded-xl"
                  />
                )}

                {/* â•â• CSS í´ë°± ì•„ë°”íƒ€ (D-ID ë¯¸ì—°ê²° ì‹œ í‘œì‹œ) â•â• */}
                {!didConnected && (
                  <>
                    {/* ë°œí™” ìƒíƒœ ë°°ê²½ íŒŒë™ íš¨ê³¼ */}
                    {status === "speaking" && (
                      <>
                        <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
                          <div className="w-64 h-64 rounded-full bg-[rgba(0,255,136,0.06)] animate-ping" style={{ animationDuration: "2s" }} />
                        </div>
                        <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
                          <div className="w-52 h-52 rounded-full bg-[rgba(0,217,255,0.08)] animate-ping" style={{ animationDuration: "2.5s" }} />
                        </div>
                      </>
                    )}
                    {/* ì²˜ë¦¬ ì¤‘ ë°°ê²½ íš¨ê³¼ */}
                    {status === "processing" && (
                      <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
                        <div className="w-56 h-56 rounded-full border-2 border-dashed border-[rgba(156,39,176,0.3)] animate-spin" style={{ animationDuration: "4s" }} />
                      </div>
                    )}
                    {/* D-ID ë¡œë”© ì¤‘ */}
                    {didLoading && (
                      <div className="absolute inset-0 flex flex-col items-center justify-center z-10">
                        <Loader2 size={40} className="text-[var(--cyan)] animate-spin mb-3" />
                        <span className="text-sm text-[var(--text-secondary)]">AI ì•„ë°”íƒ€ ì—°ê²° ì¤‘...</span>
                      </div>
                    )}
                    {/* ì•„ë°”íƒ€ ì›í˜• */}
                    {!didLoading && (
                      <div className={`relative w-48 h-48 rounded-full border-4 transition-all duration-500 ${
                        status === "speaking"
                          ? "border-[var(--green)] shadow-[0_0_40px_rgba(0,255,136,0.5)] scale-105"
                          : status === "processing"
                          ? "border-purple-400 shadow-[0_0_20px_rgba(156,39,176,0.3)]"
                          : status === "listening"
                          ? "border-[var(--warning)] shadow-[0_0_20px_rgba(255,193,7,0.3)]"
                          : "border-[var(--cyan)]"
                      } bg-gradient-to-br from-[#2a4a6b] to-[#1a3050] flex items-center justify-center`}>
                        {/* ë°œí™” ì¤‘ ì´í€„ë¼ì´ì € ë°” */}
                        {status === "speaking" ? (
                          <div className="flex items-end gap-1.5 h-16">
                            {[0, 1, 2, 3, 4].map(i => (
                              <div
                                key={i}
                                className="w-2.5 bg-gradient-to-t from-[var(--cyan)] to-[var(--green)] rounded-full"
                                style={{
                                  animation: `equalizer 0.8s ease-in-out ${i * 0.15}s infinite alternate`,
                                  height: `${20 + Math.random() * 30}px`,
                                }}
                              />
                            ))}
                          </div>
                        ) : status === "processing" ? (
                          <Loader2 size={48} className="text-purple-300 animate-spin" />
                        ) : (
                          <span className="text-6xl">ğŸ¤–</span>
                        )}
                      </div>
                    )}
                  </>
                )}

                {/* ìƒíƒœ ë¼ë²¨ (D-ID/í´ë°± ê³µí†µ) */}
                <span className={`absolute bottom-3 left-3 text-xs px-2 py-1 rounded font-medium z-20 ${
                  status === "speaking" ? "bg-[rgba(0,255,136,0.2)] text-[var(--green)]"
                    : status === "processing" ? "bg-[rgba(156,39,176,0.2)] text-purple-300"
                    : status === "listening" ? "bg-[rgba(255,193,7,0.2)] text-[var(--warning)]"
                    : "bg-black/60 text-white"
                }`}>
                  {status === "speaking" ? "ğŸ”Š ë‹µë³€ ì¤‘..."
                    : status === "processing" ? "â³ ìƒê° ì¤‘..."
                    : status === "listening" ? "ğŸ‘‚ ê²½ì²­ ì¤‘..."
                    : "AI ë©´ì ‘ê´€"}
                </span>
              </div>
            </div>

            {/* ì±„íŒ…/ë¹„ë””ì˜¤ */}
            <div className="glass-card flex flex-col">
              {/* ì‚¬ìš©ì ë¹„ë””ì˜¤ (ì‘ê²Œ) */}
              <div className="rounded-xl overflow-hidden bg-black h-32 mb-3 relative">
                <video ref={interviewVideoRef} autoPlay muted playsInline className="w-full h-full object-cover" />
                <span className="absolute bottom-2 right-2 text-xs bg-black/60 px-2 py-0.5 rounded text-white">
                  {camEnabled ? "ì¹´ë©”ë¼ ON" : "ì¹´ë©”ë¼ OFF"}
                </span>
              </div>

              {/* ì±„íŒ… ë¡œê·¸ */}
              <div className="flex-1 overflow-y-auto space-y-3 mb-3 min-h-[200px] max-h-[400px] pr-2">
                {messages.map((m, i) => (
                  <div key={i} className={`flex ${m.role === "user" ? "justify-end" : "justify-start"}`}>
                    <div className={`max-w-[85%] px-4 py-3 rounded-2xl text-sm leading-relaxed ${
                      m.role === "user"
                        ? "bg-gradient-to-r from-[rgba(0,217,255,0.15)] to-[rgba(0,255,136,0.1)] rounded-br-md"
                        : "bg-[rgba(255,255,255,0.06)] rounded-bl-md"
                    }`}>
                      {m.text}
                    </div>
                  </div>
                ))}
                <div ref={chatEndRef} />
              </div>

              {/* STT ì¸ì‹ í…ìŠ¤íŠ¸ */}
              {status === "listening" && (
                <div className="bg-[rgba(255,193,7,0.08)] border border-[rgba(255,193,7,0.2)] rounded-xl p-3 mb-3">
                  <p className="text-xs text-[var(--warning)] mb-1">ğŸ¤ ìŒì„± ì¸ì‹ ì¤‘...</p>
                  <p className="text-sm">{sttText || "ë§ì”€í•´ì£¼ì„¸ìš”..."}</p>
                </div>
              )}

              {/* ì»¨íŠ¸ë¡¤ */}
              <div className="flex items-center justify-center gap-4">
                <button onClick={toggleMic} className={`w-12 h-12 rounded-full flex items-center justify-center transition ${
                  micEnabled ? "bg-[rgba(0,255,136,0.2)] text-[var(--green)]" : "bg-[rgba(255,82,82,0.2)] text-[var(--danger)]"
                }`}>
                  {micEnabled ? <Mic size={20} /> : <MicOff size={20} />}
                </button>
                <button onClick={toggleCam} className={`w-12 h-12 rounded-full flex items-center justify-center transition ${
                  camEnabled ? "bg-[rgba(0,255,136,0.2)] text-[var(--green)]" : "bg-[rgba(255,82,82,0.2)] text-[var(--danger)]"
                }`}>
                  {camEnabled ? <Camera size={20} /> : <CameraOff size={20} />}
                </button>
                <button onClick={submitAnswer} disabled={!sttText.trim() || status !== "listening"}
                  className="btn-gradient !rounded-full w-12 h-12 flex items-center justify-center disabled:opacity-40">
                  <SkipForward size={20} />
                </button>
                <button onClick={endInterview} className="w-12 h-12 rounded-full bg-[rgba(244,67,54,0.8)] text-white flex items-center justify-center hover:bg-[rgba(244,67,54,1)] transition">
                  <PhoneOff size={20} />
                </button>
              </div>
            </div>
          </div>
        </main>
      )}

      {/* ì½”ë”© í…ŒìŠ¤íŠ¸ Phase */}
      {phase === "coding" && (
        <main className="flex-1 flex items-center justify-center p-6">
          <div className="glass-card max-w-lg text-center">
            <h2 className="text-2xl font-bold gradient-text mb-4">ğŸ’» ì½”ë”© í…ŒìŠ¤íŠ¸</h2>
            <p className="text-[var(--text-secondary)] mb-6">
              í™”ìƒ ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì½”ë”© í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?
            </p>
            <div className="flex gap-4 justify-center">
              <button onClick={() => router.push(`/coding?session=${sessionId}`)} className="btn-gradient px-8 py-3">
                ì½”ë”© í…ŒìŠ¤íŠ¸ ì‹œì‘
              </button>
              <button onClick={() => setPhase("whiteboard")} className="px-8 py-3 rounded-xl border border-[rgba(0,217,255,0.4)] text-[var(--cyan)] hover:bg-[rgba(0,217,255,0.1)] transition">
                ê±´ë„ˆë›°ê¸°
              </button>
            </div>
          </div>
        </main>
      )}

      {/* í™”ì´íŠ¸ë³´ë“œ Phase */}
      {phase === "whiteboard" && (
        <main className="flex-1 flex items-center justify-center p-6">
          <div className="glass-card max-w-lg text-center">
            <h2 className="text-2xl font-bold gradient-text mb-4">ğŸ¨ ì•„í‚¤í…ì²˜ ì„¤ê³„</h2>
            <p className="text-[var(--text-secondary)] mb-6">
              í™”ì´íŠ¸ë³´ë“œì— ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•´ë³´ì„¸ìš”.
            </p>
            <div className="flex gap-4 justify-center">
              <button onClick={() => router.push(`/whiteboard?session=${sessionId}`)} className="btn-gradient px-8 py-3">
                ì„¤ê³„ ì‹œì‘
              </button>
              <button onClick={() => setPhase("report")} className="px-8 py-3 rounded-xl border border-[rgba(0,217,255,0.4)] text-[var(--cyan)] hover:bg-[rgba(0,217,255,0.1)] transition">
                ê²°ê³¼ ë³´ê¸°
              </button>
            </div>
          </div>
        </main>
      )}

      {/* ë¦¬í¬íŠ¸ Phase */}
      {phase === "report" && (
        <main className="flex-1 overflow-y-auto p-6">
          <div className="max-w-5xl mx-auto space-y-6">
            {/* ë¡œë”© ìƒíƒœ */}
            {reportLoading && (
              <div className="flex flex-col items-center justify-center py-20">
                <Loader2 className="w-10 h-10 text-[var(--cyan)] animate-spin mb-4" />
                <p className="text-[var(--text-secondary)]">ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤â€¦</p>
              </div>
            )}

            {/* ì°¨íŠ¸ ë¦¬í¬íŠ¸ */}
            {!reportLoading && reportData && (
              <InterviewReportCharts report={reportData} />
            )}

            {/* ë°ì´í„° ì—†ì„ ë•Œ */}
            {!reportLoading && !reportData && (
              <div className="glass-card text-center py-12">
                <h2 className="text-2xl font-bold gradient-text mb-4">ğŸ“Š ë©´ì ‘ ì™„ë£Œ!</h2>
                <p className="text-[var(--text-secondary)]">ë¦¬í¬íŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>
              </div>
            )}

            {/* í•˜ë‹¨ ì•¡ì…˜ ë²„íŠ¼ */}
            <div className="flex gap-4 justify-center flex-wrap pb-8">
              <button
                onClick={() => window.open(`/api/report/${sessionId}`, "_blank")}
                className="flex items-center gap-2 px-6 py-3 rounded-xl bg-[rgba(0,217,255,0.15)] border border-[rgba(0,217,255,0.4)] text-[var(--cyan)] hover:bg-[rgba(0,217,255,0.25)] transition"
              >
                <FileText className="w-4 h-4" /> JSON ì›ë³¸
              </button>
              <button
                onClick={() => {
                  const tk = localStorage.getItem("token");
                  fetch(`/api/report/${sessionId}/pdf`, {
                    headers: { Authorization: `Bearer ${tk}` },
                  })
                    .then((res) => {
                      if (!res.ok) throw new Error("PDF ìƒì„± ì‹¤íŒ¨");
                      return res.blob();
                    })
                    .then((blob) => {
                      const url = URL.createObjectURL(blob);
                      const a = document.createElement("a");
                      a.href = url;
                      a.download = `interview_report_${sessionId?.slice(0, 8)}.pdf`;
                      a.click();
                      URL.revokeObjectURL(url);
                    })
                    .catch((err) => toast.error(err.message));
                }}
                className="flex items-center gap-2 btn-gradient px-6 py-3"
              >
                <Download className="w-4 h-4" /> PDF ë‹¤ìš´ë¡œë“œ
              </button>
              <button
                onClick={() => router.push("/dashboard")}
                className="flex items-center gap-2 px-6 py-3 rounded-xl border border-[rgba(0,217,255,0.4)] text-[var(--cyan)] hover:bg-[rgba(0,217,255,0.1)] transition"
              >
                <LayoutDashboard className="w-4 h-4" /> ëŒ€ì‹œë³´ë“œë¡œ
              </button>
            </div>
          </div>
        </main>
      )}
    </div>
  );
}
