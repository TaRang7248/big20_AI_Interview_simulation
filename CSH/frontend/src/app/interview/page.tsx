"use client";
import { useState, useEffect, useRef, useCallback, Suspense } from "react";
import { useRouter, useSearchParams } from "next/navigation";
import { useAuth } from "@/contexts/AuthContext";
import Header from "@/components/common/Header";
import EventToastContainer from "@/components/common/EventToast";
import InterviewReportCharts, { ReportData } from "@/components/report/InterviewReportCharts";
import { sessionApi, interviewApi, ttsApi, interventionApi, resumeApi } from "@/lib/api";
import { useToast } from "@/contexts/ToastContext";
import { Mic, MicOff, Camera, CameraOff, PhoneOff, SkipForward, Volume2, Loader2, FileText, Download, LayoutDashboard, AlertTriangle, Upload } from "lucide-react";

/* Web Speech API íƒ€ì… (ë¸Œë¼ìš°ì € ì „ìš©) */
type SpeechRecognitionType = typeof window extends { SpeechRecognition: infer T } ? T : unknown;
declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition;
    webkitSpeechRecognition: new () => SpeechRecognition;
  }
  interface SpeechRecognition extends EventTarget {
    lang: string; continuous: boolean; interimResults: boolean;
    start(): void; stop(): void; abort(): void;
    onresult: ((ev: SpeechRecognitionEvent) => void) | null;
    onerror: ((ev: Event) => void) | null;
    onend: (() => void) | null;
  }
  interface SpeechRecognitionEvent extends Event {
    readonly resultIndex: number;
    readonly results: SpeechRecognitionResultList;
  }
  interface SpeechRecognitionResultList { readonly length: number; item(index: number): SpeechRecognitionResult;[index: number]: SpeechRecognitionResult; }
  interface SpeechRecognitionResult { readonly length: number; readonly isFinal: boolean; item(index: number): SpeechRecognitionAlternative;[index: number]: SpeechRecognitionAlternative; }
  interface SpeechRecognitionAlternative { readonly transcript: string; readonly confidence: number; }
}

type Phase = "setup" | "interview" | "coding" | "whiteboard" | "report";
type Status = "ready" | "listening" | "speaking" | "processing";

// Next.js App Routerì—ì„œ useSearchParams ì‚¬ìš© ì‹œ Suspense boundary í•„ìš”
export default function InterviewPageWrapper() {
  return (
    <Suspense fallback={<div className="min-h-screen bg-[var(--bg-primary)] flex items-center justify-center"><div className="text-[var(--text-secondary)]">ë¡œë”© ì¤‘...</div></div>}>
      <InterviewPageInner />
    </Suspense>
  );
}

function InterviewPageInner() {
  const { user, token, loading, setActiveSession } = useAuth();
  const { toast } = useToast();
  const router = useRouter();
  const searchParams = useSearchParams();
  // URL ì—ì„œ ê³µê³  ID ì¶”ì¶œ (ex: /interview?job_posting_id=3)
  const jobPostingId = searchParams.get("job_posting_id");

  // ìƒíƒœ
  const [phase, setPhase] = useState<Phase>("setup");
  const [status, setStatus] = useState<Status>("ready");
  const [sessionId, setSessionId] = useState("");
  const [messages, setMessages] = useState<{ role: "ai" | "user"; text: string }[]>([]);
  const [currentQuestion, setCurrentQuestion] = useState("");
  const [questionNum, setQuestionNum] = useState(0);
  const totalQuestions = 5;
  const [sttText, setSttText] = useState("");
  const [manualInput, setManualInput] = useState("");  // STT ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ í…ìŠ¤íŠ¸ ì…ë ¥ (í´ë°±)
  const [sttAvailable, setSttAvailable] = useState(true); // Web Speech API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
  const [micEnabled, setMicEnabled] = useState(true);
  const [camEnabled, setCamEnabled] = useState(true);
  const [interviewStarted, setInterviewStarted] = useState(false);
  const [serverTtsEnabled, setServerTtsEnabled] = useState(true);
  const [reportData, setReportData] = useState<ReportData | null>(null);
  const [reportLoading, setReportLoading] = useState(false);

  // ì´ë ¥ì„œ ë¯¸ì—…ë¡œë“œ ê²½ê³  ëª¨ë‹¬ ìƒíƒœ (UX ê°œì„ )
  const [showResumeWarning, setShowResumeWarning] = useState(false);
  const [resumeWarningMsg, setResumeWarningMsg] = useState("");
  const [pendingSessionId, setPendingSessionId] = useState("");
  const fileInputRef = useRef<HTMLInputElement>(null);
  const [resumeUploading, setResumeUploading] = useState(false);

  // Refs
  const interviewVideoRef = useRef<HTMLVideoElement>(null);  // interview í™”ë©´ ì‚¬ìš©ì ì˜ìƒìš©
  const streamRef = useRef<MediaStream | null>(null);
  const wsRef = useRef<WebSocket | null>(null);
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const chatEndRef = useRef<HTMLDivElement>(null);
  const interventionTimerRef = useRef<ReturnType<typeof setInterval> | null>(null);
  const pushEventRef = useRef<((raw: Record<string, unknown>) => void) | null>(null);

  // WebSocket ì¬ì—°ê²° ì‹œë„ íšŸìˆ˜ â€” connectWebSocket ì¬ê·€ í˜¸ì¶œ ì‹œì—ë„ ëˆ„ì ë˜ì–´
  // ë¬´í•œ ì¬ì—°ê²° ë£¨í”„ë¥¼ ë°©ì§€ (ì´ì „: ë§¤ í˜¸ì¶œë§ˆë‹¤ 0ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ëŠ” ì§€ì—­ ë³€ìˆ˜ ì‚¬ìš©)
  const wsReconnectAttemptsRef = useRef(0);

  // SpeechRecognition ì½œë°±ì—ì„œ ìµœì‹  ìƒíƒœë¥¼ ì°¸ì¡°í•˜ê¸° ìœ„í•œ Ref
  // (í´ë¡œì € ìº¡ì²˜ ì‹œ stale value ë¬¸ì œ ë°©ì§€ â€” ì½œë°±ì€ ìµœì´ˆ ìƒì„± ì‹œì ì˜ state ê°’ë§Œ ë³´ìœ )
  const interviewStartedRef = useRef(false);
  const micEnabledRef = useRef(true);
  const sessionIdRef = useRef("");

  // state ë³€ê²½ ì‹œ refë„ ë™ê¸°í™” â€” ì½œë°±ì—ì„œ í•­ìƒ ìµœì‹  ê°’ ì°¸ì¡° ê°€ëŠ¥
  useEffect(() => { interviewStartedRef.current = interviewStarted; }, [interviewStarted]);
  useEffect(() => { micEnabledRef.current = micEnabled; }, [micEnabled]);
  useEffect(() => { sessionIdRef.current = sessionId; }, [sessionId]);

  // ì¸ì¦ í™•ì¸ â€” loading ì™„ë£Œ í›„ì—ë§Œ ë¦¬ë‹¤ì´ë ‰íŠ¸ (sessionStorage ë³µì› ëŒ€ê¸°)
  // ë©´ì ‘ ì§„í–‰ ì¤‘(interviewStartedRef)ì—ëŠ” í† í° ë§Œë£Œë¡œ ì¸í•œ ë¦¬ë‹¤ì´ë ‰íŠ¸ ë°©ì§€
  // â†’ AuthContextì˜ ìœ íœ´ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ tokenì´ nullì´ ë˜ì–´ë„ ë©´ì ‘ í™”ë©´ ìœ ì§€
  useEffect(() => {
    if (!loading && !token && !interviewStartedRef.current) router.push("/");
  }, [loading, token, router]);

  // ë¦¬í¬íŠ¸ ë°ì´í„° ë¡œë“œ
  useEffect(() => {
    if (phase !== "report" || !sessionId) return;
    setReportLoading(true);
    interviewApi
      .getReport(sessionId)
      .then((data) => setReportData(data as ReportData))
      .catch((err) => console.error("ë¦¬í¬íŠ¸ ë¡œë“œ ì‹¤íŒ¨:", err))
      .finally(() => setReportLoading(false));
  }, [phase, sessionId]);

  // ì±„íŒ… ìë™ ìŠ¤í¬ë¡¤
  useEffect(() => { chatEndRef.current?.scrollIntoView({ behavior: "smooth" }); }, [messages]);

  // â”€â”€ í˜ì´ì§€ ì§„ì… ì‹œ ìë™ìœ¼ë¡œ ë©´ì ‘ ì‹œì‘ (setup í™”ë©´ ìŠ¤í‚µ) â”€â”€
  // ì‚¬ìš©ì ì¸ì¦ ì™„ë£Œ í›„ ë°”ë¡œ startInterview()ë¥¼ í˜¸ì¶œí•˜ì—¬ ë©´ì ‘ì„ ì‹œì‘
  const autoStartedRef = useRef(false);
  useEffect(() => {
    if (phase !== "setup" || !user || autoStartedRef.current) return;
    autoStartedRef.current = true;
    startInterview();
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [phase, user]);

  // â”€â”€ interview í™”ë©´ ì „í™˜ ì‹œ ì‚¬ìš©ì ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì¬í• ë‹¹ â”€â”€
  // phaseê°€ "interview"ë¡œ ë°”ë€Œë©´ ìƒˆë¡œ ë§ˆìš´íŠ¸ëœ <video>ì— srcObjectë¥¼ ì—°ê²°
  // requestAnimationFrameìœ¼ë¡œ DOM ë§ˆìš´íŠ¸ ì™„ë£Œë¥¼ ë³´ì¥
  useEffect(() => {
    if (phase !== "interview" || !streamRef.current) return;
    const assignStream = () => {
      if (interviewVideoRef.current && streamRef.current) {
        interviewVideoRef.current.srcObject = streamRef.current;
      } else {
        // refê°€ ì•„ì§ ì—°ê²°ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì¬ì‹œë„
        requestAnimationFrame(assignStream);
      }
    };
    requestAnimationFrame(assignStream);
  }, [phase]);

  // ë©´ì ‘ ì¤‘ ìš°ë°œì  í˜ì´ì§€ ì´íƒˆ ë°©ì§€ (ë’¤ë¡œê°€ê¸°, ìƒˆë¡œê³ ì¹¨ ë“±)
  // beforeunload ì´ë²¤íŠ¸ë¡œ ì‚¬ìš©ìì—ê²Œ í™•ì¸ ëŒ€í™”ìƒìë¥¼ í‘œì‹œ
  useEffect(() => {
    if (!interviewStarted) return;
    const handleBeforeUnload = (e: BeforeUnloadEvent) => {
      e.preventDefault();
      // ìµœì‹  ë¸Œë¼ìš°ì €ì—ì„œëŠ” returnValue ì„¤ì •ë§Œìœ¼ë¡œ í™•ì¸ ëŒ€í™”ìƒì í‘œì‹œ
      e.returnValue = "ë©´ì ‘ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ë– ë‚˜ì‹œê² ìŠµë‹ˆê¹Œ?";
    };
    window.addEventListener("beforeunload", handleBeforeUnload);
    return () => window.removeEventListener("beforeunload", handleBeforeUnload);
  }, [interviewStarted]);

  // í´ë¦°ì—… (ì¹´ë©”ë¼, WebSocket, ìŒì„±ì¸ì‹)
  useEffect(() => {
    return () => {
      setActiveSession(false); // í˜ì´ì§€ ì´íƒˆ ì‹œ Auth ìœ íœ´ íƒ€ì„ì•„ì›ƒ ë³µì›
      streamRef.current?.getTracks().forEach(t => t.stop());
      wsRef.current?.close();
      recognitionRef.current?.stop();
      if (interventionTimerRef.current) clearInterval(interventionTimerRef.current);
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [setActiveSession]);

  // ========== ë©´ì ‘ ì‹œì‘ ==========
  const startInterview = async () => {
    if (!user) return;
    try {
      // ì¹´ë©”ë¼ ì´ˆê¸°í™” â€” setup useEffectì—ì„œ ì´ë¯¸ ìŠ¤íŠ¸ë¦¼ì´ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
      if (!streamRef.current) {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        streamRef.current = stream;
      }

      // ì„¸ì…˜ ìƒì„± (ê³µê³  IDê°€ ìˆìœ¼ë©´ í•¨ê»˜ ì „ë‹¬)
      const createData: { user_email: string; interview_type: string; job_posting_id?: number } = {
        user_email: user.email,
        interview_type: "technical",
      };
      if (jobPostingId) {
        createData.job_posting_id = Number(jobPostingId);
      }
      const res = await sessionApi.create(createData);
      setSessionId(res.session_id);

      // ì´ë ¥ì„œ ë¯¸ì—…ë¡œë“œ ì‹œ ê²½ê³  ëª¨ë‹¬ í‘œì‹œ (UX ê°œì„ )
      if (!res.resume_uploaded && res.resume_warning) {
        setPendingSessionId(res.session_id);
        setResumeWarningMsg(res.resume_warning);
        setShowResumeWarning(true);
        return; // ê²½ê³  ëª¨ë‹¬ì—ì„œ ì„ íƒ í›„ ë©´ì ‘ ì§„í–‰
      }

      // ì´ë ¥ì„œê°€ ì´ë¯¸ ì—…ë¡œë“œëœ ê²½ìš° ë°”ë¡œ ë©´ì ‘ ì§„í–‰
      await proceedInterview(res.session_id);
    } catch (err) {
      console.error("ë©´ì ‘ ì‹œì‘ ì‹¤íŒ¨:", err);
      toast.error("ë©´ì ‘ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¹´ë©”ë¼/ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
    }
  };

  /**
   * ë©´ì ‘ ì„¸ì…˜ ì§„í–‰ (WebSocket ì—°ê²° â†’ ìŒì„±ì¸ì‹ â†’ ì²« ì§ˆë¬¸)
   * ì´ë ¥ì„œ ê²½ê³  ëª¨ë‹¬ì—ì„œ 'ì´ë ¥ì„œ ì—†ì´ ì§„í–‰' ë˜ëŠ” 'ì´ë ¥ì„œ ì—…ë¡œë“œ í›„ ì§„í–‰' ëª¨ë‘ ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
   */
  const proceedInterview = async (sid: string) => {
    try {


      // ì¹´ë©”ë¼ê°€ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° (ê²½ê³  ëª¨ë‹¬ì—ì„œ ì´ë ¥ì„œ ì—…ë¡œë“œ í›„ ì¬ì§„í–‰)
      if (!streamRef.current) {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        streamRef.current = stream;
      }

      // WebSocket ì—°ê²° + ìë™ ì¬ì—°ê²° ë¡œì§
      // ë°±ì—”ë“œ(uvicorn --reload) ì¬ì‹œì‘ ì‹œ WebSocket ëŠê¹€ì´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
      // onclose/onerror í•¸ë“¤ëŸ¬ì—ì„œ ìë™ ì¬ì—°ê²°ì„ ì‹œë„í•˜ì—¬ ì„¸ì…˜ ì•ˆì •ì„± ë³´ì¥
      const connectWebSocket = (targetSid: string) => {
        // Next.js rewritesëŠ” WebSocket í”„ë¡œí† ì½œì„ í”„ë¡ì‹œí•˜ì§€ ëª»í•˜ë¯€ë¡œ,
        // WebSocketì€ FastAPI ë°±ì—”ë“œì— ì§ì ‘ ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤.
        // NEXT_PUBLIC_WS_URL í™˜ê²½ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ FastAPI ê¸°ë³¸ í¬íŠ¸(8000)ë¡œ ì—°ê²°
        const wsBaseUrl = process.env.NEXT_PUBLIC_WS_URL || null;
        const wsToken = sessionStorage.getItem("access_token");
        let wsUrl: string;
        if (wsBaseUrl) {
          // í™˜ê²½ë³€ìˆ˜ì— ì§€ì •ëœ WebSocket URL ì‚¬ìš© (ì˜ˆ: ws://localhost:8000)
          wsUrl = `${wsBaseUrl}/ws/interview/${targetSid}?token=${encodeURIComponent(wsToken || "")}`;
        } else {
          // ê¸°ë³¸ê°’: í˜„ì¬ í˜¸ìŠ¤íŠ¸ì˜ í¬íŠ¸ë¥¼ 8000ìœ¼ë¡œ êµì²´í•˜ì—¬ FastAPI ì§ì ‘ ì—°ê²°
          const protocol = window.location.protocol === "https:" ? "wss:" : "ws:";
          const host = window.location.hostname;
          wsUrl = `${protocol}//${host}:8000/ws/interview/${targetSid}?token=${encodeURIComponent(wsToken || "")}`;
        }
        const ws = new WebSocket(wsUrl);

        // WebSocket ì—°ê²° ì„±ê³µ ì‹œ ì¬ì—°ê²° ì¹´ìš´í„° ë¦¬ì…‹
        // â€” ì´ì „ ëŠê¹€ì—ì„œ ì •ìƒ ë³µêµ¬ëœ ê²ƒì´ë¯€ë¡œ ì¹´ìš´í„°ë¥¼ ì´ˆê¸°í™”
        ws.onopen = () => {
          wsReconnectAttemptsRef.current = 0;
        };

        ws.onmessage = (e) => {
          try {
            const data = JSON.parse(e.data);
            if (data.type === "stt_result" && data.is_final) {
              setSttText(prev => prev + " " + data.transcript);
            }
            if (data.type === "event" && pushEventRef.current) {
              pushEventRef.current(data);
            }
          } catch { /* ignore */ }
        };

        // WebSocket ëŠê¹€ ì‹œ ìë™ ì¬ì—°ê²° (ìµœëŒ€ 5íšŒ, ì§€ìˆ˜ ë°±ì˜¤í”„)
        // wsReconnectAttemptsRefë¥¼ ì‚¬ìš©í•˜ì—¬ connectWebSocket ì¬ê·€ í˜¸ì¶œ ì‹œì—ë„
        // ì¹´ìš´í„°ê°€ ëˆ„ì ë¨ â†’ ë¬´í•œ ì¬ì—°ê²° ë£¨í”„ ë°©ì§€
        const MAX_RECONNECT = 5;
        ws.onclose = (ev) => {
          // ì •ìƒ ì¢…ë£Œ(ì½”ë“œ 1000)ì´ê±°ë‚˜ ë©´ì ‘ ì¢…ë£Œ ìƒíƒœë©´ ì¬ì—°ê²°í•˜ì§€ ì•ŠìŒ
          if (ev.code === 1000 || !interviewStartedRef.current) return;
          console.warn(`[WebSocket] ì—°ê²° ëŠê¹€ (code: ${ev.code}). ì¬ì—°ê²° ì‹œë„ ${wsReconnectAttemptsRef.current + 1}/${MAX_RECONNECT}`);
          if (wsReconnectAttemptsRef.current < MAX_RECONNECT) {
            wsReconnectAttemptsRef.current++;
            // ì§€ìˆ˜ ë°±ì˜¤í”„: ì¬ì‹œë„ ê°„ê²©ì„ ì ì§„ì ìœ¼ë¡œ ì¦ê°€ (3ì´ˆ â†’ 6ì´ˆ â†’ 12ì´ˆ â†’ ...)
            const delay = 3000 * Math.pow(2, wsReconnectAttemptsRef.current - 1);
            setTimeout(() => {
              if (interviewStartedRef.current) {
                const newWs = connectWebSocket(targetSid);
                wsRef.current = newWs;
              }
            }, Math.min(delay, 30000)); // ìµœëŒ€ 30ì´ˆ ëŒ€ê¸°
          } else {
            console.error("[WebSocket] ìµœëŒ€ ì¬ì—°ê²° íšŸìˆ˜ ì´ˆê³¼. ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨ì´ í•„ìš”í•©ë‹ˆë‹¤.");
          }
        };

        ws.onerror = () => {
          console.warn("[WebSocket] ì—°ê²° ì˜¤ë¥˜ ë°œìƒ");
          // oncloseê°€ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¡œê·¸ë§Œ ì¶œë ¥
        };

        return ws;
      };

      const ws = connectWebSocket(sid);
      wsRef.current = ws;

      initSpeechRecognition();
      setPhase("interview");
      setInterviewStarted(true);
      setActiveSession(true); // ë©´ì ‘ ì‹œì‘ â†’ Auth ìœ íœ´ íƒ€ì„ì•„ì›ƒ ë¹„í™œì„±í™”
      setSessionId(sid);

      // [START] ìš”ì²­: ì²« ì¸ì‚¬ë§ ê°€ì ¸ì˜¤ê¸°
      // ë§Œì•½ API ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ ì¸ì‚¬ë§ì„ í‘œì‹œí•˜ì—¬ ì‚¬ìš©ìê°€ ë¹ˆ í™”ë©´ì„ ë³´ì§€ ì•Šë„ë¡ í•¨
      try {
        await getNextQuestion(sid, "[START]");
      } catch (err) {
        console.error("ì²« ì§ˆë¬¸ ìš”ì²­ ì‹¤íŒ¨, ê¸°ë³¸ ì¸ì‚¬ë§ í‘œì‹œ:", err);
        const fallbackGreeting = "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë©´ì ‘ì„ ì§„í–‰í•˜ê²Œ ëœ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ë¨¼ì € ê°„ë‹¨í•œ ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.";
        setCurrentQuestion(fallbackGreeting);
        setQuestionNum(1);
        setMessages(prev => [...prev, { role: "ai", text: fallbackGreeting }]);
        setStatus("listening");
      }
    } catch (err) {
      console.error("ë©´ì ‘ ì§„í–‰ ì‹¤íŒ¨:", err);
      toast.error("ë©´ì ‘ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
    }
  };

  /**
   * ì´ë ¥ì„œ ê²½ê³  ëª¨ë‹¬ì—ì„œ ì´ë ¥ì„œ ì—…ë¡œë“œ ì²˜ë¦¬
   */
  const handleResumeUploadInWarning = async (file: File) => {
    if (!file.name.toLowerCase().endsWith(".pdf")) {
      toast.error("PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.");
      return;
    }
    if (file.size > 10 * 1024 * 1024) {
      toast.error("íŒŒì¼ í¬ê¸°ëŠ” 10MB ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.");
      return;
    }
    setResumeUploading(true);
    try {
      await resumeApi.upload(file, pendingSessionId, user!.email);
      setShowResumeWarning(false);
      // ì´ë ¥ì„œ ì—…ë¡œë“œ ì™„ë£Œ í›„ ë©´ì ‘ ì§„í–‰
      await proceedInterview(pendingSessionId);
    } catch {
      toast.error("ì´ë ¥ì„œ ì—…ë¡œë“œ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
    } finally {
      setResumeUploading(false);
    }
  };

  /**
   * ì´ë ¥ì„œ ì—†ì´ ë©´ì ‘ ì§„í–‰
   */
  const proceedWithoutResume = async () => {
    setShowResumeWarning(false);
    await proceedInterview(pendingSessionId);
  };

  // ========== ìŒì„± ì¸ì‹ (Web Speech API) ==========
  const initSpeechRecognition = () => {
    const SR = window.webkitSpeechRecognition || window.SpeechRecognition;
    if (!SR) {
      // Web Speech API ë¯¸ì§€ì› ë¸Œë¼ìš°ì € â€” í…ìŠ¤íŠ¸ ì…ë ¥ ëª¨ë“œë¡œ ì „í™˜
      console.warn("[SpeechRecognition] Web Speech APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì…ë ¥ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.");
      setSttAvailable(false);
      return;
    }
    const recognition = new SR();
    recognition.lang = "ko-KR";
    recognition.continuous = true;
    recognition.interimResults = true;

    // ì—°ì† ì—ëŸ¬ ì¹´ìš´í„° â€” ì¼ì • íšŸìˆ˜ ì´ìƒ ì—ëŸ¬ ì‹œ STTë¥¼ ë¹„í™œì„±í™”í•˜ê³  í…ìŠ¤íŠ¸ ì…ë ¥ìœ¼ë¡œ ì „í™˜
    let consecutiveErrors = 0;
    const MAX_CONSECUTIVE_ERRORS = 3;

    // ìŒì„± ì¸ì‹ ê²°ê³¼ í•¸ë“¤ëŸ¬ â€” ìµœì¢…(final) ê²°ê³¼ë§Œ STT í…ìŠ¤íŠ¸ì— ì¶”ê°€
    recognition.onresult = (e: SpeechRecognitionEvent) => {
      consecutiveErrors = 0; // ì •ìƒ ê²°ê³¼ ìˆ˜ì‹  ì‹œ ì—ëŸ¬ ì¹´ìš´í„° ë¦¬ì…‹
      let final = "";
      for (let i = e.resultIndex; i < e.results.length; i++) {
        if (e.results[i].isFinal) final += e.results[i][0].transcript;
      }
      if (final) setSttText(prev => prev + " " + final);
    };

    // ìŒì„± ì¸ì‹ ì—ëŸ¬ í•¸ë“¤ëŸ¬ â€” ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ë˜ë„ë¡ ì²˜ë¦¬
    // ì—ëŸ¬ ìœ í˜•: network(ë„¤íŠ¸ì›Œí¬), not-allowed(ê¶Œí•œ), aborted(ì¤‘ë‹¨), no-speech(ë¬´ìŒ) ë“±
    recognition.onerror = ((ev: Event) => {
      const error = ev as Event & { error?: string };
      const errorType = error.error || "unknown";
      // no-speechëŠ” ì •ìƒ ë™ì‘ (ì‚¬ìš©ìê°€ ë§í•˜ì§€ ì•Šì€ ê²½ìš°) â†’ ë¬´ì‹œ
      if (errorType === "no-speech") return;
      console.warn(`[SpeechRecognition] ì—ëŸ¬: ${errorType}`);

      // not-allowed(ê¶Œí•œ ê±°ë¶€) ë˜ëŠ” network(ë„¤íŠ¸ì›Œí¬ ë¶ˆê°€) â†’ ì¦‰ì‹œ í…ìŠ¤íŠ¸ ëª¨ë“œ ì „í™˜
      if (errorType === "not-allowed" || errorType === "service-not-allowed") {
        console.warn("[SpeechRecognition] ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì…ë ¥ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.");
        setSttAvailable(false);
        return;
      }

      // abortedëŠ” ì˜ë„ì  ì¤‘ë‹¨ â†’ ì¬ì‹œì‘ ë¶ˆí•„ìš”
      if (errorType === "aborted") return;

      // ê¸°íƒ€ ì—ëŸ¬ â€” ì—°ì† ì—ëŸ¬ ì¹´ìš´í„° ì¦ê°€
      consecutiveErrors++;
      if (consecutiveErrors >= MAX_CONSECUTIVE_ERRORS) {
        console.warn(`[SpeechRecognition] ì—°ì† ${MAX_CONSECUTIVE_ERRORS}íšŒ ì—ëŸ¬ ë°œìƒ. í…ìŠ¤íŠ¸ ì…ë ¥ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.`);
        setSttAvailable(false);
      }
    }) as ((ev: Event) => void);

    // ìŒì„± ì¸ì‹ ì¢…ë£Œ í•¸ë“¤ëŸ¬ â€” Refë¥¼ í†µí•´ ìµœì‹  state ì°¸ì¡° (stale closure ë°©ì§€)
    // Chromeì—ì„œ continuous ëª¨ë“œë¼ë„ ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ ë“±ìœ¼ë¡œ ì¸ì‹ì´ ëŠê¸¸ ìˆ˜ ìˆìŒ
    recognition.onend = () => {
      // Refì—ì„œ ìµœì‹  interviewStarted/micEnabled ê°’ì„ ì½ì–´ ì¬ì‹œì‘ ì—¬ë¶€ ê²°ì •
      if (interviewStartedRef.current && micEnabledRef.current) {
        // ë””ë°”ìš´ìŠ¤: ë¹ ë¥¸ ì¬ì‹œì‘ ë£¨í”„ ë°©ì§€ (300ms ëŒ€ê¸° í›„ ì¬ì‹œì‘)
        setTimeout(() => {
          try {
            recognition.start();
          } catch (e) {
            // ì´ë¯¸ ì‹œì‘ëœ ìƒíƒœì—ì„œ start() í˜¸ì¶œ ì‹œ DOMException ë°œìƒ ê°€ëŠ¥ â†’ ë¬´ì‹œ
            console.warn("[SpeechRecognition] ì¬ì‹œì‘ ì‹¤íŒ¨ (ì´ë¯¸ í™œì„±):", e);
          }
        }, 300);
      }
    };

    recognitionRef.current = recognition;
    try {
      recognition.start();
    } catch (e) {
      console.warn("[SpeechRecognition] ì´ˆê¸° ì‹œì‘ ì‹¤íŒ¨:", e);
      setSttAvailable(false);
    }
  };

  // ========== ì§ˆë¬¸ ìš”ì²­ ==========
  const getNextQuestion = async (sid: string, message: string) => {
    setStatus("processing");
    try {
      const res = await interviewApi.chat({ session_id: sid, message, mode: "interview" });
      const q = res.response;
      setCurrentQuestion(q);
      setQuestionNum(res.question_number || questionNum + 1);
      setMessages(prev => [...prev, { role: "ai", text: q }]);
      await speakQuestion(q);
      setStatus("listening");

      // ê°œì… ì²´í¬ ì‹œì‘
      startInterventionCheck(sid);
    } catch (err) {
      // ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ "listening" ìƒíƒœë¡œ ë³µê·€ â†’ ì‚¬ìš©ìê°€ ì¬ì‹œë„ ê°€ëŠ¥
      console.error("ë‹¤ìŒ ì§ˆë¬¸ ìš”ì²­ ì‹¤íŒ¨:", err);
      setMessages(prev => [...prev, { role: "ai", text: "âš ï¸ ì¼ì‹œì  ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ë‹µë³€í•´ ì£¼ì„¸ìš”." }]);
      setStatus("listening");
    }
  };

  // ========== TTS ë°œí™” ==========
  const speakQuestion = async (text: string) => {
    setStatus("speaking");

    if (serverTtsEnabled) {
      try {
        const blob = await ttsApi.speak(text, "professional");
        const url = URL.createObjectURL(blob);
        const audio = new Audio(url);
        await new Promise<void>((resolve) => {
          audio.onended = () => resolve();
          audio.onerror = () => resolve();
          audio.play().catch(() => resolve());
        });
        URL.revokeObjectURL(url);
        return;
      } catch {
        setServerTtsEnabled(false);
      }
    }

    // ì„œë²„ TTS ë¹„í™œì„±/ì‹¤íŒ¨ ì‹œ Web Speech API í´ë°±
    try {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = "ko-KR";
      speechSynthesis.speak(utterance);
    } catch { /* ignore */ }
  };

  // ========== ê°œì… ì²´í¬ ==========
  const startInterventionCheck = (sid: string) => {
    if (interventionTimerRef.current) clearInterval(interventionTimerRef.current);
    interventionApi.startTurn(sid, currentQuestion).catch(() => { });
    interventionTimerRef.current = setInterval(async () => {
      try {
        const res = await interventionApi.check(sid, sttText);
        const interventionMessage = res.intervention?.message;
        if (res.needs_intervention && interventionMessage) {
          setMessages(prev => [...prev, { role: "ai", text: `ğŸ’¡ ${interventionMessage}` }]);
          await speakQuestion(interventionMessage);
        }
      } catch { /* ignore */ }
    }, 3000);
  };

  // ========== ë‹µë³€ ì œì¶œ ==========
  const submitAnswer = async () => {
    // STT í…ìŠ¤íŠ¸ ë˜ëŠ” ìˆ˜ë™ ì…ë ¥ ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš© (STT ìš°ì„ , ì—†ìœ¼ë©´ ìˆ˜ë™ ì…ë ¥)
    const answer = (sttText.trim() || manualInput.trim());
    if (!answer) return;
    setSttText("");
    setManualInput("");  // ìˆ˜ë™ ì…ë ¥ë„ ì´ˆê¸°í™”
    setMessages(prev => [...prev, { role: "user", text: answer }]);

    // ê°œì… íƒ€ì´ë¨¸ ì •ì§€
    if (interventionTimerRef.current) clearInterval(interventionTimerRef.current);
    interventionApi.endTurn(sessionId, answer).catch(() => { });

    // âš¡ í‰ê°€ëŠ” /api/chat ë‚´ë¶€ ì›Œí¬í”Œë¡œìš°ì—ì„œ ìë™ ì²˜ë¦¬ë¨ (Celery ì˜¤í”„ë¡œë“œ ë˜ëŠ” ì§ì ‘ í‰ê°€)
    // ë³„ë„ /api/evaluate í˜¸ì¶œ ì œê±° â€” ë™ì¼ Ollama GPU ë¦¬ì†ŒìŠ¤ ê²½í•©ìœ¼ë¡œ ì§ˆë¬¸ ìƒì„± ì§€ì—° ë°©ì§€
    // (ì´ì „: interviewApi.evaluate() fire-and-forget â†’ Ollama í ì ìœ  â†’ chat ì‘ë‹µ ì§€ì—°)
    setStatus("processing");

    // ë‹¤ìŒ ì§ˆë¬¸ or ì¢…ë£Œ
    if (questionNum >= totalQuestions) {
      endInterview();
    } else {
      await getNextQuestion(sessionId, answer);
    }
  };

  // ========== ë©´ì ‘ ì¢…ë£Œ ==========
  const endInterview = async () => {
    setInterviewStarted(false);
    setActiveSession(false); // ë©´ì ‘ ì¢…ë£Œ â†’ Auth ìœ íœ´ íƒ€ì„ì•„ì›ƒ ì¬í™œì„±í™”
    recognitionRef.current?.stop();
    if (interventionTimerRef.current) clearInterval(interventionTimerRef.current);

    setPhase("coding");
  };

  // ========== ë§ˆì´í¬/ì¹´ë©”ë¼ í† ê¸€ ==========
  const toggleMic = () => {
    const track = streamRef.current?.getAudioTracks()[0];
    if (track) { track.enabled = !track.enabled; setMicEnabled(track.enabled); }
  };
  const toggleCam = () => {
    const track = streamRef.current?.getVideoTracks()[0];
    if (track) { track.enabled = !track.enabled; setCamEnabled(track.enabled); }
  };

  if (!user) return null;

  // ========== ë Œë”ë§ ==========
  return (
    <div className="min-h-screen flex flex-col">
      <Header />
      {/* ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ì•Œë¦¼ (EventBus â†’ WebSocket) */}
      <EventToastContainer onPushEvent={(handler) => { pushEventRef.current = handler; }} />

      {/* ========== ì´ë ¥ì„œ ë¯¸ì—…ë¡œë“œ ê²½ê³  ëª¨ë‹¬ (UX ê°œì„ ) ========== */}
      {showResumeWarning && (
        <div className="fixed inset-0 z-50 flex items-center justify-center bg-black/60 backdrop-blur-sm">
          <div className="glass-card max-w-md w-full mx-4 p-6">
            {/* ê²½ê³  ì•„ì´ì½˜ + ì œëª© */}
            <div className="flex items-center gap-3 mb-4">
              <div className="w-12 h-12 rounded-full bg-[rgba(255,193,7,0.15)] flex items-center justify-center">
                <AlertTriangle size={24} className="text-[var(--warning)]" />
              </div>
              <h3 className="text-lg font-bold">ì´ë ¥ì„œê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤</h3>
            </div>

            {/* ê²½ê³  ë©”ì‹œì§€ */}
            <p className="text-sm text-[var(--text-secondary)] mb-2">
              {resumeWarningMsg}
            </p>
            <div className="bg-[rgba(255,193,7,0.08)] border border-[rgba(255,193,7,0.2)] rounded-xl p-3 mb-6">
              <p className="text-xs text-[var(--warning)]">
                ğŸ’¡ ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ì§€ì› ì§ë¬´Â·ê²½ë ¥ì— ë§ì¶˜ <strong>ë§ì¶¤í˜• ì§ˆë¬¸</strong>ì„ ë°›ì„ ìˆ˜ ìˆì–´ ë” íš¨ê³¼ì ì¸ ë©´ì ‘ ì—°ìŠµì´ ë©ë‹ˆë‹¤.
              </p>
            </div>

            {/* ì´ë ¥ì„œ ì—…ë¡œë“œ ì˜ì—­ */}
            <div
              className="border-2 border-dashed border-[rgba(0,217,255,0.3)] rounded-xl p-6 text-center cursor-pointer hover:border-[var(--cyan)] hover:bg-[rgba(0,217,255,0.03)] transition-all mb-4"
              onClick={() => fileInputRef.current?.click()}
            >
              {resumeUploading ? (
                <div className="flex flex-col items-center">
                  <Loader2 size={28} className="animate-spin text-[var(--cyan)] mb-2" />
                  <p className="text-sm text-[var(--text-secondary)]">ì—…ë¡œë“œ ì¤‘...</p>
                </div>
              ) : (
                <>
                  <Upload size={28} className="mx-auto mb-2 text-[var(--cyan)]" />
                  <p className="text-sm text-[var(--text-secondary)]">PDF ì´ë ¥ì„œë¥¼ í´ë¦­í•˜ì—¬ ì—…ë¡œë“œ</p>
                  <p className="text-xs text-[var(--text-secondary)] mt-1">ìµœëŒ€ 10MB</p>
                </>
              )}
            </div>
            <input
              ref={fileInputRef}
              type="file"
              accept=".pdf"
              hidden
              onChange={(e) => e.target.files?.[0] && handleResumeUploadInWarning(e.target.files[0])}
            />

            {/* ì•¡ì…˜ ë²„íŠ¼ */}
            <div className="flex gap-3">
              <button
                onClick={proceedWithoutResume}
                disabled={resumeUploading}
                className="flex-1 px-4 py-3 rounded-xl text-sm font-semibold border border-[rgba(255,255,255,0.15)] text-[var(--text-secondary)] hover:bg-[rgba(255,255,255,0.05)] transition disabled:opacity-40"
              >
                ì´ë ¥ì„œ ì—†ì´ ì§„í–‰
              </button>
              <button
                onClick={() => fileInputRef.current?.click()}
                disabled={resumeUploading}
                className="flex-1 btn-gradient px-4 py-3 rounded-xl text-sm font-semibold flex items-center justify-center gap-2 disabled:opacity-40"
              >
                <Upload size={16} /> ì´ë ¥ì„œ ì—…ë¡œë“œ
              </button>
            </div>
          </div>
        </div>
      )}

      {/* ë©´ì ‘ ì¤€ë¹„ ì¤‘ ë¡œë”© í™”ë©´ (ìë™ ì‹œì‘) */}
      {phase === "setup" && (
        <main className="flex-1 flex items-center justify-center p-6">
          <div className="glass-card max-w-lg w-full text-center">
            <h1 className="text-3xl font-bold gradient-text mb-4">AI ëª¨ì˜ë©´ì ‘</h1>
            <div className="flex flex-col items-center gap-4 py-8">
              <Loader2 size={48} className="text-[var(--cyan)] animate-spin" />
              <p className="text-[var(--text-secondary)]">
                ë©´ì ‘ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤...<br />
                ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.
              </p>
            </div>
          </div>
        </main>
      )}

      {/* ë©´ì ‘ ì§„í–‰ í™”ë©´ */}
      {phase === "interview" && (
        <main className="flex-1 flex flex-col p-4 max-w-[1400px] mx-auto w-full">
          {/* ìƒíƒœ ë°” */}
          <div className="flex items-center justify-between mb-4">
            <div className="flex items-center gap-3">
              <span className={`px-4 py-1.5 rounded-full text-sm font-semibold ${status === "ready" ? "bg-[rgba(0,255,136,0.2)] text-[var(--green)]" :
                status === "listening" ? "bg-[rgba(255,193,7,0.2)] text-[var(--warning)]" :
                  status === "speaking" ? "bg-[rgba(0,217,255,0.2)] text-[var(--cyan)]" :
                    "bg-[rgba(156,39,176,0.2)] text-purple-300"
                }`}>
                {status === "ready" && "ëŒ€ê¸°"}
                {status === "listening" && "ğŸ¤ ë“£ëŠ” ì¤‘..."}
                {status === "speaking" && "ğŸ”Š ë°œí™” ì¤‘..."}
                {status === "processing" && "â³ ì²˜ë¦¬ ì¤‘..."}
              </span>
              <span className="text-sm text-[var(--text-secondary)]">ì§ˆë¬¸ {questionNum}/{totalQuestions}</span>
            </div>
            <button onClick={endInterview} className="px-4 py-2 text-sm rounded-lg bg-[rgba(244,67,54,0.2)] text-[var(--danger)] border border-[rgba(244,67,54,0.3)] hover:bg-[rgba(244,67,54,0.3)] transition">
              ë©´ì ‘ ì¢…ë£Œ
            </button>
          </div>

          {/* ì§„í–‰ ë°” */}
          <div className="flex gap-1 mb-6">
            {Array.from({ length: totalQuestions }, (_, i) => (
              <div key={i} className={`h-1.5 flex-1 rounded-full transition-all ${i < questionNum ? "bg-gradient-to-r from-[var(--cyan)] to-[var(--green)]" :
                i === questionNum ? "bg-[var(--cyan)] animate-pulse" : "bg-[rgba(255,255,255,0.1)]"
                }`} />
            ))}
          </div>

          {/* 2ì—´ ë ˆì´ì•„ì›ƒ: ì‚¬ìš©ì ì˜ìƒ + ëŒ€í™”ì°½ */}
          <div className="grid grid-cols-1 lg:grid-cols-2 gap-4 flex-1">
            {/* â•â• ì™¼ìª½: ì‚¬ìš©ì ì¹´ë©”ë¼ ì˜ìƒ (í¬ê²Œ) â•â• */}
            <div className="glass-card flex flex-col">
              <h3 className="text-sm font-semibold mb-3 flex items-center gap-2">
                <Camera size={16} className="text-[var(--cyan)]" /> ë‚´ í™”ë©´
              </h3>
              <div className="flex-1 rounded-xl overflow-hidden bg-black relative min-h-[300px]">
                {/* ì‚¬ìš©ì ì›¹ìº  ë¹„ë””ì˜¤ â€” ì˜ì—­ ì „ì²´ë¥¼ ì±„ì›€ */}
                <video ref={interviewVideoRef} autoPlay muted playsInline className="w-full h-full object-cover" />
                {/* ì¹´ë©”ë¼ OFF ì˜¤ë²„ë ˆì´ */}
                {!camEnabled && (
                  <div className="absolute inset-0 bg-black/80 flex items-center justify-center">
                    <CameraOff size={48} className="text-[var(--text-secondary)]" />
                  </div>
                )}
                {/* ì¢Œí•˜ë‹¨: ì¹´ë©”ë¼ ìƒíƒœ ë±ƒì§€ */}
                <span className="absolute bottom-3 left-3 text-xs bg-black/60 px-2 py-1 rounded text-white">
                  {camEnabled ? "ğŸ“· ì¹´ë©”ë¼ ON" : "ì¹´ë©”ë¼ OFF"}
                </span>
                {/* ìš°í•˜ë‹¨: AI ìƒíƒœ ë±ƒì§€ â€” ë©´ì ‘ê´€ì´ ë§í•˜ê±°ë‚˜ ì²˜ë¦¬ ì¤‘ì¼ ë•Œ í‘œì‹œ */}
                <span className={`absolute bottom-3 right-3 text-xs px-2 py-1 rounded font-medium ${status === "speaking" ? "bg-[rgba(0,255,136,0.25)] text-[var(--green)]"
                  : status === "processing" ? "bg-[rgba(156,39,176,0.25)] text-purple-300"
                    : status === "listening" ? "bg-[rgba(255,193,7,0.25)] text-[var(--warning)]"
                      : "bg-black/60 text-white"
                  }`}>
                  {status === "speaking" ? "ğŸ”Š AI ë‹µë³€ ì¤‘..."
                    : status === "processing" ? "â³ AI ìƒê° ì¤‘..."
                      : status === "listening" ? "ğŸ¤ ë“£ëŠ” ì¤‘..."
                        : "ëŒ€ê¸°"}
                </span>
              </div>

              {/* í•˜ë‹¨ ì»¨íŠ¸ë¡¤ ë²„íŠ¼ */}
              <div className="flex items-center justify-center gap-4 mt-4">
                <button onClick={toggleMic} title={micEnabled ? "ë§ˆì´í¬ ë„ê¸°" : "ë§ˆì´í¬ ì¼œê¸°"} className={`w-12 h-12 rounded-full flex items-center justify-center transition ${micEnabled ? "bg-[rgba(0,255,136,0.2)] text-[var(--green)]" : "bg-[rgba(255,82,82,0.2)] text-[var(--danger)]"
                  }`}>
                  {micEnabled ? <Mic size={20} /> : <MicOff size={20} />}
                </button>
                <button onClick={toggleCam} title={camEnabled ? "ì¹´ë©”ë¼ ë„ê¸°" : "ì¹´ë©”ë¼ ì¼œê¸°"} className={`w-12 h-12 rounded-full flex items-center justify-center transition ${camEnabled ? "bg-[rgba(0,255,136,0.2)] text-[var(--green)]" : "bg-[rgba(255,82,82,0.2)] text-[var(--danger)]"
                  }`}>
                  {camEnabled ? <Camera size={20} /> : <CameraOff size={20} />}
                </button>
                <button onClick={submitAnswer} disabled={(!sttText.trim() && !manualInput.trim()) || status !== "listening"} title="ë‹µë³€ ì œì¶œ"
                  className="btn-gradient !rounded-full w-12 h-12 flex items-center justify-center disabled:opacity-40">
                  <SkipForward size={20} />
                </button>
                <button onClick={endInterview} title="ë©´ì ‘ ì¢…ë£Œ" className="w-12 h-12 rounded-full bg-[rgba(244,67,54,0.8)] text-white flex items-center justify-center hover:bg-[rgba(244,67,54,1)] transition">
                  <PhoneOff size={20} />
                </button>
              </div>
            </div>

            {/* â•â• ì˜¤ë¥¸ìª½: ëŒ€í™”ì°½ â•â• */}
            <div className="glass-card flex flex-col">
              <h3 className="text-sm font-semibold mb-3 flex items-center gap-2">
                <Volume2 size={16} className="text-[var(--cyan)]" /> AI ë©´ì ‘ê´€ ëŒ€í™”
              </h3>

              {/* ì±„íŒ… ë¡œê·¸ */}
              <div className="flex-1 overflow-y-auto space-y-3 mb-3 min-h-[300px] max-h-[520px] pr-2">
                {messages.map((m, i) => (
                  <div key={i} className={`flex ${m.role === "user" ? "justify-end" : "justify-start"}`}>
                    <div className={`max-w-[85%] px-4 py-3 rounded-2xl text-sm leading-relaxed ${m.role === "user"
                      ? "bg-gradient-to-r from-[rgba(0,217,255,0.15)] to-[rgba(0,255,136,0.1)] rounded-br-md"
                      : "bg-[rgba(255,255,255,0.06)] rounded-bl-md"
                      }`}>
                      {m.text}
                    </div>
                  </div>
                ))}
                <div ref={chatEndRef} />
              </div>

              {/* STT ì¸ì‹ í…ìŠ¤íŠ¸ + ìˆ˜ë™ í…ìŠ¤íŠ¸ ì…ë ¥ í´ë°± */}
              {status === "listening" && (
                <div className="space-y-2">
                  {/* STT í™œì„± ì‹œ: ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ê²°ê³¼ í‘œì‹œ */}
                  {sttAvailable && (
                    <div className="bg-[rgba(255,193,7,0.08)] border border-[rgba(255,193,7,0.2)] rounded-xl p-3">
                      <p className="text-xs text-[var(--warning)] mb-1">ğŸ¤ ìŒì„± ì¸ì‹ ì¤‘...</p>
                      <p className="text-sm">{sttText || "ë§ì”€í•´ì£¼ì„¸ìš”..."}</p>
                    </div>
                  )}
                  {/* STT ë¹„í™œì„± ì‹œ: ì•ˆë‚´ ë©”ì‹œì§€ */}
                  {!sttAvailable && (
                    <div className="bg-[rgba(244,67,54,0.08)] border border-[rgba(244,67,54,0.2)] rounded-xl p-3">
                      <p className="text-xs text-[var(--danger)] mb-1">âš ï¸ ìŒì„± ì¸ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤</p>
                      <p className="text-xs text-[var(--text-secondary)]">ì•„ë˜ ì…ë ¥ì°½ì— ë‹µë³€ì„ ì§ì ‘ ì…ë ¥í•´ì£¼ì„¸ìš”.</p>
                    </div>
                  )}
                  {/* ìˆ˜ë™ í…ìŠ¤íŠ¸ ì…ë ¥ (í•­ìƒ í‘œì‹œ â€” STT ë³´ì™„/ëŒ€ì²´) */}
                  <div className="flex gap-2">
                    <input
                      type="text"
                      value={manualInput}
                      onChange={(e) => setManualInput(e.target.value)}
                      onKeyDown={(e) => {
                        // Enter í‚¤ë¡œ ë‹µë³€ ì œì¶œ (Shift+EnterëŠ” ë¬´ì‹œ)
                        if (e.key === "Enter" && !e.shiftKey) {
                          e.preventDefault();
                          submitAnswer();
                        }
                      }}
                      placeholder={sttAvailable ? "í…ìŠ¤íŠ¸ë¡œë„ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤..." : "ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”..."}
                      className="flex-1 bg-[rgba(255,255,255,0.06)] border border-[rgba(255,255,255,0.15)] rounded-xl px-4 py-2.5 text-sm placeholder:text-[var(--text-secondary)] focus:outline-none focus:border-[var(--cyan)] transition"
                    />
                    <button
                      onClick={submitAnswer}
                      disabled={!sttText.trim() && !manualInput.trim()}
                      className="btn-gradient px-4 py-2.5 rounded-xl text-sm font-semibold disabled:opacity-40 whitespace-nowrap"
                    >
                      ì œì¶œ
                    </button>
                  </div>
                </div>
              )}
            </div>
          </div>
        </main>
      )}

      {/* ì½”ë”© í…ŒìŠ¤íŠ¸ Phase */}
      {phase === "coding" && (
        <main className="flex-1 flex items-center justify-center p-6">
          <div className="glass-card max-w-lg text-center">
            <h2 className="text-2xl font-bold gradient-text mb-4">ğŸ’» ì½”ë”© í…ŒìŠ¤íŠ¸</h2>
            <p className="text-[var(--text-secondary)] mb-6">
              í™”ìƒ ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì½”ë”© í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?
            </p>
            <div className="flex gap-4 justify-center">
              <button onClick={() => router.push(`/coding?session=${sessionId}`)} className="btn-gradient px-8 py-3">
                ì½”ë”© í…ŒìŠ¤íŠ¸ ì‹œì‘
              </button>
              <button onClick={() => setPhase("whiteboard")} className="px-8 py-3 rounded-xl border border-[rgba(0,217,255,0.4)] text-[var(--cyan)] hover:bg-[rgba(0,217,255,0.1)] transition">
                ê±´ë„ˆë›°ê¸°
              </button>
            </div>
          </div>
        </main>
      )}

      {/* í™”ì´íŠ¸ë³´ë“œ Phase */}
      {phase === "whiteboard" && (
        <main className="flex-1 flex items-center justify-center p-6">
          <div className="glass-card max-w-lg text-center">
            <h2 className="text-2xl font-bold gradient-text mb-4">ğŸ¨ ì•„í‚¤í…ì²˜ ì„¤ê³„</h2>
            <p className="text-[var(--text-secondary)] mb-6">
              í™”ì´íŠ¸ë³´ë“œì— ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•´ë³´ì„¸ìš”.
            </p>
            <div className="flex gap-4 justify-center">
              <button onClick={() => router.push(`/whiteboard?session=${sessionId}`)} className="btn-gradient px-8 py-3">
                ì„¤ê³„ ì‹œì‘
              </button>
              <button onClick={() => setPhase("report")} className="px-8 py-3 rounded-xl border border-[rgba(0,217,255,0.4)] text-[var(--cyan)] hover:bg-[rgba(0,217,255,0.1)] transition">
                ê²°ê³¼ ë³´ê¸°
              </button>
            </div>
          </div>
        </main>
      )}

      {/* ë¦¬í¬íŠ¸ Phase */}
      {phase === "report" && (
        <main className="flex-1 overflow-y-auto p-6">
          <div className="max-w-5xl mx-auto space-y-6">
            {/* ë¡œë”© ìƒíƒœ */}
            {reportLoading && (
              <div className="flex flex-col items-center justify-center py-20">
                <Loader2 className="w-10 h-10 text-[var(--cyan)] animate-spin mb-4" />
                <p className="text-[var(--text-secondary)]">ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤â€¦</p>
              </div>
            )}

            {/* ì°¨íŠ¸ ë¦¬í¬íŠ¸ */}
            {!reportLoading && reportData && (
              <InterviewReportCharts report={reportData} />
            )}

            {/* ë°ì´í„° ì—†ì„ ë•Œ */}
            {!reportLoading && !reportData && (
              <div className="glass-card text-center py-12">
                <h2 className="text-2xl font-bold gradient-text mb-4">ğŸ“Š ë©´ì ‘ ì™„ë£Œ!</h2>
                <p className="text-[var(--text-secondary)]">ë¦¬í¬íŠ¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>
              </div>
            )}

            {/* í•˜ë‹¨ ì•¡ì…˜ ë²„íŠ¼ */}
            <div className="flex gap-4 justify-center flex-wrap pb-8">
              <button
                onClick={() => window.open(`/api/report/${sessionId}`, "_blank")}
                className="flex items-center gap-2 px-6 py-3 rounded-xl bg-[rgba(0,217,255,0.15)] border border-[rgba(0,217,255,0.4)] text-[var(--cyan)] hover:bg-[rgba(0,217,255,0.25)] transition"
              >
                <FileText className="w-4 h-4" /> JSON ì›ë³¸
              </button>
              <button
                onClick={() => {
                  const tk = sessionStorage.getItem("access_token");
                  fetch(`/api/report/${sessionId}/pdf`, {
                    headers: { Authorization: `Bearer ${tk}` },
                  })
                    .then((res) => {
                      if (!res.ok) throw new Error("PDF ìƒì„± ì‹¤íŒ¨");
                      return res.blob();
                    })
                    .then((blob) => {
                      const url = URL.createObjectURL(blob);
                      const a = document.createElement("a");
                      a.href = url;
                      a.download = `interview_report_${sessionId?.slice(0, 8)}.pdf`;
                      a.click();
                      URL.revokeObjectURL(url);
                    })
                    .catch((err) => toast.error(err.message));
                }}
                className="flex items-center gap-2 btn-gradient px-6 py-3"
              >
                <Download className="w-4 h-4" /> PDF ë‹¤ìš´ë¡œë“œ
              </button>
              <button
                onClick={() => router.push("/dashboard")}
                className="flex items-center gap-2 px-6 py-3 rounded-xl border border-[rgba(0,217,255,0.4)] text-[var(--cyan)] hover:bg-[rgba(0,217,255,0.1)] transition"
              >
                <LayoutDashboard className="w-4 h-4" /> ëŒ€ì‹œë³´ë“œë¡œ
              </button>
            </div>
          </div>
        </main>
      )}
    </div>
  );
}
