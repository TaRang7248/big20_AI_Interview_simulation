"""
Hume AI TTS ì„œë¹„ìŠ¤
- Hume AIì˜ EVI(Empathic Voice Interface)ë¥¼ ì‚¬ìš©í•œ ê°ì •ì  TTS êµ¬í˜„
- ë©´ì ‘ê´€ì˜ ìŒì„±ì„ ìì—°ìŠ¤ëŸ½ê³  ê°ì •ì ìœ¼ë¡œ ìƒì„±
"""

import os
import asyncio
import base64
import json
import wave
import io
from typing import Optional, Callable, Dict, Any
from dataclasses import dataclass
from dotenv import load_dotenv

load_dotenv()

# Hume AI API í‚¤ ì„¤ì •
HUME_API_KEY = os.getenv("HUME_API_KEY")
HUME_CONFIG_ID = os.getenv("HUME_CONFIG_ID")  # EVI ì„¤ì • ID (ì„ íƒì‚¬í•­)


@dataclass
class HumeVoiceConfig:
    """Hume AI ìŒì„± ì„¤ì •"""
    voice_name: str = "ITO"  # Hume ê¸°ë³¸ ìŒì„±
    language: str = "ko"  # í•œêµ­ì–´ ì§€ì› (EVI 4-mini)
    speaking_rate: float = 1.0
    emotion_style: str = "professional"  # professional, friendly, empathetic


class HumeTTSService:
    """
    Hume AI EVIë¥¼ ì‚¬ìš©í•œ TTS ì„œë¹„ìŠ¤
    
    íŠ¹ì§•:
    - ê°ì • ì¸ì‹ ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ìƒì„±
    - í•œêµ­ì–´ ì§€ì› (EVI 4-mini)
    - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ê°€ëŠ¥
    """
    
    def __init__(self, api_key: Optional[str] = None, config_id: Optional[str] = None):
        self.api_key = api_key or HUME_API_KEY
        self.config_id = config_id or HUME_CONFIG_ID
        self._client = None
        self._audio_queue = asyncio.Queue()
        
        if not self.api_key:
            print("âš ï¸ HUME_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    
    async def _get_client(self):
        """Hume í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (lazy loading)"""
        if self._client is None:
            try:
                from hume.client import AsyncHumeClient
                self._client = AsyncHumeClient(api_key=self.api_key)
            except ImportError:
                raise ImportError(
                    "Hume SDKê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                    "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install hume[microphone]"
                )
        return self._client
    
    async def generate_speech_stream(
        self, 
        text: str, 
        on_audio_chunk: Optional[Callable[[bytes], None]] = None
    ) -> bytes:
        """
        í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ (ìŠ¤íŠ¸ë¦¬ë°)
        
        Args:
            text: ë³€í™˜í•  í…ìŠ¤íŠ¸
            on_audio_chunk: ì˜¤ë””ì˜¤ ì²­í¬ê°€ ë„ì°©í•  ë•Œë§ˆë‹¤ í˜¸ì¶œë˜ëŠ” ì½œë°±
            
        Returns:
            ì „ì²´ ì˜¤ë””ì˜¤ ë°ì´í„° (bytes)
        """
        client = await self._get_client()
        audio_chunks = []
        
        try:
            from hume.empathic_voice.chat.socket_client import ChatConnectOptions
            from hume.empathic_voice.chat.types import SubscribeEvent
            from hume import Stream
            
            stream = Stream.new()
            
            async def on_message(message: SubscribeEvent):
                if message.type == "audio_output":
                    audio_data = base64.b64decode(message.data.encode("utf-8"))
                    audio_chunks.append(audio_data)
                    if on_audio_chunk:
                        on_audio_chunk(audio_data)
                    await stream.put(audio_data)
                elif message.type == "assistant_end":
                    # ìŒì„± ìƒì„± ì™„ë£Œ
                    pass
            
            options = ChatConnectOptions(config_id=self.config_id) if self.config_id else ChatConnectOptions()
            
            async with client.empathic_voice.chat.connect_with_callbacks(
                options=options,
                on_open=lambda: print("ğŸ¤ Hume AI ì—°ê²°ë¨"),
                on_message=on_message,
                on_close=lambda: print("ğŸ”‡ Hume AI ì—°ê²° ì¢…ë£Œ"),
                on_error=lambda err: print(f"âŒ Hume AI ì˜¤ë¥˜: {err}")
            ) as socket:
                # í…ìŠ¤íŠ¸ ì „ì†¡í•˜ì—¬ ìŒì„± ìƒì„± ìš”ì²­
                await socket.send_text_input(text)
                
                # ì‘ë‹µ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
                await asyncio.sleep(5)  # ê¸°ë³¸ ëŒ€ê¸° ì‹œê°„
                
        except Exception as e:
            print(f"âŒ Hume TTS ì˜¤ë¥˜: {e}")
            return b""
        
        return b"".join(audio_chunks)
    
    async def generate_speech_simple(
        self, 
        text: str,
        output_file: Optional[str] = None
    ) -> Optional[str]:
        """
        ê°„ë‹¨í•œ TTS ìƒì„± (REST API ì‚¬ìš©)
        
        Hume AIì˜ TTS REST APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
        
        Args:
            text: ë³€í™˜í•  í…ìŠ¤íŠ¸
            output_file: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ (ì„ íƒ)
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
        """
        import aiohttp
        
        if not self.api_key:
            print("âŒ HUME_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return None
        
        print(f"ğŸ”Š [Hume TTS] ìŒì„± ìƒì„± ì¤‘... (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)})")
        
        # Hume AI TTS REST API ì—”ë“œí¬ì¸íŠ¸
        url = "https://api.hume.ai/v0/evi/tts"
        
        headers = {
            "X-Hume-Api-Key": self.api_key,
            "Content-Type": "application/json"
        }
        
        payload = {
            "text": text,
            "voice": {
                "name": "ITO"  # Hume ê¸°ë³¸ ìŒì„±
            }
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, headers=headers, json=payload) as response:
                    if response.status == 200:
                        audio_data = await response.read()
                        
                        if output_file:
                            with open(output_file, "wb") as f:
                                f.write(audio_data)
                            print(f"ğŸ’¾ [Hume TTS] ì €ì¥ ì™„ë£Œ: {output_file}")
                            return output_file
                        else:
                            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                            temp_file = "hume_tts_output.mp3"
                            with open(temp_file, "wb") as f:
                                f.write(audio_data)
                            return temp_file
                    else:
                        error_text = await response.text()
                        print(f"âŒ Hume TTS API ì˜¤ë¥˜ ({response.status}): {error_text}")
                        return None
                        
        except Exception as e:
            print(f"âŒ Hume TTS ì˜¤ë¥˜: {e}")
            return None


class HumeInterviewerVoice:
    """
    AI ë©´ì ‘ê´€ ìŒì„± ì„œë¹„ìŠ¤
    
    Hume AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë©´ì ‘ê´€ì˜ ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì ì¸ ìŒì„±ì„ ìƒì„±
    """
    
    def __init__(self):
        self.tts_service = HumeTTSService()
        self.voice_config = HumeVoiceConfig()
        self._is_speaking = False
        
    @property
    def is_speaking(self) -> bool:
        return self._is_speaking
    
    async def speak(
        self, 
        text: str, 
        emotion: str = "neutral",
        output_file: Optional[str] = None
    ) -> Optional[str]:
        """
        ë©´ì ‘ê´€ì´ ë§í•˜ê¸°
        
        Args:
            text: ë§í•  ë‚´ìš©
            emotion: ê°ì • (neutral, friendly, serious, encouraging)
            output_file: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        """
        self._is_speaking = True
        
        try:
            # ê°ì •ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (Humeê°€ ìë™ìœ¼ë¡œ ê°ì •ì„ ì¸ì‹í•˜ì§€ë§Œ, íŒíŠ¸ ì œê³µ)
            processed_text = self._add_emotion_context(text, emotion)
            
            result = await self.tts_service.generate_speech_simple(
                processed_text,
                output_file
            )
            
            return result
            
        finally:
            self._is_speaking = False
    
    def _add_emotion_context(self, text: str, emotion: str) -> str:
        """ê°ì • ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ (Hume AIê°€ ë” ì˜ ì´í•´í•˜ë„ë¡)"""
        # Hume AIëŠ” í…ìŠ¤íŠ¸ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜
        # í•„ìš”ì‹œ SSML ë˜ëŠ” íŠ¹ìˆ˜ ë§ˆì»¤ ì¶”ê°€ ê°€ëŠ¥
        return text
    
    async def speak_question(self, question: str) -> Optional[str]:
        """ë©´ì ‘ ì§ˆë¬¸ ìŒì„± ìƒì„±"""
        return await self.speak(question, emotion="professional")
    
    async def speak_feedback(self, feedback: str, is_positive: bool = True) -> Optional[str]:
        """í”¼ë“œë°± ìŒì„± ìƒì„±"""
        emotion = "encouraging" if is_positive else "serious"
        return await self.speak(feedback, emotion=emotion)
    
    async def speak_greeting(self) -> Optional[str]:
        """ì¸ì‚¬ë§ ìŒì„± ìƒì„±"""
        greeting = "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë©´ì ‘ì„ ì§„í–‰í•˜ê²Œ ëœ AI ë©´ì ‘ê´€ì…ë‹ˆë‹¤. í¸í•˜ê²Œ ì„í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤."
        return await self.speak(greeting, emotion="friendly")
    
    async def speak_closing(self) -> Optional[str]:
        """ì¢…ë£Œ ì¸ì‚¬ ìŒì„± ìƒì„±"""
        closing = "ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ë©´ì ‘ì€ ì—¬ê¸°ì„œ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤. ì¢‹ì€ ê²°ê³¼ ìˆìœ¼ì‹œê¸¸ ë°”ëë‹ˆë‹¤."
        return await self.speak(closing, emotion="friendly")


# ========== FastAPI ì—”ë“œí¬ì¸íŠ¸ í†µí•© ==========

def create_tts_router():
    """FastAPI ë¼ìš°í„° ìƒì„±"""
    from fastapi import APIRouter, HTTPException
    from fastapi.responses import FileResponse, StreamingResponse
    from pydantic import BaseModel
    
    router = APIRouter(prefix="/tts", tags=["TTS"])
    interviewer_voice = HumeInterviewerVoice()
    
    class TTSRequest(BaseModel):
        text: str
        emotion: str = "neutral"
    
    @router.post("/speak")
    async def speak(request: TTSRequest):
        """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
        output_file = f"tts_output_{hash(request.text) % 10000}.mp3"
        result = await interviewer_voice.speak(
            request.text, 
            request.emotion,
            output_file
        )
        
        if result:
            return FileResponse(
                result,
                media_type="audio/mpeg",
                filename="speech.mp3"
            )
        else:
            raise HTTPException(status_code=500, detail="TTS ìƒì„± ì‹¤íŒ¨")
    
    @router.post("/question")
    async def speak_question(request: TTSRequest):
        """ë©´ì ‘ ì§ˆë¬¸ ìŒì„± ìƒì„±"""
        result = await interviewer_voice.speak_question(request.text)
        
        if result:
            return FileResponse(result, media_type="audio/mpeg")
        else:
            raise HTTPException(status_code=500, detail="TTS ìƒì„± ì‹¤íŒ¨")
    
    @router.get("/greeting")
    async def greeting():
        """ì¸ì‚¬ë§ ìŒì„±"""
        result = await interviewer_voice.speak_greeting()
        
        if result:
            return FileResponse(result, media_type="audio/mpeg")
        else:
            raise HTTPException(status_code=500, detail="TTS ìƒì„± ì‹¤íŒ¨")
    
    @router.get("/status")
    async def status():
        """TTS ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        return {
            "service": "Hume AI TTS",
            "api_key_configured": bool(HUME_API_KEY),
            "config_id_configured": bool(HUME_CONFIG_ID),
            "is_speaking": interviewer_voice.is_speaking
        }
    
    return router


# ========== í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ==========

async def test_hume_tts():
    """Hume TTS í…ŒìŠ¤íŠ¸"""
    print("=" * 50)
    print("Hume AI TTS í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    if not HUME_API_KEY:
        print("âŒ HUME_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— ë‹¤ìŒì„ ì¶”ê°€í•˜ì„¸ìš”:")
        print("   HUME_API_KEY=your_api_key_here")
        return
    
    interviewer = HumeInterviewerVoice()
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    test_text = "ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
    print(f"\ní…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸: {test_text}")
    
    result = await interviewer.speak_question(test_text)
    
    if result:
        print(f"âœ… ìŒì„± íŒŒì¼ ìƒì„± ì™„ë£Œ: {result}")
    else:
        print("âŒ ìŒì„± ìƒì„± ì‹¤íŒ¨")


if __name__ == "__main__":
    asyncio.run(test_hume_tts())
