"""
Hume AI Prosody ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤
================================
ë©´ì ‘ ì§€ì›ìì˜ **ìŒì„± í†¤(Prosody)** ì—ì„œ 48ì¢… ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.

ê¸°ëŠ¥:
  - Hume Expression Measurement Streaming API (WebSocket) ê¸°ë°˜ ì‹¤ì‹œê°„ ë¶„ì„
  - Hume Expression Measurement Batch API (REST) ê¸°ë°˜ ë…¹ìŒ í›„ ë¶„ì„
  - DeepFace 7ì¢… í‘œì • ê°ì •ê³¼ ë³‘í•©í•˜ì—¬ ë©€í‹°ëª¨ë‹¬ ê°ì • ìœµí•©
  - ë©´ì ‘ ë§¥ë½ì— ìµœì í™”ëœ 10ì¢… í•µì‹¬ ì§€í‘œ ì¶”ì¶œ

48ì¢… ê°ì • â†’ ë©´ì ‘ í•µì‹¬ ì§€í‘œ ë§¤í•‘:
  - ìì‹ ê°(Confidence): Determination, Pride, Triumph
  - ë¶ˆì•ˆ(Anxiety): Anxiety, Fear, Distress
  - ì§‘ì¤‘(Focus): Concentration, Contemplation, Interest
  - ë‹¹í™©(Confusion): Confusion, Awkwardness, Embarrassment
  - ê¸ì •(Positivity): Joy, Satisfaction, Excitement
  - ì§„ì •(Calmness): Calmness, Contentment, Relief
  - ë¶€ì •(Negativity): Anger, Disgust, Contempt
  - ìŠ¬í””(Sadness): Sadness, Disappointment, Doubt
  - ë†€ëŒ(Surprise): Surprise (positive), Surprise (negative), Realization
  - í”¼ë¡œ(Fatigue): Boredom, Tiredness
"""

import os
import asyncio
import base64
import json
import time
import statistics
from typing import Optional, Dict, List, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from collections import Counter

import httpx
from dotenv import load_dotenv

load_dotenv()

# ========== Hume AI API í‚¤ (hume_tts_service.pyì™€ ê³µìœ ) ==========
HUME_API_KEY = os.getenv("HUME_API_KEY")
HUME_SECRET_KEY = os.getenv("HUME_SECRET_KEY")

# ========== ë©´ì ‘ í•µì‹¬ ì§€í‘œ ë§¤í•‘ ==========
INTERVIEW_EMOTION_MAP: Dict[str, List[str]] = {
    "confidence": ["Determination", "Pride", "Triumph"],
    "anxiety": ["Anxiety", "Fear", "Distress"],
    "focus": ["Concentration", "Contemplation", "Interest"],
    "confusion": ["Confusion", "Awkwardness", "Embarrassment"],
    "positivity": ["Joy", "Satisfaction", "Excitement"],
    "calmness": ["Calmness", "Contentment", "Relief"],
    "negativity": ["Anger", "Disgust", "Contempt"],
    "sadness": ["Sadness", "Disappointment", "Doubt"],
    "surprise": ["Surprise (positive)", "Surprise (negative)", "Realization"],
    "fatigue": ["Boredom", "Tiredness"],
}

# 48ì¢… ì „ì²´ ê°ì • ëª©ë¡
ALL_PROSODY_EMOTIONS = [
    "Admiration", "Adoration", "Aesthetic Appreciation", "Amusement",
    "Anger", "Anxiety", "Awe", "Awkwardness",
    "Boredom", "Calmness", "Concentration", "Contemplation",
    "Contentment", "Craving", "Desire", "Determination",
    "Disappointment", "Disgust", "Distress", "Doubt",
    "Ecstasy", "Embarrassment", "Empathic Pain", "Entrancement",
    "Envy", "Excitement", "Fear", "Guilt",
    "Horror", "Interest", "Joy", "Love",
    "Nostalgia", "Pain", "Pride", "Realization",
    "Relief", "Romance", "Sadness", "Satisfaction",
    "Shame", "Surprise (negative)", "Surprise (positive)", "Sympathy",
    "Tiredness", "Triumph", "Confusion", "Contempt",
]


# ========== ë°ì´í„° í´ë˜ìŠ¤ ==========

@dataclass
class ProsodyEmotionSample:
    """ë‹¨ì¼ Prosody ê°ì • ë¶„ì„ ìƒ˜í”Œ"""
    timestamp: float
    text: str                       # ë°œí™” í…ìŠ¤íŠ¸
    time_begin: float               # ì˜¤ë””ì˜¤ ë‚´ ì‹œì‘ ì‹œê° (ì´ˆ)
    time_end: float                 # ì˜¤ë””ì˜¤ ë‚´ ì¢…ë£Œ ì‹œê° (ì´ˆ)
    raw_emotions: Dict[str, float]  # 48ì¢… ê°ì • {ì´ë¦„: ìŠ¤ì½”ì–´}
    interview_indicators: Dict[str, float]  # 10ì¢… ë©´ì ‘ ì§€í‘œ
    dominant_emotion: str           # ê°€ì¥ ë†’ì€ ê°ì •
    dominant_indicator: str         # ê°€ì¥ ë†’ì€ ë©´ì ‘ ì§€í‘œ


@dataclass
class ProsodyTurnStats:
    """ë‹¨ì¼ í„´ì˜ Prosody ê°ì • í†µê³„"""
    turn_index: int
    sample_count: int = 0
    dominant_indicator: str = ""
    indicator_averages: Dict[str, float] = field(default_factory=dict)
    top_emotions: List[Tuple[str, float]] = field(default_factory=list)
    confidence_trend: str = ""  # "rising", "stable", "falling"


@dataclass
class ProsodySessionStats:
    """ì„¸ì…˜ ì „ì²´ Prosody ê°ì • í†µê³„"""
    session_id: str
    total_samples: int = 0
    indicator_averages: Dict[str, float] = field(default_factory=dict)
    indicator_grades: Dict[str, str] = field(default_factory=dict)
    dominant_indicator: str = ""
    overall_assessment: str = ""
    confidence_level: str = ""      # ìì‹ ê° ìˆ˜ì¤€ í‰ê°€
    anxiety_level: str = ""         # ë¶ˆì•ˆ ìˆ˜ì¤€ í‰ê°€
    engagement_level: str = ""      # ì°¸ì—¬ë„ ìˆ˜ì¤€ í‰ê°€
    emotional_stability: float = 0.0  # ê°ì • ì•ˆì •ì„± (0-1)
    turn_details: List[Dict] = field(default_factory=list)
    emotion_timeline: List[Dict] = field(default_factory=list)

    def to_dict(self) -> Dict:
        return {
            "total_samples": self.total_samples,
            "indicator_averages": {
                k: round(v, 4) for k, v in self.indicator_averages.items()
            },
            "indicator_grades": self.indicator_grades,
            "dominant_indicator": self.dominant_indicator,
            "overall_assessment": self.overall_assessment,
            "confidence_level": self.confidence_level,
            "anxiety_level": self.anxiety_level,
            "engagement_level": self.engagement_level,
            "emotional_stability": round(self.emotional_stability, 3),
            "turn_details": self.turn_details,
            "emotion_timeline": self.emotion_timeline,
        }


# ========== í† í° ì¸ì¦ (hume_tts_serviceì™€ ë…ë¦½ ìºì‹±) ==========
_prosody_access_token: Optional[str] = None
_prosody_token_expires_at: float = 0


async def _get_prosody_access_token() -> Optional[str]:
    """Hume AI OAuth2 í† í° ì¸ì¦ (Prosody ì „ìš© ìºì‹œ)"""
    global _prosody_access_token, _prosody_token_expires_at

    if _prosody_access_token and time.time() < _prosody_token_expires_at - 300:
        return _prosody_access_token

    if not HUME_API_KEY or not HUME_SECRET_KEY:
        print("âš ï¸ [HumeProsody] HUME_API_KEY ë˜ëŠ” HUME_SECRET_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    try:
        auth = f"{HUME_API_KEY}:{HUME_SECRET_KEY}"
        encoded_auth = base64.b64encode(auth.encode()).decode()

        async with httpx.AsyncClient() as client:
            resp = await client.post(
                url="https://api.hume.ai/oauth2-cc/token",
                headers={"Authorization": f"Basic {encoded_auth}"},
                data={"grant_type": "client_credentials"},
            )
            if resp.status_code == 200:
                data = resp.json()
                _prosody_access_token = data.get("access_token")
                expires_in = data.get("expires_in", 3600)
                _prosody_token_expires_at = time.time() + expires_in
                print("âœ… [HumeProsody] í† í° ì¸ì¦ ì„±ê³µ")
                return _prosody_access_token
            else:
                print(f"âŒ [HumeProsody] í† í° ì¸ì¦ ì‹¤íŒ¨: {resp.status_code}")
                return None
    except Exception as e:
        print(f"âŒ [HumeProsody] í† í° ì¸ì¦ ì˜¤ë¥˜: {e}")
        return None


# ========== ê°ì • ìŠ¤ì½”ì–´ â†’ ë©´ì ‘ ì§€í‘œ ë³€í™˜ ==========

def extract_interview_indicators(raw_emotions: Dict[str, float]) -> Dict[str, float]:
    """
    48ì¢… Hume Prosody ê°ì • ìŠ¤ì½”ì–´ë¥¼ 10ì¢… ë©´ì ‘ í•µì‹¬ ì§€í‘œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    ê° ì§€í‘œëŠ” í•´ë‹¹ ê°ì • ê·¸ë£¹ì˜ í‰ê·  ìŠ¤ì½”ì–´ì…ë‹ˆë‹¤.
    """
    indicators: Dict[str, float] = {}
    for indicator_name, emotion_names in INTERVIEW_EMOTION_MAP.items():
        scores = [raw_emotions.get(name, 0.0) for name in emotion_names]
        indicators[indicator_name] = sum(scores) / len(scores) if scores else 0.0
    return indicators


def get_dominant_indicator(indicators: Dict[str, float]) -> str:
    """ê°€ì¥ ë†’ì€ ë©´ì ‘ ì§€í‘œ ë°˜í™˜"""
    if not indicators:
        return "unknown"
    return max(indicators, key=indicators.get)


def determine_emotion_adaptive_mode(indicators: Dict[str, float]) -> str:
    """
    Prosody ë©´ì ‘ ì§€í‘œ ê¸°ë°˜ ê°ì • ì ì‘ ëª¨ë“œ ê²°ì •.

    DeepFace ì˜ 3ë¶„ë¥˜(encouraging/challenging/normal) ì™€ í˜¸í™˜.
    Prosody ëŠ” ë” ì„¸ë°€í•œ ì§€í‘œë¥¼ í™œìš©í•˜ë¯€ë¡œ ì •í™•ë„ê°€ ë†’ìŠµë‹ˆë‹¤.
    """
    anxiety = indicators.get("anxiety", 0)
    sadness = indicators.get("sadness", 0)
    negativity = indicators.get("negativity", 0)
    confidence = indicators.get("confidence", 0)
    positivity = indicators.get("positivity", 0)
    confusion = indicators.get("confusion", 0)

    # ë¶€ì •ì  ìƒíƒœê°€ ê°•í•˜ë©´ ê²©ë ¤ ëª¨ë“œ
    if (anxiety + sadness + negativity) / 3 > 0.15 or confusion > 0.2:
        return "encouraging"
    # ìì‹ ê°+ê¸ì •ì´ ë†’ìœ¼ë©´ ì‹¬í™” ëª¨ë“œ
    elif (confidence + positivity) / 2 > 0.2:
        return "challenging"
    else:
        return "normal"


# ========== Hume Prosody ë¶„ì„ ì„œë¹„ìŠ¤ ==========

class HumeProsodyService:
    """
    Hume AI Expression Measurement APIë¥¼ ì‚¬ìš©í•˜ì—¬
    ë©´ì ‘ ì§€ì›ìì˜ ìŒì„± í†¤ì—ì„œ 48ì¢… ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì„œë¹„ìŠ¤.
    """

    def __init__(self):
        self.api_key = HUME_API_KEY
        self.secret_key = HUME_SECRET_KEY
        self._is_available = bool(self.api_key)

        # ì„¸ì…˜ë³„ ë°ì´í„° ì €ì¥ì†Œ
        self._session_samples: Dict[str, List[ProsodyEmotionSample]] = {}
        self._session_turn_indices: Dict[str, int] = {}
        self._session_turn_boundaries: Dict[str, List[int]] = {}  # í„´ ì‹œì‘ sample index

        if not self._is_available:
            print("âš ï¸ [HumeProsody] HUME_API_KEY ë¯¸ì„¤ì • â€” ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”")
        else:
            print("âœ… [HumeProsody] ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

    @property
    def is_available(self) -> bool:
        return self._is_available

    # ------------------------------------------------------------------ #
    #  Batch API â€” ì˜¤ë””ì˜¤ íŒŒì¼/ë°”ì´íŠ¸ ë¶„ì„                                    #
    # ------------------------------------------------------------------ #
    async def analyze_audio_bytes(
        self,
        audio_data: bytes,
        session_id: str,
        content_type: str = "audio/wav",
    ) -> Optional[List[ProsodyEmotionSample]]:
        """
        ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ Hume Batch APIë¡œ ë¶„ì„í•©ë‹ˆë‹¤.

        Args:
            audio_data: ì˜¤ë””ì˜¤ íŒŒì¼ ë°”ì´íŠ¸ (wav, mp3 ë“±)
            session_id: ì„¸ì…˜ ID
            content_type: MIME íƒ€ì…

        Returns:
            ProsodyEmotionSample ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None
        """
        if not self._is_available:
            return None

        token = await _get_prosody_access_token()
        if not token:
            # API Key ì¸ì¦ í´ë°±
            headers = {
                "X-Hume-Api-Key": self.api_key,
            }
        else:
            headers = {
                "Authorization": f"Bearer {token}",
            }

        try:
            # Batch Job ì œì¶œ
            async with httpx.AsyncClient(timeout=60.0) as client:
                # íŒŒì¼ ì—…ë¡œë“œ + Prosody ëª¨ë¸ ì„¤ì •
                files = {"file": ("audio.wav", audio_data, content_type)}
                models_config = json.dumps({
                    "models": {
                        "prosody": {
                            "granularity": "utterance",
                            "identify_speakers": False,
                        }
                    }
                })

                resp = await client.post(
                    "https://api.hume.ai/v0/batch/jobs",
                    headers=headers,
                    files=files,
                    data={"json": models_config},
                )

                if resp.status_code != 200:
                    print(f"âŒ [HumeProsody] Batch Job ì œì¶œ ì‹¤íŒ¨: {resp.status_code} {resp.text[:200]}")
                    return None

                job_data = resp.json()
                job_id = job_data.get("job_id")
                if not job_id:
                    print(f"âŒ [HumeProsody] Job ID ì—†ìŒ: {job_data}")
                    return None

                print(f"ğŸ”„ [HumeProsody] Batch Job ì œì¶œ: {job_id}")

                # í´ë§ìœ¼ë¡œ ì™„ë£Œ ëŒ€ê¸°
                predictions = await self._poll_batch_job(client, headers, job_id)
                if predictions is None:
                    return None

                # íŒŒì‹±
                samples = self._parse_prosody_predictions(predictions, session_id)
                return samples

        except Exception as e:
            print(f"âŒ [HumeProsody] Batch ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None

    async def _poll_batch_job(
        self, client: httpx.AsyncClient, headers: dict, job_id: str,
        max_wait: int = 120, interval: float = 2.0,
    ) -> Optional[Dict]:
        """Batch Job ì™„ë£Œ í´ë§"""
        elapsed = 0.0
        while elapsed < max_wait:
            resp = await client.get(
                f"https://api.hume.ai/v0/batch/jobs/{job_id}",
                headers=headers,
            )
            if resp.status_code == 200:
                status_data = resp.json()
                status = status_data.get("state", {}).get("status", "")
                if status == "COMPLETED":
                    # ì˜ˆì¸¡ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                    pred_resp = await client.get(
                        f"https://api.hume.ai/v0/batch/jobs/{job_id}/predictions",
                        headers=headers,
                    )
                    if pred_resp.status_code == 200:
                        return pred_resp.json()
                    print(f"âŒ [HumeProsody] ì˜ˆì¸¡ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {pred_resp.status_code}")
                    return None
                elif status == "FAILED":
                    print(f"âŒ [HumeProsody] Batch Job ì‹¤íŒ¨: {status_data}")
                    return None
                # IN_PROGRESS â€” ê³„ì† ëŒ€ê¸°
            await asyncio.sleep(interval)
            elapsed += interval

        print(f"âš ï¸ [HumeProsody] Batch Job íƒ€ì„ì•„ì›ƒ ({max_wait}ì´ˆ)")
        return None

    # ------------------------------------------------------------------ #
    #  Streaming API â€” ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ë¶„ì„                                #
    # ------------------------------------------------------------------ #
    async def analyze_audio_stream(
        self,
        audio_chunk: bytes,
        session_id: str,
    ) -> Optional[ProsodyEmotionSample]:
        """
        ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ Hume Streaming API (WebSocket)ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.

        í˜„ì¬ëŠ” REST ê¸°ë°˜ ê°„ì´ êµ¬í˜„ â€” í”„ë ˆì„ ëˆ„ì  í›„ Batch ë¶„ì„.
        ë³¸ê²© WebSocket ìŠ¤íŠ¸ë¦¬ë°ì€ hume SDK ì˜ connect ë¥¼ í™œìš©í•©ë‹ˆë‹¤.

        Args:
            audio_chunk: PCM16 ì˜¤ë””ì˜¤ ì²­í¬
            session_id: ì„¸ì…˜ ID

        Returns:
            ProsodyEmotionSample ë˜ëŠ” None
        """
        if not self._is_available:
            return None

        token = await _get_prosody_access_token()
        if not token and not self.api_key:
            return None

        headers = {}
        if token:
            headers["Authorization"] = f"Bearer {token}"
        else:
            headers["X-Hume-Api-Key"] = self.api_key

        try:
            audio_b64 = base64.b64encode(audio_chunk).decode("utf-8")

            async with httpx.AsyncClient(timeout=10.0) as client:
                resp = await client.post(
                    "https://api.hume.ai/v0/stream/models",
                    headers={**headers, "Content-Type": "application/json"},
                    json={
                        "data": audio_b64,
                        "models": {"prosody": {}},
                        "raw_text": False,
                    },
                )

                if resp.status_code != 200:
                    return None

                result = resp.json()
                prosody_preds = result.get("prosody", {}).get("predictions", [])

                if not prosody_preds:
                    return None

                # ì²« ë²ˆì§¸ ì˜ˆì¸¡ ì‚¬ìš©
                pred = prosody_preds[0]
                raw_emotions = {
                    e["name"]: e["score"]
                    for e in pred.get("emotions", [])
                }
                indicators = extract_interview_indicators(raw_emotions)
                dominant = max(raw_emotions, key=raw_emotions.get) if raw_emotions else "neutral"

                sample = ProsodyEmotionSample(
                    timestamp=time.time(),
                    text=pred.get("text", ""),
                    time_begin=pred.get("time", {}).get("begin", 0),
                    time_end=pred.get("time", {}).get("end", 0),
                    raw_emotions=raw_emotions,
                    interview_indicators=indicators,
                    dominant_emotion=dominant,
                    dominant_indicator=get_dominant_indicator(indicators),
                )

                # ì„¸ì…˜ì— ì €ì¥
                self._session_samples.setdefault(session_id, []).append(sample)
                return sample

        except Exception as e:
            print(f"âš ï¸ [HumeProsody] ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None

    # ------------------------------------------------------------------ #
    #  ì˜ˆì¸¡ ê²°ê³¼ íŒŒì‹±                                                        #
    # ------------------------------------------------------------------ #
    def _parse_prosody_predictions(
        self, predictions_data: Any, session_id: str
    ) -> List[ProsodyEmotionSample]:
        """Hume API Batch ì‘ë‹µì„ ProsodyEmotionSample ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        samples: List[ProsodyEmotionSample] = []

        try:
            # Batch API ì‘ë‹µ êµ¬ì¡°: [{source: {}, results: {predictions: [{models: {prosody: ...}}]}}]
            for source_entry in predictions_data:
                results = source_entry.get("results", {})
                preds = results.get("predictions", [])
                for pred_group in preds:
                    prosody_model = pred_group.get("models", {}).get("prosody", {})
                    grouped = prosody_model.get("grouped_predictions", [])
                    for group in grouped:
                        for pred in group.get("predictions", []):
                            raw_emotions = {
                                e["name"]: e["score"]
                                for e in pred.get("emotions", [])
                            }
                            indicators = extract_interview_indicators(raw_emotions)
                            dominant = (
                                max(raw_emotions, key=raw_emotions.get)
                                if raw_emotions
                                else "neutral"
                            )

                            sample = ProsodyEmotionSample(
                                timestamp=time.time(),
                                text=pred.get("text", ""),
                                time_begin=pred.get("time", {}).get("begin", 0),
                                time_end=pred.get("time", {}).get("end", 0),
                                raw_emotions=raw_emotions,
                                interview_indicators=indicators,
                                dominant_emotion=dominant,
                                dominant_indicator=get_dominant_indicator(indicators),
                            )
                            samples.append(sample)
        except Exception as e:
            print(f"âš ï¸ [HumeProsody] íŒŒì‹± ì˜¤ë¥˜: {e}")

        # ì„¸ì…˜ì— ì €ì¥
        self._session_samples.setdefault(session_id, []).extend(samples)
        print(f"âœ… [HumeProsody] {len(samples)}ê°œ ìƒ˜í”Œ íŒŒì‹± ì™„ë£Œ (session={session_id[:8]}...)")
        return samples

    # ------------------------------------------------------------------ #
    #  ìˆ˜ë™ ìƒ˜í”Œ ì¶”ê°€ (Celery Worker ë“±ì—ì„œ ì‚¬ìš©)                              #
    # ------------------------------------------------------------------ #
    def add_sample_from_dict(self, session_id: str, data: Dict) -> ProsodyEmotionSample:
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ ProsodyEmotionSample ìƒì„± ë° ì €ì¥"""
        raw_emotions = data.get("raw_emotions", {})
        indicators = extract_interview_indicators(raw_emotions)
        dominant = max(raw_emotions, key=raw_emotions.get) if raw_emotions else "neutral"

        sample = ProsodyEmotionSample(
            timestamp=data.get("timestamp", time.time()),
            text=data.get("text", ""),
            time_begin=data.get("time_begin", 0),
            time_end=data.get("time_end", 0),
            raw_emotions=raw_emotions,
            interview_indicators=indicators,
            dominant_emotion=dominant,
            dominant_indicator=get_dominant_indicator(indicators),
        )
        self._session_samples.setdefault(session_id, []).append(sample)
        return sample

    # ------------------------------------------------------------------ #
    #  í„´ ê²½ê³„ ê´€ë¦¬                                                          #
    # ------------------------------------------------------------------ #
    def start_new_turn(self, session_id: str):
        """ìƒˆ ë‹µë³€ í„´ ì‹œì‘ ì‹œ í˜¸ì¶œ"""
        idx = len(self._session_samples.get(session_id, []))
        self._session_turn_boundaries.setdefault(session_id, []).append(idx)
        turn_num = len(self._session_turn_boundaries[session_id])
        self._session_turn_indices[session_id] = turn_num

    # ------------------------------------------------------------------ #
    #  í†µê³„ ê³„ì‚°                                                             #
    # ------------------------------------------------------------------ #
    def get_latest_indicators(self, session_id: str) -> Optional[Dict[str, float]]:
        """ì„¸ì…˜ì˜ ìµœì‹  ë©´ì ‘ ì§€í‘œ ë°˜í™˜"""
        samples = self._session_samples.get(session_id, [])
        if not samples:
            return None
        return samples[-1].interview_indicators

    def get_latest_adaptive_mode(self, session_id: str) -> str:
        """ì„¸ì…˜ì˜ ìµœì‹  Prosody ê¸°ë°˜ ì ì‘ ëª¨ë“œ ë°˜í™˜"""
        indicators = self.get_latest_indicators(session_id)
        if not indicators:
            return "normal"
        return determine_emotion_adaptive_mode(indicators)

    def get_session_stats(self, session_id: str) -> ProsodySessionStats:
        """ì„¸ì…˜ ì „ì²´ Prosody ê°ì • í†µê³„ ê³„ì‚°"""
        samples = self._session_samples.get(session_id, [])
        stats = ProsodySessionStats(session_id=session_id)
        stats.total_samples = len(samples)

        if not samples:
            stats.overall_assessment = "Prosody ë¶„ì„ ë°ì´í„° ì—†ìŒ"
            return stats

        # ì§€í‘œë³„ í‰ê· 
        indicator_values: Dict[str, List[float]] = {k: [] for k in INTERVIEW_EMOTION_MAP}
        for s in samples:
            for k, v in s.interview_indicators.items():
                indicator_values[k].append(v)

        for k, vals in indicator_values.items():
            stats.indicator_averages[k] = sum(vals) / len(vals) if vals else 0

        # ì§€í‘œë³„ ë“±ê¸‰
        for k, avg in stats.indicator_averages.items():
            stats.indicator_grades[k] = self._grade_indicator(k, avg)

        # ì£¼ìš” ì§€í‘œ
        stats.dominant_indicator = get_dominant_indicator(stats.indicator_averages)

        # ìì‹ ê° / ë¶ˆì•ˆ / ì°¸ì—¬ë„ ìˆ˜ì¤€ í‰ê°€
        stats.confidence_level = self._assess_level(
            stats.indicator_averages.get("confidence", 0), "confidence"
        )
        stats.anxiety_level = self._assess_level(
            stats.indicator_averages.get("anxiety", 0), "anxiety"
        )
        engagement = (
            stats.indicator_averages.get("focus", 0)
            + stats.indicator_averages.get("positivity", 0)
        ) / 2
        stats.engagement_level = self._assess_level(engagement, "engagement")

        # ê°ì • ì•ˆì •ì„± (ì§€í‘œ ë¶„ì‚°ì˜ ì—­ìˆ˜)
        all_indicator_stds = []
        for k, vals in indicator_values.items():
            if len(vals) >= 2:
                all_indicator_stds.append(statistics.stdev(vals))
        if all_indicator_stds:
            avg_std = sum(all_indicator_stds) / len(all_indicator_stds)
            stats.emotional_stability = max(0, 1.0 - avg_std * 5)  # ì •ê·œí™”
        else:
            stats.emotional_stability = 0.5

        # í„´ë³„ í†µê³„
        boundaries = self._session_turn_boundaries.get(session_id, [])
        for i, start_idx in enumerate(boundaries):
            end_idx = boundaries[i + 1] if i + 1 < len(boundaries) else len(samples)
            turn_samples = samples[start_idx:end_idx]
            if not turn_samples:
                continue

            turn_indicators: Dict[str, float] = {k: 0 for k in INTERVIEW_EMOTION_MAP}
            for s in turn_samples:
                for k, v in s.interview_indicators.items():
                    turn_indicators[k] += v
            for k in turn_indicators:
                turn_indicators[k] /= len(turn_samples)

            # ìì‹ ê° ì¶”ì„¸
            conf_vals = [s.interview_indicators.get("confidence", 0) for s in turn_samples]
            if len(conf_vals) >= 2:
                trend = "rising" if conf_vals[-1] > conf_vals[0] * 1.1 else (
                    "falling" if conf_vals[-1] < conf_vals[0] * 0.9 else "stable"
                )
            else:
                trend = "stable"

            stats.turn_details.append({
                "turn_index": i + 1,
                "sample_count": len(turn_samples),
                "dominant_indicator": get_dominant_indicator(turn_indicators),
                "indicator_averages": {k: round(v, 4) for k, v in turn_indicators.items()},
                "confidence_trend": trend,
            })

        # íƒ€ì„ë¼ì¸ (ìµœëŒ€ 50 í¬ì¸íŠ¸)
        step = max(1, len(samples) // 50)
        for i in range(0, len(samples), step):
            s = samples[i]
            stats.emotion_timeline.append({
                "timestamp": s.timestamp,
                "text": s.text[:50] if s.text else "",
                "dominant_emotion": s.dominant_emotion,
                "dominant_indicator": s.dominant_indicator,
                "confidence": round(s.interview_indicators.get("confidence", 0), 4),
                "anxiety": round(s.interview_indicators.get("anxiety", 0), 4),
                "focus": round(s.interview_indicators.get("focus", 0), 4),
            })

        # ì¢…í•© í‰ê°€
        stats.overall_assessment = self._generate_assessment(stats)

        return stats

    def get_session_stats_dict(self, session_id: str) -> Dict:
        """ì„¸ì…˜ í†µê³„ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜ (ë¦¬í¬íŠ¸ ìƒì„±ìš©)"""
        return self.get_session_stats(session_id).to_dict()

    # ------------------------------------------------------------------ #
    #  DeepFace + Prosody ë©€í‹°ëª¨ë‹¬ ìœµí•©                                      #
    # ------------------------------------------------------------------ #
    def merge_with_deepface(
        self,
        prosody_indicators: Dict[str, float],
        deepface_emotion: Dict[str, Any],
        prosody_weight: float = 0.5,
    ) -> Dict[str, Any]:
        """
        Prosody ë©´ì ‘ ì§€í‘œì™€ DeepFace ê°ì •ì„ ìœµí•©í•©ë‹ˆë‹¤.

        Args:
            prosody_indicators: 10ì¢… Prosody ë©´ì ‘ ì§€í‘œ
            deepface_emotion: DeepFace ê²°ê³¼ {dominant_emotion, probabilities}
            prosody_weight: Prosody ê°€ì¤‘ì¹˜ (0-1, ê¸°ë³¸ 0.5)

        Returns:
            ìœµí•©ëœ ê°ì • ë°ì´í„°
        """
        deepface_weight = 1.0 - prosody_weight

        # DeepFace 7ì¢… â†’ ë©´ì ‘ ì§€í‘œ ë§¤í•‘
        deepface_probs = deepface_emotion.get("probabilities", {})
        deepface_indicators = {
            "confidence": deepface_probs.get("happy", 0) * 0.5 + deepface_probs.get("surprise", 0) * 0.3,
            "anxiety": deepface_probs.get("fear", 0) * 0.6 + deepface_probs.get("sad", 0) * 0.3,
            "focus": deepface_probs.get("neutral", 0) * 0.7,
            "confusion": deepface_probs.get("surprise", 0) * 0.3 + deepface_probs.get("fear", 0) * 0.2,
            "positivity": deepface_probs.get("happy", 0) * 0.8,
            "calmness": deepface_probs.get("neutral", 0) * 0.6,
            "negativity": deepface_probs.get("angry", 0) * 0.5 + deepface_probs.get("disgust", 0) * 0.4,
            "sadness": deepface_probs.get("sad", 0) * 0.8,
            "surprise": deepface_probs.get("surprise", 0) * 0.7,
            "fatigue": deepface_probs.get("neutral", 0) * 0.2 + deepface_probs.get("sad", 0) * 0.2,
        }

        # ê°€ì¤‘ í‰ê·  ìœµí•©
        merged = {}
        for key in INTERVIEW_EMOTION_MAP:
            p_val = prosody_indicators.get(key, 0)
            d_val = deepface_indicators.get(key, 0)
            merged[key] = p_val * prosody_weight + d_val * deepface_weight

        # ìœµí•© ì ì‘ ëª¨ë“œ
        adaptive_mode = determine_emotion_adaptive_mode(merged)

        return {
            "merged_indicators": merged,
            "dominant_indicator": get_dominant_indicator(merged),
            "emotion_adaptive_mode": adaptive_mode,
            "prosody_indicators": prosody_indicators,
            "deepface_indicators": deepface_indicators,
            "prosody_weight": prosody_weight,
            "source": "multimodal_fusion",
        }

    # ------------------------------------------------------------------ #
    #  ì„¸ì…˜ ì •ë¦¬                                                             #
    # ------------------------------------------------------------------ #
    def cleanup_session(self, session_id: str):
        """ì„¸ì…˜ ë°ì´í„° ì •ë¦¬"""
        self._session_samples.pop(session_id, None)
        self._session_turn_indices.pop(session_id, None)
        self._session_turn_boundaries.pop(session_id, None)

    # ------------------------------------------------------------------ #
    #  ë‚´ë¶€ í—¬í¼                                                             #
    # ------------------------------------------------------------------ #
    @staticmethod
    def _grade_indicator(indicator: str, value: float) -> str:
        """ì§€í‘œê°’ì„ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
        # ë¶€ì •ì  ì§€í‘œ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
        negative_indicators = {"anxiety", "confusion", "negativity", "sadness", "fatigue"}
        if indicator in negative_indicators:
            if value < 0.05:
                return "A"
            elif value < 0.10:
                return "B"
            elif value < 0.20:
                return "C"
            else:
                return "D"
        # ê¸ì •ì  ì§€í‘œ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        else:
            if value > 0.20:
                return "A"
            elif value > 0.10:
                return "B"
            elif value > 0.05:
                return "C"
            else:
                return "D"

    @staticmethod
    def _assess_level(value: float, indicator_type: str) -> str:
        """ìˆ˜ì¤€ í‰ê°€ ë¬¸ìì—´ ë°˜í™˜"""
        if indicator_type == "anxiety":
            # ë¶ˆì•ˆì€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
            if value < 0.05:
                return "ë§¤ìš° ì•ˆì •ì "
            elif value < 0.10:
                return "ì•ˆì •ì "
            elif value < 0.20:
                return "ì•½ê°„ ë¶ˆì•ˆ"
            else:
                return "ë†’ì€ ë¶ˆì•ˆ"
        else:
            # ìì‹ ê°/ì°¸ì—¬ë„ëŠ” ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
            if value > 0.20:
                return "ë§¤ìš° ë†’ìŒ"
            elif value > 0.10:
                return "ë†’ìŒ"
            elif value > 0.05:
                return "ë³´í†µ"
            else:
                return "ë‚®ìŒ"

    @staticmethod
    def _generate_assessment(stats: "ProsodySessionStats") -> str:
        """ì¢…í•© í‰ê°€ ë¬¸ìì—´ ìƒì„±"""
        parts = []

        conf = stats.indicator_averages.get("confidence", 0)
        anx = stats.indicator_averages.get("anxiety", 0)
        focus = stats.indicator_averages.get("focus", 0)

        if conf > 0.15:
            parts.append("ìì‹ ê° ìˆëŠ” ìŒì„± í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì˜€ìŠµë‹ˆë‹¤")
        elif conf > 0.08:
            parts.append("ì ì ˆí•œ ìì‹ ê°ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤")
        else:
            parts.append("ìŒì„±ì—ì„œ ìì‹ ê°ì´ ë‹¤ì†Œ ë¶€ì¡±í•˜ê²Œ ëŠê»´ì¡ŒìŠµë‹ˆë‹¤")

        if anx > 0.15:
            parts.append("ë¶ˆì•ˆê°ì´ ìŒì„±ì—ì„œ ê°ì§€ë˜ì—ˆìœ¼ë¯€ë¡œ ê¸´ì¥ ê´€ë¦¬ ì—°ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤")
        elif anx < 0.05:
            parts.append("ê¸´ì¥ì„ ì˜ ê´€ë¦¬í•˜ë©° ì•ˆì •ì ì¸ ìŒì„±ì„ ìœ ì§€í–ˆìŠµë‹ˆë‹¤")

        if focus > 0.15:
            parts.append("ë†’ì€ ì§‘ì¤‘ë ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤")

        if stats.emotional_stability > 0.7:
            parts.append("ì „ë°˜ì ìœ¼ë¡œ ê°ì •ì´ ì•ˆì •ì ì´ì—ˆìŠµë‹ˆë‹¤")
        elif stats.emotional_stability < 0.4:
            parts.append("ê°ì • ë³€í™”ê°€ í° í¸ì´ë¯€ë¡œ ì¼ì •í•œ í†¤ ìœ ì§€ë¥¼ ì—°ìŠµí•˜ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤")

        return ". ".join(parts) + "." if parts else "ìŒì„± ê°ì • ë¶„ì„ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."


# ========== ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ==========
_prosody_service: Optional[HumeProsodyService] = None


def get_prosody_service() -> Optional[HumeProsodyService]:
    """Prosody ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _prosody_service
    if _prosody_service is None:
        _prosody_service = HumeProsodyService()
    return _prosody_service


def is_prosody_available() -> bool:
    """Prosody ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€"""
    svc = get_prosody_service()
    return svc is not None and svc.is_available
