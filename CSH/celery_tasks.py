"""
Celery íƒœìŠ¤í¬ ì •ì˜
==================
AI ë©´ì ‘ ì‹œìŠ¤í…œì˜ ë¹„ë™ê¸° ì‘ì—… íƒœìŠ¤í¬ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.

íƒœìŠ¤í¬ ì¢…ë¥˜:
1. LLM ê¸°ë°˜ ë‹µë³€ í‰ê°€
2. ê°ì • ë¶„ì„ (ë°°ì¹˜)
3. ë¦¬í¬íŠ¸ ìƒì„±
4. TTS ìŒì„± ìƒì„±
5. ì´ë ¥ì„œ RAG ì²˜ë¦¬
6. ì„¸ì…˜ ì •ë¦¬ ë° í†µê³„ ì§‘ê³„

ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜:
- ê° íƒœìŠ¤í¬ ì™„ë£Œ ì‹œ Redis Pub/Subë¥¼ í†µí•´ ì´ë²¤íŠ¸ë¥¼ ë°œí–‰í•©ë‹ˆë‹¤.
- API ì„œë²„ì—ì„œ ì´ë²¤íŠ¸ë¥¼ ìˆ˜ì‹ í•˜ì—¬ WebSocketìœ¼ë¡œ í”„ë¡ íŠ¸ì—”ë“œì— ì „ë‹¬í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import time
import re
from typing import Dict, List, Any, Optional

# JSON Resilience ìœ í‹¸ë¦¬í‹°
from json_utils import parse_evaluation_json
from datetime import datetime, timedelta
from collections import Counter

# ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

from celery_app import celery_app
from celery import shared_task, group, chain, chord
from celery.exceptions import SoftTimeLimitExceeded
from dotenv import load_dotenv

load_dotenv()


# ========== ì´ë²¤íŠ¸ ë°œí–‰ í—¬í¼ (Celery Worker ë™ê¸° ì»¨í…ìŠ¤íŠ¸) ==========

def _publish_event(event_type_str: str, session_id: str = None, data: dict = None, source: str = "celery_worker"):
    """
    Celery íƒœìŠ¤í¬ ë‚´ë¶€ì—ì„œ ì´ë²¤íŠ¸ ë°œí–‰ (ë™ê¸°, Redis Pub/Sub).
    API ì„œë²„ì˜ EventBusê°€ ìˆ˜ì‹ í•˜ì—¬ ë¡œì»¬ í•¸ë“¤ëŸ¬ + WebSocket ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì²˜ë¦¬.
    """
    try:
        import redis
        r = redis.from_url(os.getenv("CELERY_BROKER_URL", "redis://localhost:6379/0"), decode_responses=True)
        event_payload = json.dumps({
            "event_type": event_type_str,
            "event_id": os.urandom(6).hex(),
            "timestamp": datetime.now().isoformat(),
            "source": source,
            "session_id": session_id,
            "data": data or {},
        }, ensure_ascii=False)
        channel = f"interview_events:{event_type_str}"
        r.publish(channel, event_payload)
        r.close()
    except Exception as e:
        print(f"[EventPublish] ì´ë²¤íŠ¸ ë°œí–‰ ì‹¤íŒ¨ ({event_type_str}): {e}")

# ========== ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (Workerì—ì„œ ì‚¬ìš©) ==========
_llm = None
_rag = None
_tts_service = None


def get_llm():
    """LLM ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (Lazy Loading)"""
    global _llm
    if _llm is None:
        try:
            from langchain_ollama import ChatOllama
            DEFAULT_LLM_MODEL = os.getenv("LLM_MODEL", "qwen3:4b")
            DEFAULT_LLM_NUM_CTX = int(os.getenv("LLM_NUM_CTX", "16384"))
            _llm = ChatOllama(model=DEFAULT_LLM_MODEL, temperature=0.3, num_ctx=DEFAULT_LLM_NUM_CTX)
        except Exception as e:
            print(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    return _llm


def get_rag():
    """RAG ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (Lazy Loading)"""
    global _rag
    if _rag is None:
        try:
            from resume_rag import ResumeRAG
            connection_string = os.getenv("POSTGRES_CONNECTION_STRING")
            if connection_string:
                _rag = ResumeRAG(connection_string=connection_string)
        except Exception as e:
            print(f"RAG ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    return _rag


def get_tts_service():
    """TTS ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (Lazy Loading)"""
    global _tts_service
    if _tts_service is None:
        try:
            from hume_tts_service import HumeInterviewerVoice
            _tts_service = HumeInterviewerVoice()
        except Exception as e:
            print(f"TTS ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    return _tts_service


# ========== LLM í‰ê°€ íƒœìŠ¤í¬ ==========

EVALUATION_PROMPT = """ë‹¹ì‹ ì€ IT ê¸°ì—…ì˜ 30ë…„ì°¨ ìˆ˜ì„ ê°œë°œì ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ì§€ì›ìì˜ ë‹µë³€ì„ ë¶„ì„í•˜ê³  í‰ê°€í•´ì£¼ì„¸ìš”.

[í‰ê°€ ê¸°ì¤€]
1. ë¬¸ì œ í•´ê²°ë ¥ (1-5ì ): ì§€ì›ìê°€ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ ì ‘ê·¼í•˜ê³  í•´ê²°í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
2. ë…¼ë¦¬ì„± (1-5ì ): ë‹µë³€ì˜ ë…¼ë¦¬ì  íë¦„ì´ ì¼ê´€ì„± ìˆëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
3. ê¸°ìˆ  ì´í•´ë„ (1-5ì ): ê¸°ìˆ ì  ê°œë…ì— ëŒ€í•œ ì´í•´ê°€ ì •í™•í•œê°€?
4. STAR ê¸°ë²• (1-5ì ): ìƒí™©-ê³¼ì œ-í–‰ë™-ê²°ê³¼ êµ¬ì¡°ë¡œ ë‹µë³€í–ˆëŠ”ê°€?
5. ì˜ì‚¬ì†Œí†µëŠ¥ë ¥ (1-5ì ): ë‹µë³€ì´ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?

[í•©ê²© ì¶”ì²œ ê¸°ì¤€]
- "í•©ê²©": ì´ì  20ì  ì´ìƒì´ê³  ëª¨ë“  í•­ëª© 3ì  ì´ìƒ
- "ë³´ë¥˜": ì´ì  15~19ì ì´ê±°ë‚˜ ì¼ë¶€ í•­ëª© 2ì 
- "ë¶ˆí•©ê²©": ì´ì  14ì  ì´í•˜ì´ê±°ë‚˜ 2ê°œ ì´ìƒ í•­ëª© 2ì  ì´í•˜

[ì¶œë ¥ í˜•ì‹ - ë°˜ë“œì‹œ JSONìœ¼ë¡œ ì‘ë‹µ]
{{
    "scores": {{
        "problem_solving": ìˆ«ì,
        "logic": ìˆ«ì,
        "technical": ìˆ«ì,
        "star": ìˆ«ì,
        "communication": ìˆ«ì
    }},
    "total_score": ìˆ«ì(25ì  ë§Œì ),
    "recommendation": "í•©ê²©" ë˜ëŠ” "ë³´ë¥˜" ë˜ëŠ” "ë¶ˆí•©ê²©",
    "recommendation_reason": "ì¶”ì²œ ì‚¬ìœ ë¥¼ í•œ ì¤„ë¡œ ì‘ì„±",
    "strengths": ["ê°•ì 1", "ê°•ì 2"],
    "improvements": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
    "brief_feedback": "í•œ ì¤„ í”¼ë“œë°±"
}}"""


@celery_app.task(
    bind=True,
    name="celery_tasks.evaluate_answer_task",
    max_retries=3,
    default_retry_delay=5,
    soft_time_limit=60,
    time_limit=90
)
def evaluate_answer_task(
    self,
    session_id: str,
    question: str,
    answer: str,
    resume_context: str = ""
) -> Dict:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ í‰ê°€ (ë¹„ë™ê¸° íƒœìŠ¤í¬)
    
    Args:
        session_id: ì„¸ì…˜ ID
        question: ë©´ì ‘ ì§ˆë¬¸
        answer: ì‚¬ìš©ì ë‹µë³€
        resume_context: ì´ë ¥ì„œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ (RAGì—ì„œ ì¶”ì¶œ)
    
    Returns:
        í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    task_id = self.request.id
    print(f"[Task {task_id}] ë‹µë³€ í‰ê°€ ì‹œì‘ - Session: {session_id}")
    
    try:
        llm = get_llm()
        if not llm:
            return _default_evaluation("LLM ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€")
        
        from langchain_core.messages import HumanMessage, SystemMessage
        
        # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        rag_section = ""
        if resume_context:
            rag_section = f"\n[ì°¸ê³ : ì´ë ¥ì„œ ë‚´ìš©]\n{resume_context}"
        
        messages = [
            SystemMessage(content=EVALUATION_PROMPT),
            HumanMessage(content=f"""
[ì§ˆë¬¸]
{question}

[ì§€ì›ì ë‹µë³€]
{answer}
{rag_section}

ìœ„ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
""")
        ]
        
        response = llm.invoke(messages)
        response_text = response.content
        
        # JSON Resilience íŒŒì‹±
        evaluation = parse_evaluation_json(response_text, context=f"celery_evaluate_answer[{task_id}]")
        evaluation["task_id"] = task_id
        evaluation["evaluated_at"] = datetime.now().isoformat()
        print(f"[Task {task_id}] í‰ê°€ ì™„ë£Œ - ì ìˆ˜: {evaluation.get('total_score', 'N/A')}")

        # ğŸ“¤ ì´ë²¤íŠ¸ ë°œí–‰: í‰ê°€ ì™„ë£Œ
        _publish_event(
            "evaluation.completed",
            session_id=session_id,
            data={"task_id": task_id, "score": evaluation.get("total_score"), "feedback": evaluation.get("brief_feedback", "")},
        )
        return evaluation
            
    except SoftTimeLimitExceeded:
        print(f"[Task {task_id}] ì‹œê°„ ì´ˆê³¼")
        return _default_evaluation("í‰ê°€ ì‹œê°„ ì´ˆê³¼")
        
    except Exception as e:
        print(f"[Task {task_id}] í‰ê°€ ì˜¤ë¥˜: {e}")
        # ì¬ì‹œë„
        if self.request.retries < self.max_retries:
            raise self.retry(exc=e)
        return _default_evaluation(str(e))


def _default_evaluation(reason: str = "") -> Dict:
    """ê¸°ë³¸ í‰ê°€ ê²°ê³¼ ë°˜í™˜"""
    return {
        "scores": {
            "problem_solving": 3,
            "logic": 3,
            "technical": 3,
            "star": 3,
            "communication": 3
        },
        "total_score": 15,
        "recommendation": "ë³´ë¥˜",
        "recommendation_reason": reason or "LLM ì„œë¹„ìŠ¤ ë¯¸ì‚¬ìš©ìœ¼ë¡œ ê¸°ë³¸ í‰ê°€ ì ìš©",
        "strengths": ["ë‹µë³€ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤."],
        "improvements": ["ë” êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ë³´ì„¸ìš”."],
        "brief_feedback": reason or "ë‹µë³€ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.",
        "fallback": True
    }


@celery_app.task(
    bind=True,
    name="celery_tasks.batch_evaluate_task",
    soft_time_limit=300,
    time_limit=360
)
def batch_evaluate_task(
    self,
    session_id: str,
    qa_pairs: List[Dict]
) -> List[Dict]:
    """
    ì—¬ëŸ¬ ë‹µë³€ì„ ë°°ì¹˜ë¡œ í‰ê°€
    
    Args:
        session_id: ì„¸ì…˜ ID
        qa_pairs: [{"question": "...", "answer": "..."}, ...] ë¦¬ìŠ¤íŠ¸
    
    Returns:
        í‰ê°€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    task_id = self.request.id
    print(f"[Task {task_id}] ë°°ì¹˜ í‰ê°€ ì‹œì‘ - {len(qa_pairs)}ê°œ ë‹µë³€")
    
    results = []
    for i, pair in enumerate(qa_pairs):
        try:
            result = evaluate_answer_task.apply(
                args=[session_id, pair["question"], pair["answer"], pair.get("resume_context", "")]
            ).get(timeout=90)
            result["question_index"] = i
            results.append(result)
        except Exception as e:
            print(f"[Task {task_id}] ë°°ì¹˜ í‰ê°€ {i} ì˜¤ë¥˜: {e}")
            results.append({**_default_evaluation(str(e)), "question_index": i})
    
    print(f"[Task {task_id}] ë°°ì¹˜ í‰ê°€ ì™„ë£Œ - {len(results)}ê°œ ê²°ê³¼")
    return results


# ========== ê°ì • ë¶„ì„ íƒœìŠ¤í¬ ==========

@celery_app.task(
    bind=True,
    name="celery_tasks.analyze_emotion_task",
    soft_time_limit=30,
    time_limit=45
)
def analyze_emotion_task(
    self,
    session_id: str,
    image_data: str  # Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
) -> Dict:
    """
    ì´ë¯¸ì§€ì—ì„œ ê°ì • ë¶„ì„ ìˆ˜í–‰ (ë¹„ë™ê¸° íƒœìŠ¤í¬)
    
    Args:
        session_id: ì„¸ì…˜ ID
        image_data: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„°
    
    Returns:
        ê°ì • ë¶„ì„ ê²°ê³¼
    """
    task_id = self.request.id
    
    try:
        import base64
        import numpy as np
        import cv2
        from deepface import DeepFace
        
        # Base64 ë””ì½”ë”©
        image_bytes = base64.b64decode(image_data)
        nparr = np.frombuffer(image_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if img is None:
            raise ValueError("ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")
        
        # DeepFace ë¶„ì„
        result = DeepFace.analyze(img, actions=["emotion"], enforce_detection=False)
        item = result[0] if isinstance(result, list) else result
        
        scores = item.get("emotion", {})
        keys_map = {
            "happy": "happy", "sad": "sad", "angry": "angry",
            "surprise": "surprise", "fear": "fear",
            "disgust": "disgust", "neutral": "neutral"
        }
        
        raw = {k: float(scores.get(src, 0.0)) for k, src in keys_map.items()}
        total = sum(raw.values()) or 1.0
        probabilities = {k: round(v / total, 4) for k, v in raw.items()}
        
        result = {
            "session_id": session_id,
            "dominant_emotion": item.get("dominant_emotion"),
            "probabilities": probabilities,
            "raw_scores": raw,
            "analyzed_at": datetime.now().isoformat(),
            "task_id": task_id
        }

        # ğŸ“¤ ì´ë²¤íŠ¸ ë°œí–‰: ê°ì • ë¶„ì„ ì™„ë£Œ
        _publish_event(
            "emotion.analyzed",
            session_id=session_id,
            data={"dominant_emotion": result["dominant_emotion"], "probabilities": probabilities, "confidence": max(probabilities.values()) if probabilities else 0},
        )
        return result
        
    except Exception as e:
        print(f"[Task {task_id}] ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {
            "session_id": session_id,
            "dominant_emotion": "neutral",
            "probabilities": {"neutral": 1.0},
            "error": str(e),
            "task_id": task_id
        }


@celery_app.task(
    bind=True,
    name="celery_tasks.batch_emotion_analysis_task",
    soft_time_limit=120,
    time_limit=180
)
def batch_emotion_analysis_task(
    self,
    session_id: str,
    image_data_list: List[str]
) -> Dict:
    """
    ì—¬ëŸ¬ ì´ë¯¸ì§€ì˜ ê°ì •ì„ ë°°ì¹˜ë¡œ ë¶„ì„í•˜ê³  í†µê³„ ìƒì„±
    
    Args:
        session_id: ì„¸ì…˜ ID
        image_data_list: Base64 ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ê°ì • ë¶„ì„ í†µê³„
    """
    task_id = self.request.id
    print(f"[Task {task_id}] ë°°ì¹˜ ê°ì • ë¶„ì„ ì‹œì‘ - {len(image_data_list)}ê°œ ì´ë¯¸ì§€")
    
    results = []
    emotion_counts = Counter()
    emotion_scores = {"happy": [], "sad": [], "angry": [], "surprise": [], 
                      "fear": [], "disgust": [], "neutral": []}
    
    for i, image_data in enumerate(image_data_list):
        try:
            result = analyze_emotion_task.apply(
                args=[session_id, image_data]
            ).get(timeout=30)
            
            results.append(result)
            dominant = result.get("dominant_emotion", "neutral")
            emotion_counts[dominant] += 1
            
            for emo, prob in result.get("probabilities", {}).items():
                emotion_scores[emo].append(prob)
                
        except Exception as e:
            print(f"[Task {task_id}] ì´ë¯¸ì§€ {i} ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    # í†µê³„ ê³„ì‚°
    avg_scores = {}
    for emo, scores in emotion_scores.items():
        if scores:
            avg_scores[emo] = round(sum(scores) / len(scores), 4)
        else:
            avg_scores[emo] = 0.0
    
    return {
        "session_id": session_id,
        "total_analyzed": len(results),
        "emotion_distribution": dict(emotion_counts),
        "average_scores": avg_scores,
        "dominant_overall": emotion_counts.most_common(1)[0][0] if emotion_counts else "neutral",
        "task_id": task_id
    }


# ========== ë¦¬í¬íŠ¸ ìƒì„± íƒœìŠ¤í¬ ==========

STAR_KEYWORDS = {
    'situation': ['ìƒí™©', 'ë°°ê²½', 'ë‹¹ì‹œ', 'ê·¸ë•Œ', 'í™˜ê²½', 'ìƒíƒœ', 'ë¬¸ì œ', 'ì´ìŠˆ', 'ê³¼ì œ'],
    'task': ['ëª©í‘œ', 'ê³¼ì œ', 'ì„ë¬´', 'ì—­í• ', 'ë‹´ë‹¹', 'ì±…ì„', 'í•´ì•¼ í• ', 'ëª©ì ', 'ë¯¸ì…˜'],
    'action': ['í–‰ë™', 'ìˆ˜í–‰', 'ì‹¤í–‰', 'ì²˜ë¦¬', 'í•´ê²°', 'ê°œë°œ', 'êµ¬í˜„', 'ì ìš©', 'ì§„í–‰', 'ì‹œë„', 'ë…¸ë ¥'],
    'result': ['ê²°ê³¼', 'ì„±ê³¼', 'ë‹¬ì„±', 'ì™„ë£Œ', 'ê°œì„ ', 'í–¥ìƒ', 'ì¦ê°€', 'ê°ì†Œ', 'íš¨ê³¼', 'ì„±ê³µ']
}

TECH_KEYWORDS = [
    'python', 'java', 'javascript', 'react', 'vue', 'django', 'flask', 'spring',
    'aws', 'azure', 'docker', 'kubernetes', 'sql', 'mongodb', 'postgresql',
    'git', 'ci/cd', 'api', 'rest', 'machine learning', 'deep learning',
    'tensorflow', 'pytorch', 'pandas', 'LLM', 'RAG', 'LangChain', 'FastAPI'
]


@celery_app.task(
    bind=True,
    name="celery_tasks.generate_report_task",
    soft_time_limit=120,
    time_limit=180
)
def generate_report_task(
    self,
    session_id: str,
    chat_history: List[Dict],
    evaluations: List[Dict],
    emotion_stats: Optional[Dict] = None,
    prosody_stats: Optional[Dict] = None
) -> Dict:
    """
    ë©´ì ‘ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± (ë¹„ë™ê¸° íƒœìŠ¤í¬)
    
    Args:
        session_id: ì„¸ì…˜ ID
        chat_history: ëŒ€í™” ê¸°ë¡
        evaluations: í‰ê°€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        emotion_stats: ê°ì • ë¶„ì„ í†µê³„ (DeepFace)
        prosody_stats: ìŒì„± ê°ì • ë¶„ì„ í†µê³„ (Hume Prosody)
    
    Returns:
        ì¢…í•© ë¦¬í¬íŠ¸
    """
    task_id = self.request.id
    print(f"[Task {task_id}] ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ - Session: {session_id}")
    
    try:
        # ì‚¬ìš©ì ë‹µë³€ ì¶”ì¶œ
        answers = [msg["content"] for msg in chat_history if msg["role"] == "user"]
        
        # STAR ë¶„ì„
        star_analysis = _analyze_star_structure(answers)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = _extract_keywords(answers)
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = {
            'total_answers': len(answers),
            'avg_length': round(sum(len(a) for a in answers) / len(answers), 1) if answers else 0,
            'total_chars': sum(len(a) for a in answers)
        }
        
        # í‰ê°€ ì ìˆ˜ ì§‘ê³„
        if evaluations:
            avg_scores = {"problem_solving": 0, "logic": 0, "technical": 0, "star": 0, "communication": 0}
            for ev in evaluations:
                for key in avg_scores:
                    avg_scores[key] += ev.get("scores", {}).get(key, 0)
            for key in avg_scores:
                avg_scores[key] = round(avg_scores[key] / len(evaluations), 1)
            total_avg = round(sum(avg_scores.values()) / 5, 1)
        else:
            avg_scores = {}
            total_avg = 0
        
        # ì „ì²´ ê°•ì /ê°œì„ ì  ì§‘ê³„
        all_strengths = []
        all_improvements = []
        for ev in evaluations:
            all_strengths.extend(ev.get("strengths", []))
            all_improvements.extend(ev.get("improvements", []))
        
        strength_counts = Counter(all_strengths)
        improvement_counts = Counter(all_improvements)
        
        report = {
            "session_id": session_id,
            "generated_at": datetime.now().isoformat(),
            "task_id": task_id,
            "summary": {
                "total_questions": len([m for m in chat_history if m["role"] == "assistant"]),
                "total_answers": metrics['total_answers'],
                "average_answer_length": metrics['avg_length'],
                "interview_duration": "N/A"  # ì„¸ì…˜ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨
            },
            "star_analysis": {
                "situation_score": min(star_analysis['situation']['count'] * 20, 100),
                "task_score": min(star_analysis['task']['count'] * 20, 100),
                "action_score": min(star_analysis['action']['count'] * 20, 100),
                "result_score": min(star_analysis['result']['count'] * 20, 100),
                "overall_star_score": _calculate_star_score(star_analysis)
            },
            "evaluation_scores": {
                "average_by_criteria": avg_scores,
                "total_average": total_avg,
                "max_score": 25
            },
            "keywords": keywords,
            "top_strengths": strength_counts.most_common(5),
            "top_improvements": improvement_counts.most_common(5),
            "emotion_analysis": emotion_stats or {},
            "prosody_analysis": prosody_stats or {},
            "recommendations": _generate_recommendations(avg_scores, star_analysis),
            "grade": _calculate_grade(total_avg, star_analysis)
        }
        
        print(f"[Task {task_id}] ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ - ë“±ê¸‰: {report['grade']}")

        # ğŸ“¤ ì´ë²¤íŠ¸ ë°œí–‰: ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ
        _publish_event(
            "report.generated",
            session_id=session_id,
            data={"task_id": task_id, "grade": report.get("grade"), "total_average": total_avg},
        )
        return report
        
    except Exception as e:
        print(f"[Task {task_id}] ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        _publish_event("system.error", session_id=session_id, data={"error": str(e), "source": "generate_report_task"})
        return {
            "session_id": session_id,
            "error": str(e),
            "task_id": task_id
        }


def _analyze_star_structure(answers: List[str]) -> Dict:
    """STAR ê¸°ë²• ë¶„ì„"""
    star_analysis = {key: {'count': 0, 'examples': []} for key in STAR_KEYWORDS}
    
    for answer in answers:
        answer_lower = answer.lower()
        for element, keywords in STAR_KEYWORDS.items():
            for keyword in keywords:
                if keyword in answer_lower:
                    star_analysis[element]['count'] += 1
                    break
    
    return star_analysis


def _extract_keywords(answers: List[str]) -> Dict:
    """í‚¤ì›Œë“œ ì¶”ì¶œ"""
    all_text = ' '.join(answers).lower()
    
    found_tech = []
    for kw in TECH_KEYWORDS:
        if kw.lower() in all_text:
            count = all_text.count(kw.lower())
            found_tech.append((kw, count))
    
    found_tech.sort(key=lambda x: x[1], reverse=True)
    
    return {
        'tech_keywords': found_tech[:10],
        'total_tech_mentions': sum(c for _, c in found_tech)
    }


def _calculate_star_score(star_analysis: Dict) -> int:
    """STAR ì¢…í•© ì ìˆ˜ ê³„ì‚° (100ì  ë§Œì )"""
    total = 0
    for element in ['situation', 'task', 'action', 'result']:
        count = star_analysis[element]['count']
        total += min(count * 25, 25)  # ê° ìš”ì†Œ ìµœëŒ€ 25ì 
    return total


def _generate_recommendations(avg_scores: Dict, star_analysis: Dict) -> List[str]:
    """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
    recommendations = []
    
    if avg_scores.get('problem_solving', 0) < 3:
        recommendations.append("ë‹µë³€ì— êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ì‚¬ë¡€ë¥¼ ë” í¬í•¨í•´ë³´ì„¸ìš”.")
    
    if avg_scores.get('star', 0) < 3:
        recommendations.append("STAR ê¸°ë²•(ìƒí™©-ê³¼ì œ-í–‰ë™-ê²°ê³¼)ì„ í™œìš©í•´ êµ¬ì¡°ì ìœ¼ë¡œ ë‹µë³€í•´ë³´ì„¸ìš”.")
    
    if star_analysis.get('result', {}).get('count', 0) < 2:
        recommendations.append("í”„ë¡œì íŠ¸ë‚˜ ê²½í—˜ì˜ ê²°ê³¼ì™€ ì„±ê³¼ë¥¼ ë” ê°•ì¡°í•´ë³´ì„¸ìš”.")
    
    if avg_scores.get('technical', 0) < 3:
        recommendations.append("ê¸°ìˆ ì  ìš©ì–´ì™€ ê°œë…ì„ ì •í™•í•˜ê²Œ ì‚¬ìš©í•˜ë„ë¡ ì—°ìŠµí•´ë³´ì„¸ìš”.")
    
    if not recommendations:
        recommendations.append("ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ë©´ì ‘ì´ì—ˆìŠµë‹ˆë‹¤! ìì‹ ê°ì„ ê°€ì§€ì„¸ìš”.")
    
    return recommendations


def _calculate_grade(total_avg: float, star_analysis: Dict) -> str:
    """ë“±ê¸‰ ê³„ì‚°"""
    star_score = _calculate_star_score(star_analysis)
    combined = (total_avg / 5 * 50) + (star_score / 2)  # 100ì  ë§Œì ìœ¼ë¡œ í™˜ì‚°
    
    if combined >= 90:
        return "S"
    elif combined >= 80:
        return "A"
    elif combined >= 70:
        return "B"
    elif combined >= 60:
        return "C"
    else:
        return "D"


# ========== TTS ìƒì„± íƒœìŠ¤í¬ ==========

@celery_app.task(
    bind=True,
    name="celery_tasks.generate_tts_task",
    soft_time_limit=30,
    time_limit=45,
    max_retries=2
)
def generate_tts_task(
    self,
    text: str,
    voice_config: Optional[Dict] = None
) -> Dict:
    """
    í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ (ë¹„ë™ê¸° íƒœìŠ¤í¬)
    
    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        voice_config: ìŒì„± ì„¤ì • (ì„ íƒì‚¬í•­)
    
    Returns:
        ìŒì„± íŒŒì¼ ê²½ë¡œ ë˜ëŠ” Base64 ë°ì´í„°
    """
    task_id = self.request.id
    print(f"[Task {task_id}] TTS ìƒì„± ì‹œì‘ - í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
    
    try:
        import asyncio
        
        tts_service = get_tts_service()
        if not tts_service:
            return {"error": "TTS ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€", "task_id": task_id}
        
        # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            audio_url = loop.run_until_complete(tts_service.speak(text))
        finally:
            loop.close()
        
        return {
            "audio_url": audio_url,
            "text_length": len(text),
            "generated_at": datetime.now().isoformat(),
            "task_id": task_id
        }
        
    except Exception as e:
        print(f"[Task {task_id}] TTS ìƒì„± ì˜¤ë¥˜: {e}")
        if self.request.retries < self.max_retries:
            raise self.retry(exc=e)
        return {"error": str(e), "task_id": task_id}


# ========== RAG ì²˜ë¦¬ íƒœìŠ¤í¬ ==========

@celery_app.task(
    bind=True,
    name="celery_tasks.process_resume_task",
    soft_time_limit=180,
    time_limit=240
)
def process_resume_task(
    self,
    session_id: str,
    pdf_path: str
) -> Dict:
    """
    ì´ë ¥ì„œ PDFë¥¼ ì²˜ë¦¬í•˜ê³  ë²¡í„° ì €ì¥ì†Œì— ì¸ë±ì‹± (ë¹„ë™ê¸° íƒœìŠ¤í¬)
    
    Args:
        session_id: ì„¸ì…˜ ID
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
    
    Returns:
        ì²˜ë¦¬ ê²°ê³¼
    """
    task_id = self.request.id
    print(f"[Task {task_id}] ì´ë ¥ì„œ ì²˜ë¦¬ ì‹œì‘ - Session: {session_id}")
    
    try:
        if not os.path.exists(pdf_path):
            return {"error": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "task_id": task_id}
        
        rag = get_rag()
        if not rag:
            return {"error": "RAG ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€", "task_id": task_id}
        
        # PDF ì¸ë±ì‹±
        rag.load_and_index_pdf(pdf_path)

        # ğŸ“¤ ì´ë²¤íŠ¸ ë°œí–‰: ì´ë ¥ì„œ ì¸ë±ì‹± ì™„ë£Œ
        _publish_event(
            "resume.indexed",
            session_id=session_id,
            data={"pdf_path": pdf_path, "task_id": task_id},
        )
        return {
            "session_id": session_id,
            "status": "success",
            "pdf_path": pdf_path,
            "indexed_at": datetime.now().isoformat(),
            "task_id": task_id
        }
        
    except Exception as e:
        print(f"[Task {task_id}] ì´ë ¥ì„œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {
            "session_id": session_id,
            "status": "error",
            "error": str(e),
            "task_id": task_id
        }


@celery_app.task(
    bind=True,
    name="celery_tasks.retrieve_resume_context_task",
    soft_time_limit=30,
    time_limit=45
)
def retrieve_resume_context_task(
    self,
    query: str,
    top_k: int = 3
) -> Dict:
    """
    ì´ë ¥ì„œì—ì„œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ë¹„ë™ê¸° íƒœìŠ¤í¬)
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬ (ë‹µë³€ ë‚´ìš©)
        top_k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
    
    Returns:
        ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸
    """
    task_id = self.request.id
    
    try:
        rag = get_rag()
        if not rag:
            return {"context": "", "task_id": task_id}
        
        retriever = rag.get_retriever()
        docs = retriever.invoke(query)
        
        if docs:
            context = "\n".join([d.page_content for d in docs[:top_k]])
            return {
                "context": context,
                "num_docs": len(docs[:top_k]),
                "task_id": task_id
            }
        
        return {"context": "", "num_docs": 0, "task_id": task_id}
        
    except Exception as e:
        print(f"[Task {task_id}] ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return {"context": "", "error": str(e), "task_id": task_id}


# ========== ìœ ì§€ë³´ìˆ˜ íƒœìŠ¤í¬ ==========

@celery_app.task(name="celery_tasks.cleanup_sessions_task")
def cleanup_sessions_task() -> Dict:
    """ë§Œë£Œëœ ì„¸ì…˜ ì •ë¦¬"""
    print("[Cleanup] ì„¸ì…˜ ì •ë¦¬ ì‘ì—… ì‹œì‘")
    
    # Redisì—ì„œ ë§Œë£Œëœ ì„¸ì…˜ ì •ë¦¬
    try:
        import redis
        redis_url = os.getenv("REDIS_URL", "redis://localhost:6379/0")
        r = redis.from_url(redis_url)
        
        # 24ì‹œê°„ ì´ìƒ ëœ ì„¸ì…˜ í‚¤ ì‚­ì œ
        cleaned = 0
        pattern = "session:*"
        for key in r.scan_iter(pattern):
            ttl = r.ttl(key)
            if ttl == -1:  # TTL ì—†ëŠ” í‚¤
                r.expire(key, 86400)  # 24ì‹œê°„ TTL ì„¤ì •
            elif ttl < 0:
                r.delete(key)
                cleaned += 1
        
        print(f"[Cleanup] {cleaned}ê°œ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ")
        return {"cleaned_sessions": cleaned, "timestamp": datetime.now().isoformat()}
        
    except Exception as e:
        print(f"[Cleanup] ì˜¤ë¥˜: {e}")
        return {"error": str(e)}


@celery_app.task(name="celery_tasks.aggregate_statistics_task")
def aggregate_statistics_task() -> Dict:
    """í†µê³„ ì§‘ê³„ ì‘ì—…"""
    print("[Stats] í†µê³„ ì§‘ê³„ ì‘ì—… ì‹œì‘")
    
    try:
        import redis
        redis_url = os.getenv("REDIS_URL", "redis://localhost:6379/0")
        r = redis.from_url(redis_url)
        
        # ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ í†µê³„
        today = datetime.now().strftime("%Y-%m-%d")
        
        # ê°„ë‹¨í•œ í†µê³„ ì €ì¥
        stats = {
            "date": today,
            "aggregated_at": datetime.now().isoformat()
        }
        
        r.hset(f"stats:{today}", mapping=stats)
        r.expire(f"stats:{today}", 604800)  # 7ì¼ê°„ ìœ ì§€
        
        print(f"[Stats] í†µê³„ ì§‘ê³„ ì™„ë£Œ - {today}")
        return stats
        
    except Exception as e:
        print(f"[Stats] ì˜¤ë¥˜: {e}")
        return {"error": str(e)}


# ========== ë³µí•© ì›Œí¬í”Œë¡œìš° íƒœìŠ¤í¬ ==========

@celery_app.task(
    bind=True,
    name="celery_tasks.complete_interview_workflow_task"
)
def complete_interview_workflow_task(
    self,
    session_id: str,
    chat_history: List[Dict],
    emotion_images: List[str] = None
) -> Dict:
    """
    ë©´ì ‘ ì™„ë£Œ í›„ ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    (í‰ê°€ + ê°ì • ë¶„ì„ + ë¦¬í¬íŠ¸ ìƒì„±)
    
    Args:
        session_id: ì„¸ì…˜ ID
        chat_history: ëŒ€í™” ê¸°ë¡
        emotion_images: ê°ì • ë¶„ì„ìš© ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (ì„ íƒ)
    
    Returns:
        ìµœì¢… ê²°ê³¼
    """
    task_id = self.request.id
    print(f"[Task {task_id}] ë©´ì ‘ ì™„ë£Œ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
    
    try:
        # 1. ëª¨ë“  QA ìŒ ì¶”ì¶œ
        qa_pairs = []
        current_question = None
        for msg in chat_history:
            if msg["role"] == "assistant":
                current_question = msg["content"]
            elif msg["role"] == "user" and current_question:
                qa_pairs.append({
                    "question": current_question,
                    "answer": msg["content"]
                })
                current_question = None
        
        # 2. ë°°ì¹˜ í‰ê°€ ì‹¤í–‰
        evaluations = batch_evaluate_task.apply(
            args=[session_id, qa_pairs]
        ).get(timeout=360)
        
        # 3. ê°ì • ë¶„ì„ (ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš°)
        emotion_stats = None
        if emotion_images:
            emotion_stats = batch_emotion_analysis_task.apply(
                args=[session_id, emotion_images]
            ).get(timeout=180)
        
        # 4. ë¦¬í¬íŠ¸ ìƒì„±
        report = generate_report_task.apply(
            args=[session_id, chat_history, evaluations, emotion_stats]
        ).get(timeout=180)
        
        print(f"[Task {task_id}] ë©´ì ‘ ì™„ë£Œ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ")

        # ğŸ“¤ ì´ë²¤íŠ¸ ë°œí–‰: ì›Œí¬í”Œë¡œìš° ì™„ë£Œ (ë¦¬í¬íŠ¸ í¬í•¨)
        _publish_event(
            "report.generated",
            session_id=session_id,
            data={
                "task_id": task_id,
                "grade": report.get("grade") if isinstance(report, dict) else None,
                "workflow": True,
            },
        )
        return {
            "session_id": session_id,
            "evaluations": evaluations,
            "emotion_stats": emotion_stats,
            "report": report,
            "workflow_task_id": task_id
        }
        
    except Exception as e:
        print(f"[Task {task_id}] ì›Œí¬í”Œë¡œìš° ì˜¤ë¥˜: {e}")
        _publish_event("system.error", session_id=session_id, data={"error": str(e), "source": "complete_interview_workflow_task"})
        return {
            "session_id": session_id,
            "error": str(e),
            "workflow_task_id": task_id
        }


# ========== TTS í”„ë¦¬í˜ì¹­ íƒœìŠ¤í¬ ==========

@celery_app.task(
    bind=True,
    name="celery_tasks.prefetch_tts_task",
    soft_time_limit=60,
    time_limit=90
)
def prefetch_tts_task(
    self,
    session_id: str,
    texts: List[str]
) -> Dict:
    """
    ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì˜ TTSë¥¼ ë¯¸ë¦¬ ìƒì„± (í”„ë¦¬í˜ì¹­)
    
    Args:
        session_id: ì„¸ì…˜ ID
        texts: TTSë¡œ ë³€í™˜í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        ìƒì„±ëœ ì˜¤ë””ì˜¤ URL ë”•ì…”ë„ˆë¦¬
    """
    task_id = self.request.id
    print(f"[Task {task_id}] TTS í”„ë¦¬í˜ì¹­ ì‹œì‘ - {len(texts)}ê°œ í…ìŠ¤íŠ¸")
    
    results = {}
    import asyncio
    
    tts_service = get_tts_service()
    if not tts_service:
        return {"error": "TTS ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€", "task_id": task_id}
    
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    try:
        for i, text in enumerate(texts):
            try:
                audio_url = loop.run_until_complete(tts_service.speak(text))
                results[f"text_{i}"] = {
                    "text": text[:50] + "..." if len(text) > 50 else text,
                    "audio_url": audio_url,
                    "success": True
                }
            except Exception as e:
                results[f"text_{i}"] = {
                    "text": text[:50] + "..." if len(text) > 50 else text,
                    "error": str(e),
                    "success": False
                }
    finally:
        loop.close()
    
    print(f"[Task {task_id}] TTS í”„ë¦¬í˜ì¹­ ì™„ë£Œ - ì„±ê³µ: {sum(1 for r in results.values() if r.get('success'))}/{len(texts)}")
    return {
        "session_id": session_id,
        "results": results,
        "task_id": task_id
    }


# ========== ì‹¤ì‹œê°„ LLM ì§ˆë¬¸ ìƒì„± íƒœìŠ¤í¬ ==========

INTERVIEWER_PROMPT_CELERY = """ë‹¹ì‹ ì€ IT ê¸°ì—…ì˜ 30ë…„ì°¨ ìˆ˜ì„ ê°œë°œì ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì ì¸ ë©´ì ‘ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.
ì§ˆë¬¸ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ í•´ì£¼ì„¸ìš”."""


@celery_app.task(
    bind=True,
    name="celery_tasks.generate_question_task",
    soft_time_limit=30,
    time_limit=45,
    max_retries=2
)
def generate_question_task(
    self,
    session_id: str,
    user_answer: str,
    chat_history: List[Dict],
    question_count: int
) -> Dict:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (ë¹„ë™ê¸° íƒœìŠ¤í¬)
    
    Args:
        session_id: ì„¸ì…˜ ID
        user_answer: ì‚¬ìš©ìì˜ ì´ì „ ë‹µë³€
        chat_history: ëŒ€í™” ê¸°ë¡
        question_count: í˜„ì¬ ì§ˆë¬¸ ìˆ˜
    
    Returns:
        ìƒì„±ëœ ì§ˆë¬¸
    """
    task_id = self.request.id
    print(f"[Task {task_id}] ì§ˆë¬¸ ìƒì„± ì‹œì‘ - Session: {session_id}")
    
    try:
        llm = get_llm()
        if not llm:
            return {
                "question": "ê·¸ ê²½í—˜ì—ì„œ ê°€ì¥ ì–´ë ¤ì› ë˜ ì ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?",
                "fallback": True,
                "task_id": task_id
            }
        
        from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
        
        messages = [SystemMessage(content=INTERVIEWER_PROMPT_CELERY)]
        
        # ëŒ€í™” ê¸°ë¡ ì¶”ê°€
        for msg in chat_history[-6:]:  # ìµœê·¼ 6ê°œë§Œ
            if msg["role"] == "assistant":
                messages.append(AIMessage(content=msg["content"]))
            elif msg["role"] == "user":
                messages.append(HumanMessage(content=msg["content"]))
        
        # ì§ˆë¬¸ ìƒì„± ìš”ì²­
        question_prompt = f"""[í˜„ì¬ ìƒí™©]
- ì§„í–‰ëœ ì§ˆë¬¸ ìˆ˜: {question_count}
- ì§€ì›ìì˜ ë§ˆì§€ë§‰ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
- ì§ˆë¬¸ë§Œ ì‘ì„±í•˜ì„¸ìš”."""
        
        messages.append(HumanMessage(content=question_prompt))
        
        response = llm.invoke(messages)
        question = response.content.strip()
        
        print(f"[Task {task_id}] ì§ˆë¬¸ ìƒì„± ì™„ë£Œ")
        return {
            "question": question,
            "session_id": session_id,
            "task_id": task_id
        }
        
    except Exception as e:
        print(f"[Task {task_id}] ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")
        if self.request.retries < self.max_retries:
            raise self.retry(exc=e)
        return {
            "question": "ê·¸ ê²½í—˜ì—ì„œ ê°€ì¥ ì–´ë ¤ì› ë˜ ì ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?",
            "fallback": True,
            "error": str(e),
            "task_id": task_id
        }


# ========== Redis ì„¸ì…˜ ì €ì¥ íƒœìŠ¤í¬ ==========

@celery_app.task(name="celery_tasks.save_session_to_redis_task")
def save_session_to_redis_task(
    session_id: str,
    session_data: Dict
) -> Dict:
    """
    ì„¸ì…˜ ë°ì´í„°ë¥¼ Redisì— ì €ì¥ (ë°±ì—…ìš©)
    
    Args:
        session_id: ì„¸ì…˜ ID
        session_data: ì„¸ì…˜ ë°ì´í„°
    
    Returns:
        ì €ì¥ ê²°ê³¼
    """
    try:
        import redis
        redis_url = os.getenv("REDIS_URL", "redis://localhost:6379/0")
        r = redis.from_url(redis_url)
        
        key = f"session:{session_id}"
        r.hset(key, mapping={
            "data": json.dumps(session_data, ensure_ascii=False, default=str),
            "updated_at": datetime.now().isoformat()
        })
        r.expire(key, 86400)  # 24ì‹œê°„ TTL
        
        return {
            "session_id": session_id,
            "status": "saved",
            "key": key
        }
        
    except Exception as e:
        return {
            "session_id": session_id,
            "status": "error",
            "error": str(e)
        }


# ========== ë¯¸ë””ì–´ íŠ¸ëœìŠ¤ì½”ë”© íƒœìŠ¤í¬ ==========

@celery_app.task(
    bind=True,
    name="celery_tasks.transcode_recording_task",
    soft_time_limit=600,
    time_limit=660,
    max_retries=2,
    default_retry_delay=30,
)
def transcode_recording_task(
    self,
    session_id: str,
    video_path: str,
    audio_path: str,
    target_bitrate: int = 2000,
    target_audio_bitrate: int = 128,
) -> Dict:
    """
    ë©´ì ‘ ë…¹í™” ì˜ìƒì„ ì›¹ ìµœì í™” í¬ë§·ìœ¼ë¡œ íŠ¸ëœìŠ¤ì½”ë”©í•©ë‹ˆë‹¤.
    GStreamer ìš°ì„ , FFmpeg í´ë°± í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹.
    
    ì›Œí¬í”Œë¡œìš°:
    1. raw ë¹„ë””ì˜¤ + raw ì˜¤ë””ì˜¤ â†’ ë¨¹ì‹± (Muxing)
    2. H.264 + AAC íŠ¸ëœìŠ¤ì½”ë”©
    3. ì¸ë„¤ì¼ ìƒì„±
    4. ì›ë³¸ raw íŒŒì¼ ì‚­ì œ
    5. ì´ë²¤íŠ¸ ë°œí–‰ â†’ í”„ë¡ íŠ¸ì—”ë“œ ì•Œë¦¼
    
    Args:
        session_id: ë©´ì ‘ ì„¸ì…˜ ID
        video_path: raw ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        audio_path: raw ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (WAV)
        target_bitrate: ë¹„ë””ì˜¤ ë¹„íŠ¸ë ˆì´íŠ¸ (kbps)
        target_audio_bitrate: ì˜¤ë””ì˜¤ ë¹„íŠ¸ë ˆì´íŠ¸ (kbps)
    
    Returns:
        íŠ¸ëœìŠ¤ì½”ë”© ê²°ê³¼ (ì¶œë ¥ ê²½ë¡œ, íŒŒì¼ í¬ê¸°, ê¸¸ì´ ë“±)
    """
    task_id = self.request.id or "unknown"
    print(f"ğŸ¬ [Task {task_id}] íŠ¸ëœìŠ¤ì½”ë”© ì‹œì‘: {session_id[:8]}...")
    
    _publish_event(
        "recording.transcoding_started",
        session_id=session_id,
        data={"task_id": task_id, "video_path": video_path},
    )
    
    try:
        from media_recording_service import MediaRecordingService
        
        result = MediaRecordingService.transcode(
            session_id=session_id,
            video_path=video_path,
            audio_path=audio_path,
            target_codec="h264",
            target_bitrate=target_bitrate,
            target_audio_bitrate=target_audio_bitrate,
        )
        
        _publish_event(
            "recording.transcoding_completed",
            session_id=session_id,
            data={
                "task_id": task_id,
                "output_path": result.get("output_path"),
                "thumbnail_path": result.get("thumbnail_path"),
                "duration_sec": result.get("duration_sec", 0),
                "file_size_mb": round(result.get("file_size_bytes", 0) / 1024 / 1024, 2),
            },
        )
        
        print(f"âœ… [Task {task_id}] íŠ¸ëœìŠ¤ì½”ë”© ì™„ë£Œ: {session_id[:8]}...")
        return {
            "session_id": session_id,
            "status": "completed",
            "task_id": task_id,
            **result,
        }
    
    except FileNotFoundError as e:
        print(f"âŒ [Task {task_id}] íŒŒì¼ ì—†ìŒ: {e}")
        _publish_event(
            "recording.transcoding_failed",
            session_id=session_id,
            data={"task_id": task_id, "error": str(e)},
        )
        return {"session_id": session_id, "status": "error", "error": str(e)}
    
    except Exception as e:
        print(f"âŒ [Task {task_id}] íŠ¸ëœìŠ¤ì½”ë”© ì˜¤ë¥˜: {e}")
        _publish_event(
            "recording.transcoding_failed",
            session_id=session_id,
            data={"task_id": task_id, "error": str(e)},
        )
        # ì¬ì‹œë„
        if self.request.retries < self.max_retries:
            raise self.retry(exc=e)
        return {"session_id": session_id, "status": "error", "error": str(e)}


@celery_app.task(
    bind=True,
    name="celery_tasks.cleanup_recording_task",
    soft_time_limit=60,
    time_limit=90,
)
def cleanup_recording_task(
    self,
    session_id: str,
    file_paths: List[str],
) -> Dict:
    """
    ë…¹í™” ê´€ë ¨ íŒŒì¼ë“¤ì„ ì •ë¦¬ (ì‚­ì œ)í•©ë‹ˆë‹¤.
    ì„¸ì…˜ ë§Œë£Œ ë˜ëŠ” ì‚¬ìš©ì ìš”ì²­ ì‹œ í˜¸ì¶œë©ë‹ˆë‹¤.
    """
    removed = []
    errors = []
    for path in file_paths:
        if path and os.path.exists(path):
            try:
                os.remove(path)
                removed.append(os.path.basename(path))
            except Exception as e:
                errors.append(f"{os.path.basename(path)}: {e}")
    
    return {
        "session_id": session_id,
        "removed": removed,
        "errors": errors,
        "status": "completed" if not errors else "partial",
    }


# ========== í—¬í¼ í•¨ìˆ˜ ==========

def run_async(coro):
    """ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰"""
    import asyncio
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        return loop.run_until_complete(coro)
    finally:
        loop.close()
