"""
AI ëª¨ì˜ë©´ì ‘ í†µí•© ì‹œìŠ¤í…œ
========================
ê¸°ëŠ¥ í†µí•©:
1. LLM ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (Ollama/Llama3)
2. TTS ì„œë¹„ìŠ¤ (Hume AI)
3. STT ì„œë¹„ìŠ¤ (Deepgram)
4. í™”ìƒ ë©´ì ‘ + ê°ì • ë¶„ì„ (DeepFace + WebRTC)
5. ì´ë ¥ì„œ RAG (PostgreSQL + PGVector)
6. STAR ê¸°ë²• ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„±

ì‹¤í–‰ ë°©ë²•:
    uvicorn integrated_interview_server:app --host 0.0.0.0 --port 8000 --reload
"""

import os
import sys
import asyncio
import time
import uuid
import json
from datetime import datetime
from typing import Optional, Dict, List, Set, Any
from collections import Counter
import re

# FastAPI ë° ì›¹ í”„ë ˆì„ì›Œí¬
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Request
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# WebRTC
from aiortc import RTCPeerConnection, RTCSessionDescription
from aiortc.contrib.media import MediaBlackhole

# í™˜ê²½ ì„¤ì •
from dotenv import load_dotenv

# ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)
sys.path.append(root_dir)
sys.path.append(current_dir)

load_dotenv()

# ========== ì„¤ì • ==========
DEFAULT_LLM_MODEL = os.getenv("LLM_MODEL", "llama3")
DEFAULT_LLM_TEMPERATURE = float(os.getenv("LLM_TEMPERATURE", "0.7"))
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

# ========== FastAPI ì•± ì´ˆê¸°í™” ==========
app = FastAPI(
    title="AI ëª¨ì˜ë©´ì ‘ í†µí•© ì‹œìŠ¤í…œ",
    description="TTS, STT, LLM, í™”ìƒ ë©´ì ‘, ê°ì • ë¶„ì„ì„ í†µí•©í•œ AI ë©´ì ‘ ì‹œìŠ¤í…œ",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ë§ˆìš´íŠ¸
static_dir = os.path.join(current_dir, "static")
if os.path.exists(static_dir):
    app.mount("/static", StaticFiles(directory=static_dir), name="static")

# ========== ì™¸ë¶€ ì„œë¹„ìŠ¤ ì„í¬íŠ¸ ==========
# TTS ì„œë¹„ìŠ¤
try:
    from hume_tts_service import HumeTTSService, HumeInterviewerVoice, create_tts_router
    tts_router = create_tts_router()
    app.include_router(tts_router)
    TTS_AVAILABLE = True
    print("âœ… Hume TTS ì„œë¹„ìŠ¤ í™œì„±í™”ë¨")
except ImportError as e:
    TTS_AVAILABLE = False
    print(f"âš ï¸ Hume TTS ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”: {e}")

# RAG ì„œë¹„ìŠ¤
try:
    from resume_rag import ResumeRAG
    RAG_AVAILABLE = True
    print("âœ… Resume RAG ì„œë¹„ìŠ¤ í™œì„±í™”ë¨")
except ImportError as e:
    RAG_AVAILABLE = False
    print(f"âš ï¸ Resume RAG ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”: {e}")

# LLM ì„œë¹„ìŠ¤
try:
    from langchain_ollama import ChatOllama
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    LLM_AVAILABLE = True
    print("âœ… LLM ì„œë¹„ìŠ¤ í™œì„±í™”ë¨")
except ImportError as e:
    LLM_AVAILABLE = False
    print(f"âš ï¸ LLM ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”: {e}")

# ê°ì • ë¶„ì„
try:
    from deepface import DeepFace
    import numpy as np
    EMOTION_AVAILABLE = True
    print("âœ… ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤ í™œì„±í™”ë¨")
except ImportError as e:
    EMOTION_AVAILABLE = False
    print(f"âš ï¸ ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”: {e}")

# Redis
try:
    import redis
    REDIS_AVAILABLE = True
    print("âœ… Redis ì„œë¹„ìŠ¤ í™œì„±í™”ë¨")
except ImportError:
    REDIS_AVAILABLE = False
    print("âš ï¸ Redis ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”")


# ========== ì „ì—­ ìƒíƒœ ê´€ë¦¬ ==========
class InterviewState:
    """ë©´ì ‘ ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬"""
    def __init__(self):
        self.sessions: Dict[str, Dict] = {}
        self.pcs: Set[RTCPeerConnection] = set()
        self.pc_sessions: Dict[RTCPeerConnection, str] = {}
        self.last_emotion: Optional[Dict] = None
        self.emotion_lock = asyncio.Lock()
        
    def create_session(self, session_id: str = None) -> str:
        """ìƒˆ ë©´ì ‘ ì„¸ì…˜ ìƒì„±"""
        if not session_id:
            session_id = uuid.uuid4().hex
        
        self.sessions[session_id] = {
            "id": session_id,
            "created_at": datetime.now().isoformat(),
            "status": "initialized",
            "chat_history": [],
            "emotions": [],
            "answers": [],
            "current_question_idx": 0,
            "interview_mode": "text"  # text, voice, video
        }
        return session_id
    
    def get_session(self, session_id: str) -> Optional[Dict]:
        return self.sessions.get(session_id)
    
    def update_session(self, session_id: str, data: Dict):
        if session_id in self.sessions:
            self.sessions[session_id].update(data)

state = InterviewState()


# ========== LLM ë©´ì ‘ê´€ ì„œë¹„ìŠ¤ ==========
class AIInterviewer:
    """AI ë©´ì ‘ê´€ - LLM ê¸°ë°˜ ì§ˆë¬¸ ìƒì„± ë° ëŒ€í™” ê´€ë¦¬"""
    
    SYSTEM_PROMPT = """ë‹¹ì‹ ì€ IT ê¸°ì—…ì˜ 30ë…„ì°¨ ìˆ˜ì„ ê°œë°œì ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ì§€ì›ìì˜ ì´ë ¥ì„œ ë‚´ìš©ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ê¸°ìˆ  ìŠ¤íƒê³¼ ê²½í—˜ì— ëŒ€í•´ ì‹¬ë„ ìˆëŠ” ì§ˆë¬¸ì„ ë˜ì§€ì„¸ìš”.
ì œê³µëœ 'ì°¸ê³ ìš© ì´ë ¥ì„œ ë‚´ìš©'ì„ ì ê·¹ í™œìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•˜ì„¸ìš”.

[ì¤‘ìš” ê·œì¹™]
1. ë‹µë³€ì´ ë¶€ì‹¤í•˜ë©´ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ìš”êµ¬í•˜ê±°ë‚˜ ê¼¬ë¦¬ ì§ˆë¬¸ì„ í•˜ì„¸ìš”.
2. ê¼¬ë¦¬ ì§ˆë¬¸ì€ ì£¼ì œë‹¹ ìµœëŒ€ 2ë²ˆê¹Œì§€ë§Œ í—ˆìš©í•©ë‹ˆë‹¤. 
3. ë™ì¼í•œ ê¸°ìˆ ì  ì£¼ì œì— ëŒ€í•´ 2ë²ˆì˜ ë‹µë³€ì„ ë“¤ì—ˆë‹¤ë©´, "ì•Œê² ìŠµë‹ˆë‹¤. ë‹¤ìŒì€..."ì´ë¼ë©° ì£¼ì œë¥¼ ì „í™˜í•˜ì„¸ìš”.
4. ì§ˆë¬¸ì€ í•œ ë²ˆì— í•˜ë‚˜ë§Œ í•˜ì„¸ìš”.
5. ì‘ë‹µì€ 100ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

ì§ˆë¬¸ì„ í•  ë•Œ ë„ˆë¬´ ê³µê²©ì ì´ì§€ ì•Šê²Œ, ì •ì¤‘í•˜ì§€ë§Œ ë‚ ì¹´ë¡œìš´ íƒœë„ë¥¼ ìœ ì§€í•˜ì„¸ìš”."""

    DEFAULT_QUESTIONS = [
        "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë©´ì ‘ì„ ì§„í–‰í•˜ê²Œ ëœ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ë¨¼ì € ê°„ë‹¨í•œ ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
        "ì§€ì›í•˜ì‹  í¬ì§€ì…˜ì— ê´€ì‹¬ì„ ê°–ê²Œ ëœ ê³„ê¸°ê°€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ë³¸ì¸ì˜ ê°€ì¥ í° ê¸°ìˆ ì  ê°•ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹œë‚˜ìš”?",
        "ê°€ì¥ ë„ì „ì ì´ì—ˆë˜ í”„ë¡œì íŠ¸ ê²½í—˜ì— ëŒ€í•´ ë§ì”€í•´ì£¼ì„¸ìš”.",
        "íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì´ ë°œìƒí–ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ì…¨ë‚˜ìš”?",
        "ì•ìœ¼ë¡œì˜ ì»¤ë¦¬ì–´ ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "ë§ˆì§€ë§‰ìœ¼ë¡œ ì €í¬ íšŒì‚¬ì— ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?"
    ]

    def __init__(self):
        self.llm = None
        self.rag = None
        self.retriever = None
        self.tts_service = None
        
        self._init_services()
    
    def _init_services(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        # LLM ì´ˆê¸°í™”
        if LLM_AVAILABLE:
            try:
                self.llm = ChatOllama(
                    model=DEFAULT_LLM_MODEL, 
                    temperature=DEFAULT_LLM_TEMPERATURE
                )
                print(f"âœ… LLM ì´ˆê¸°í™” ì™„ë£Œ: {DEFAULT_LLM_MODEL}")
            except Exception as e:
                print(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # RAG ì´ˆê¸°í™”
        if RAG_AVAILABLE:
            try:
                connection_string = os.getenv("POSTGRES_CONNECTION_STRING")
                if connection_string:
                    self.rag = ResumeRAG(connection_string=connection_string)
                    self.retriever = self.rag.get_retriever()
                    print("âœ… RAG ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ RAG ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # TTS ì´ˆê¸°í™”
        if TTS_AVAILABLE:
            try:
                self.tts_service = HumeInterviewerVoice()
                print("âœ… TTS ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ TTS ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def get_initial_greeting(self) -> str:
        """ì´ˆê¸° ì¸ì‚¬ë§ ë°˜í™˜"""
        return self.DEFAULT_QUESTIONS[0]
    
    async def generate_response(
        self, 
        session_id: str, 
        user_input: str,
        use_rag: bool = True
    ) -> str:
        """ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ AI ì‘ë‹µ ìƒì„±"""
        session = state.get_session(session_id)
        if not session:
            return "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # LLMì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì§ˆë¬¸ ìˆœí™˜
        if not self.llm:
            idx = session.get("current_question_idx", 0)
            next_idx = (idx + 1) % len(self.DEFAULT_QUESTIONS)
            state.update_session(session_id, {"current_question_idx": next_idx})
            return self.DEFAULT_QUESTIONS[next_idx]
        
        try:
            # ëŒ€í™” ê¸°ë¡ êµ¬ì„±
            chat_history = session.get("chat_history", [])
            messages = [SystemMessage(content=self.SYSTEM_PROMPT)]
            
            # ì´ì „ ëŒ€í™” ì¶”ê°€
            for msg in chat_history[-10:]:  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ
                if msg["role"] == "assistant":
                    messages.append(AIMessage(content=msg["content"]))
                else:
                    messages.append(HumanMessage(content=msg["content"]))
            
            # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
            messages.append(HumanMessage(content=user_input))
            
            # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            if use_rag and self.retriever:
                try:
                    retrieved_docs = self.retriever.invoke(user_input)
                    if retrieved_docs:
                        context_text = "\n".join([doc.page_content for doc in retrieved_docs])
                        context_msg = SystemMessage(
                            content=f"--- [RAG] ì°¸ê³ ìš© ì´ë ¥ì„œ ë‚´ìš© ---\n{context_text}\n---"
                        )
                        messages.append(context_msg)
                except Exception as e:
                    print(f"RAG ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            
            # LLM ì‘ë‹µ ìƒì„±
            response = self.llm.invoke(messages)
            ai_response = response.content
            
            # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
            chat_history.append({"role": "user", "content": user_input})
            chat_history.append({"role": "assistant", "content": ai_response})
            state.update_session(session_id, {"chat_history": chat_history})
            
            return ai_response
            
        except Exception as e:
            print(f"LLM ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    async def generate_speech(self, text: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
        if self.tts_service:
            try:
                return await self.tts_service.speak(text)
            except Exception as e:
                print(f"TTS ì˜¤ë¥˜: {e}")
        return None


# AI ë©´ì ‘ê´€ ì¸ìŠ¤í„´ìŠ¤
interviewer = AIInterviewer()


# ========== ë©´ì ‘ ë¦¬í¬íŠ¸ ìƒì„± ==========
class InterviewReportGenerator:
    """STAR ê¸°ë²• ê¸°ë°˜ ë©´ì ‘ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    STAR_KEYWORDS = {
        'situation': ['ìƒí™©', 'ë°°ê²½', 'ë‹¹ì‹œ', 'ê·¸ë•Œ', 'í™˜ê²½', 'ìƒíƒœ', 'ë¬¸ì œ', 'ì´ìŠˆ', 'ê³¼ì œ'],
        'task': ['ëª©í‘œ', 'ê³¼ì œ', 'ì„ë¬´', 'ì—­í• ', 'ë‹´ë‹¹', 'ì±…ì„', 'í•´ì•¼ í• ', 'ëª©ì ', 'ë¯¸ì…˜'],
        'action': ['í–‰ë™', 'ìˆ˜í–‰', 'ì‹¤í–‰', 'ì²˜ë¦¬', 'í•´ê²°', 'ê°œë°œ', 'êµ¬í˜„', 'ì ìš©', 'ì§„í–‰', 'ì‹œë„', 'ë…¸ë ¥'],
        'result': ['ê²°ê³¼', 'ì„±ê³¼', 'ë‹¬ì„±', 'ì™„ë£Œ', 'ê°œì„ ', 'í–¥ìƒ', 'ì¦ê°€', 'ê°ì†Œ', 'íš¨ê³¼', 'ì„±ê³µ']
    }
    
    TECH_KEYWORDS = [
        'python', 'java', 'javascript', 'react', 'vue', 'django', 'flask', 'spring',
        'aws', 'azure', 'docker', 'kubernetes', 'sql', 'mongodb', 'postgresql',
        'git', 'ci/cd', 'api', 'rest', 'machine learning', 'deep learning',
        'tensorflow', 'pytorch', 'pandas', 'LLM', 'RAG', 'LangChain', 'FastAPI'
    ]
    
    def __init__(self, llm=None):
        self.llm = llm or interviewer.llm
    
    def analyze_star_structure(self, answers: List[str]) -> Dict:
        """STAR ê¸°ë²• ë¶„ì„"""
        star_analysis = {key: {'count': 0, 'examples': []} for key in self.STAR_KEYWORDS}
        
        for answer in answers:
            answer_lower = answer.lower()
            for element, keywords in self.STAR_KEYWORDS.items():
                for keyword in keywords:
                    if keyword in answer_lower:
                        star_analysis[element]['count'] += 1
                        break
        
        return star_analysis
    
    def extract_keywords(self, answers: List[str]) -> Dict:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        all_text = ' '.join(answers).lower()
        
        found_tech = []
        for kw in self.TECH_KEYWORDS:
            if kw.lower() in all_text:
                count = all_text.count(kw.lower())
                found_tech.append((kw, count))
        
        found_tech.sort(key=lambda x: x[1], reverse=True)
        
        korean_words = re.findall(r'[ê°€-í£]{2,}', all_text)
        word_freq = Counter(korean_words)
        
        stopwords = ['ê·¸ë˜ì„œ', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ìˆìŠµë‹ˆë‹¤', 'í–ˆìŠµë‹ˆë‹¤', 'í•©ë‹ˆë‹¤']
        for sw in stopwords:
            word_freq.pop(sw, None)
        
        return {
            'tech_keywords': found_tech[:10],
            'general_keywords': word_freq.most_common(15)
        }
    
    def calculate_metrics(self, answers: List[str]) -> Dict:
        """ë‹µë³€ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if not answers:
            return {'total': 0, 'avg_length': 0}
        
        return {
            'total': len(answers),
            'avg_length': round(sum(len(a) for a in answers) / len(answers), 1),
            'total_chars': sum(len(a) for a in answers)
        }
    
    def generate_report(
        self, 
        session_id: str, 
        emotion_stats: Optional[Dict] = None
    ) -> Dict:
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        session = state.get_session(session_id)
        if not session:
            return {"error": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        chat_history = session.get("chat_history", [])
        answers = [msg["content"] for msg in chat_history if msg["role"] == "user"]
        
        star_analysis = self.analyze_star_structure(answers)
        keywords = self.extract_keywords(answers)
        metrics = self.calculate_metrics(answers)
        
        report = {
            "session_id": session_id,
            "generated_at": datetime.now().isoformat(),
            "metrics": metrics,
            "star_analysis": {
                key: {"count": val["count"]} 
                for key, val in star_analysis.items()
            },
            "keywords": keywords,
            "emotion_stats": emotion_stats,
            "feedback": self._generate_feedback(star_analysis, metrics, keywords)
        }
        
        return report
    
    def _generate_feedback(self, star_analysis: Dict, metrics: Dict, keywords: Dict) -> List[str]:
        """í”¼ë“œë°± ìƒì„±"""
        feedback = []
        
        # STAR ë¶„ì„ í”¼ë“œë°±
        weak_elements = [k for k, v in star_analysis.items() if v['count'] < 2]
        if weak_elements:
            element_names = {
                'situation': 'ìƒí™©(S)', 'task': 'ê³¼ì œ(T)',
                'action': 'í–‰ë™(A)', 'result': 'ê²°ê³¼(R)'
            }
            weak_names = [element_names[e] for e in weak_elements]
            feedback.append(f"ğŸ“ STAR ê¸°ë²•ì—ì„œ {', '.join(weak_names)} ìš”ì†Œë¥¼ ë” ë³´ì™„í•˜ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.")
        
        # ë‹µë³€ ê¸¸ì´ í”¼ë“œë°±
        if metrics.get('avg_length', 0) < 50:
            feedback.append("ğŸ’¡ ë‹µë³€ì„ ë” êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ ì‘ì„±í•´ë³´ì„¸ìš”.")
        
        # ê¸°ìˆ  í‚¤ì›Œë“œ í”¼ë“œë°±
        if not keywords.get('tech_keywords'):
            feedback.append("ğŸ”§ ê¸°ìˆ ì ì¸ ìš©ì–´ì™€ ë„êµ¬ë¥¼ ë” í™œìš©í•´ë³´ì„¸ìš”.")
        
        if not feedback:
            feedback.append("âœ… ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ë‹µë³€ êµ¬ì¡°ë¥¼ ë³´ì—¬ì£¼ì…¨ìŠµë‹ˆë‹¤!")
        
        return feedback


# ========== ê°ì • ë¶„ì„ ==========
_redis_client: Optional[redis.Redis] = None
_ts_available: Optional[bool] = None

def get_redis() -> Optional[redis.Redis]:
    """Redis í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    global _redis_client
    if not REDIS_AVAILABLE:
        return None
    if _redis_client is None:
        try:
            _redis_client = redis.from_url(REDIS_URL)
        except Exception:
            return None
    return _redis_client

def push_timeseries(key: str, ts_ms: int, value: float, labels: Dict[str, str]):
    """ì‹œê³„ì—´ ë°ì´í„° ì €ì¥"""
    global _ts_available
    r = get_redis()
    if not r:
        return
    
    try:
        if _ts_available is not False:
            args = ["TS.ADD", key, ts_ms, value, "LABELS"]
            for k, v in labels.items():
                args.extend([k, v])
            r.execute_command(*args)
            _ts_available = True
            return
    except Exception:
        _ts_available = False
    
    try:
        r.zadd(key, {str(ts_ms): float(value)})
    except Exception:
        pass

async def analyze_emotions(track, session_id: str):
    """ì˜ìƒ í”„ë ˆì„ ê°ì • ë¶„ì„"""
    if not EMOTION_AVAILABLE:
        return
    
    sample_period = 1.0
    last_ts = 0.0
    
    try:
        while True:
            frame = await track.recv()
            now = time.monotonic()
            
            if now - last_ts < sample_period:
                continue
            last_ts = now
            
            try:
                img = frame.to_ndarray(format="bgr24")
            except Exception:
                continue
            
            try:
                res = DeepFace.analyze(img, actions=["emotion"], enforce_detection=False)
                item = res[0] if isinstance(res, list) else res
                scores = item.get("emotion", {})
                
                keys_map = {
                    "happy": "happy", "sad": "sad", "angry": "angry",
                    "surprise": "surprise", "fear": "fear", 
                    "disgust": "disgust", "neutral": "neutral"
                }
                raw = {k: float(scores.get(src, 0.0)) for k, src in keys_map.items()}
                total = sum(raw.values()) or 1.0
                probabilities = {k: (v / total) for k, v in raw.items()}
                
                data = {
                    "dominant_emotion": item.get("dominant_emotion"),
                    "probabilities": probabilities,
                    "raw_scores": raw
                }
                
                async with state.emotion_lock:
                    state.last_emotion = data
                
                # Redis ì €ì¥
                ts_ms = int(time.time() * 1000)
                for emo, prob in probabilities.items():
                    key = f"emotion:{session_id}:{emo}"
                    push_timeseries(key, ts_ms, prob, {"session_id": session_id})
                    
            except Exception:
                pass
                
    except Exception:
        pass


# ========== API ëª¨ë¸ ==========
class ChatRequest(BaseModel):
    session_id: str
    message: str
    use_rag: bool = True

class ChatResponse(BaseModel):
    session_id: str
    response: str
    audio_url: Optional[str] = None

class SessionInfo(BaseModel):
    session_id: str
    status: str
    created_at: str
    message_count: int

class Offer(BaseModel):
    sdp: str
    type: str


# ========== API ì—”ë“œí¬ì¸íŠ¸ ==========

@app.get("/", response_class=HTMLResponse)
async def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return """
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="utf-8">
        <title>AI ëª¨ì˜ë©´ì ‘ ì‹œìŠ¤í…œ</title>
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            body { 
                font-family: 'Segoe UI', system-ui, sans-serif;
                background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
                min-height: 100vh;
                color: #fff;
                display: flex;
                align-items: center;
                justify-content: center;
            }
            .container {
                text-align: center;
                padding: 40px;
            }
            h1 {
                font-size: 48px;
                background: linear-gradient(90deg, #00d9ff, #00ff88);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                margin-bottom: 20px;
            }
            p { color: #8892b0; margin-bottom: 40px; font-size: 18px; }
            .links {
                display: flex;
                gap: 20px;
                justify-content: center;
                flex-wrap: wrap;
            }
            .link-card {
                background: rgba(255,255,255,0.05);
                border: 1px solid rgba(255,255,255,0.1);
                border-radius: 16px;
                padding: 30px;
                width: 250px;
                text-decoration: none;
                color: #fff;
                transition: all 0.3s;
            }
            .link-card:hover {
                transform: translateY(-5px);
                border-color: #00d9ff;
                box-shadow: 0 10px 40px rgba(0,217,255,0.2);
            }
            .link-card h3 { margin-bottom: 10px; }
            .link-card p { font-size: 14px; color: #8892b0; margin: 0; }
            .status { margin-top: 40px; font-size: 14px; color: #666; }
            .status span { color: #00ff88; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ¯ AI ëª¨ì˜ë©´ì ‘ ì‹œìŠ¤í…œ</h1>
            <p>TTS, STT, LLM, í™”ìƒ ë©´ì ‘, ê°ì • ë¶„ì„ì„ í†µí•©í•œ AI ë©´ì ‘ ì‹œìŠ¤í…œ</p>
            
            <div class="links">
                <a href="/static/video.html" class="link-card">
                    <h3>ğŸ¥ í™”ìƒ ë©´ì ‘</h3>
                    <p>WebRTC ê¸°ë°˜ ì‹¤ì‹œê°„ í™”ìƒ ë©´ì ‘ ë° ê°ì • ë¶„ì„</p>
                </a>
                <a href="/static/dashboard.html" class="link-card">
                    <h3>ğŸ“Š ê°ì • ëŒ€ì‹œë³´ë“œ</h3>
                    <p>ì‹¤ì‹œê°„ ê°ì • ë¶„ì„ ê²°ê³¼ ì‹œê°í™”</p>
                </a>
                <a href="/docs" class="link-card">
                    <h3>ğŸ“š API ë¬¸ì„œ</h3>
                    <p>FastAPI Swagger ë¬¸ì„œ</p>
                </a>
                <a href="/interview" class="link-card">
                    <h3>ğŸ’¬ ì›¹ ì±„íŒ… ë©´ì ‘</h3>
                    <p>í…ìŠ¤íŠ¸ ê¸°ë°˜ AI ë©´ì ‘</p>
                </a>
            </div>
            
            <div class="status">
                ì„œë¹„ìŠ¤ ìƒíƒœ: 
                <span>LLM """ + ("âœ…" if LLM_AVAILABLE else "âŒ") + """</span> | 
                <span>TTS """ + ("âœ…" if TTS_AVAILABLE else "âŒ") + """</span> | 
                <span>RAG """ + ("âœ…" if RAG_AVAILABLE else "âŒ") + """</span> | 
                <span>ê°ì •ë¶„ì„ """ + ("âœ…" if EMOTION_AVAILABLE else "âŒ") + """</span>
            </div>
        </div>
    </body>
    </html>
    """


@app.get("/interview", response_class=HTMLResponse)
async def interview_page():
    """ì›¹ ê¸°ë°˜ í…ìŠ¤íŠ¸ ì±„íŒ… ë©´ì ‘ í˜ì´ì§€"""
    return """
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="utf-8">
        <title>AI ëª¨ì˜ë©´ì ‘ - ì±„íŒ…</title>
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            body { 
                font-family: 'Segoe UI', sans-serif;
                background: linear-gradient(135deg, #1a1a2e, #16213e);
                min-height: 100vh;
                color: #fff;
            }
            .container {
                max-width: 900px;
                margin: 0 auto;
                padding: 20px;
                height: 100vh;
                display: flex;
                flex-direction: column;
            }
            header {
                text-align: center;
                padding: 20px 0;
                border-bottom: 1px solid rgba(255,255,255,0.1);
            }
            header h1 {
                font-size: 24px;
                background: linear-gradient(90deg, #00d9ff, #00ff88);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
            }
            .chat-container {
                flex: 1;
                overflow-y: auto;
                padding: 20px 0;
            }
            .message {
                display: flex;
                margin-bottom: 16px;
                gap: 12px;
            }
            .message.user { flex-direction: row-reverse; }
            .avatar {
                width: 40px;
                height: 40px;
                border-radius: 50%;
                display: flex;
                align-items: center;
                justify-content: center;
                font-size: 20px;
                flex-shrink: 0;
            }
            .message.ai .avatar { background: linear-gradient(135deg, #00d9ff, #00ff88); }
            .message.user .avatar { background: rgba(255,255,255,0.1); }
            .bubble {
                max-width: 70%;
                padding: 12px 16px;
                border-radius: 16px;
                line-height: 1.5;
            }
            .message.ai .bubble {
                background: rgba(0,217,255,0.1);
                border: 1px solid rgba(0,217,255,0.2);
            }
            .message.user .bubble {
                background: rgba(255,255,255,0.1);
            }
            .input-area {
                display: flex;
                gap: 12px;
                padding: 20px 0;
                border-top: 1px solid rgba(255,255,255,0.1);
            }
            #messageInput {
                flex: 1;
                padding: 14px 20px;
                border: 1px solid rgba(255,255,255,0.2);
                border-radius: 25px;
                background: rgba(255,255,255,0.05);
                color: #fff;
                font-size: 16px;
            }
            #messageInput:focus {
                outline: none;
                border-color: #00d9ff;
            }
            #sendBtn {
                padding: 14px 30px;
                background: linear-gradient(135deg, #00d9ff, #00ff88);
                border: none;
                border-radius: 25px;
                color: #1a1a2e;
                font-weight: 600;
                cursor: pointer;
            }
            #sendBtn:hover { transform: scale(1.05); }
            #sendBtn:disabled { opacity: 0.5; cursor: not-allowed; }
            .typing { color: #888; font-style: italic; }
            .controls {
                display: flex;
                gap: 10px;
                margin-top: 10px;
                justify-content: center;
            }
            .controls button {
                padding: 8px 16px;
                border: 1px solid rgba(255,255,255,0.2);
                border-radius: 8px;
                background: transparent;
                color: #fff;
                cursor: pointer;
            }
            .controls button:hover { background: rgba(255,255,255,0.1); }
        </style>
    </head>
    <body>
        <div class="container">
            <header>
                <h1>ğŸ’¬ AI ëª¨ì˜ë©´ì ‘ ì±„íŒ…</h1>
            </header>
            
            <div class="chat-container" id="chatContainer"></div>
            
            <div class="input-area">
                <input type="text" id="messageInput" placeholder="ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”..." />
                <button id="sendBtn">ì „ì†¡</button>
            </div>
            
            <div class="controls">
                <button onclick="startNewSession()">ìƒˆ ë©´ì ‘ ì‹œì‘</button>
                <button onclick="generateReport()">ë¦¬í¬íŠ¸ ìƒì„±</button>
                <button onclick="location.href='/'">í™ˆìœ¼ë¡œ</button>
            </div>
        </div>
        
        <script>
            let sessionId = null;
            const chatContainer = document.getElementById('chatContainer');
            const messageInput = document.getElementById('messageInput');
            const sendBtn = document.getElementById('sendBtn');
            
            function addMessage(content, isUser = false) {
                const div = document.createElement('div');
                div.className = 'message ' + (isUser ? 'user' : 'ai');
                div.innerHTML = `
                    <div class="avatar">${isUser ? 'ğŸ‘¤' : 'ğŸ‘”'}</div>
                    <div class="bubble">${content}</div>
                `;
                chatContainer.appendChild(div);
                chatContainer.scrollTop = chatContainer.scrollHeight;
            }
            
            async function startNewSession() {
                const resp = await fetch('/api/session', { method: 'POST' });
                const data = await resp.json();
                sessionId = data.session_id;
                chatContainer.innerHTML = '';
                addMessage(data.greeting);
            }
            
            async function sendMessage() {
                const message = messageInput.value.trim();
                if (!message || !sessionId) return;
                
                addMessage(message, true);
                messageInput.value = '';
                sendBtn.disabled = true;
                
                const typingDiv = document.createElement('div');
                typingDiv.className = 'message ai typing';
                typingDiv.innerHTML = '<div class="avatar">ğŸ‘”</div><div class="bubble">ìƒê° ì¤‘...</div>';
                chatContainer.appendChild(typingDiv);
                
                try {
                    const resp = await fetch('/api/chat', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ session_id: sessionId, message })
                    });
                    const data = await resp.json();
                    typingDiv.remove();
                    addMessage(data.response);
                } catch (e) {
                    typingDiv.remove();
                    addMessage('ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
                }
                
                sendBtn.disabled = false;
            }
            
            async function generateReport() {
                if (!sessionId) { alert('ë©´ì ‘ì„ ë¨¼ì € ì‹œì‘í•´ì£¼ì„¸ìš”.'); return; }
                
                const resp = await fetch(`/api/report/${sessionId}`);
                const report = await resp.json();
                
                let reportHtml = '<h3>ğŸ“Š ë©´ì ‘ ë¦¬í¬íŠ¸</h3>';
                reportHtml += `<p>ì´ ë‹µë³€: ${report.metrics.total}íšŒ</p>`;
                reportHtml += `<p>í‰ê·  ê¸¸ì´: ${report.metrics.avg_length}ì</p>`;
                reportHtml += '<h4>í”¼ë“œë°±:</h4><ul>';
                report.feedback.forEach(f => { reportHtml += `<li>${f}</li>`; });
                reportHtml += '</ul>';
                
                addMessage(reportHtml);
            }
            
            sendBtn.onclick = sendMessage;
            messageInput.onkeypress = (e) => { if (e.key === 'Enter') sendMessage(); };
            
            // í˜ì´ì§€ ë¡œë“œ ì‹œ ì„¸ì…˜ ì‹œì‘
            startNewSession();
        </script>
    </body>
    </html>
    """


# ========== Session API ==========

@app.post("/api/session")
async def create_session():
    """ìƒˆ ë©´ì ‘ ì„¸ì…˜ ìƒì„±"""
    session_id = state.create_session()
    greeting = interviewer.get_initial_greeting()
    
    # ì´ˆê¸° ì¸ì‚¬ ì €ì¥
    state.update_session(session_id, {
        "status": "active",
        "chat_history": [{"role": "assistant", "content": greeting}]
    })
    
    return {
        "session_id": session_id,
        "greeting": greeting,
        "status": "active"
    }


@app.get("/api/session/{session_id}")
async def get_session(session_id: str):
    """ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
    session = state.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return SessionInfo(
        session_id=session["id"],
        status=session["status"],
        created_at=session["created_at"],
        message_count=len(session.get("chat_history", []))
    )


# ========== Chat API ==========

@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡ ë° AI ì‘ë‹µ ë°›ê¸°"""
    session = state.get_session(request.session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # AI ì‘ë‹µ ìƒì„±
    response = await interviewer.generate_response(
        request.session_id,
        request.message,
        request.use_rag
    )
    
    # TTS ìƒì„± (ì„ íƒì )
    audio_url = None
    if TTS_AVAILABLE and interviewer.tts_service:
        try:
            audio_file = await interviewer.generate_speech(response)
            if audio_file:
                audio_url = f"/audio/{os.path.basename(audio_file)}"
        except Exception as e:
            print(f"TTS ìƒì„± ì˜¤ë¥˜: {e}")
    
    return ChatResponse(
        session_id=request.session_id,
        response=response,
        audio_url=audio_url
    )


# ========== Report API ==========

@app.get("/api/report/{session_id}")
async def get_report(session_id: str):
    """ë©´ì ‘ ë¦¬í¬íŠ¸ ìƒì„±"""
    session = state.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    generator = InterviewReportGenerator()
    
    # ê°ì • í†µê³„ ì¡°íšŒ (ìˆëŠ” ê²½ìš°)
    emotion_stats = None
    if state.last_emotion:
        emotion_stats = state.last_emotion
    
    report = generator.generate_report(session_id, emotion_stats)
    return report


# ========== WebRTC/Video API ==========

@app.post("/offer")
async def webrtc_offer(offer: Offer):
    """WebRTC offer ì²˜ë¦¬"""
    import traceback
    try:
        pc = RTCPeerConnection()
        state.pcs.add(pc)
        session_id = state.create_session()
        state.pc_sessions[pc] = session_id
        
        @pc.on("iceconnectionstatechange")
        async def on_ice_state_change():
            if pc.iceConnectionState in ("failed", "closed", "disconnected"):
                await pc.close()
                state.pcs.discard(pc)
        
        @pc.on("track")
        async def on_track(track):
            if track.kind == "video":
                pc.addTrack(track)
                asyncio.create_task(analyze_emotions(track, session_id))
            else:
                bh = MediaBlackhole()
                asyncio.create_task(_consume_audio(track, bh))
        
        await pc.setRemoteDescription(RTCSessionDescription(sdp=offer.sdp, type=offer.type))
        answer = await pc.createAnswer()
        await pc.setLocalDescription(answer)
        
        return {
            "sdp": pc.localDescription.sdp,
            "type": pc.localDescription.type,
            "session_id": session_id
        }
    except Exception as e:
        error_detail = traceback.format_exc()
        print(f"[/offer ERROR] {error_detail}")
        return JSONResponse(status_code=500, content={"error": str(e)})


async def _consume_audio(track, sink: MediaBlackhole):
    """ì˜¤ë””ì˜¤ íŠ¸ë™ ì†Œë¹„"""
    try:
        while True:
            frame = await track.recv()
            sink.write(frame)
    except Exception:
        pass


# ========== Emotion API ==========

@app.get("/emotion")
async def get_emotion():
    """í˜„ì¬ ê°ì • ìƒíƒœ ì¡°íšŒ"""
    async with state.emotion_lock:
        if state.last_emotion is None:
            return {"status": "no_data"}
        return state.last_emotion


@app.get("/emotion/sessions")
async def get_emotion_sessions():
    """ëª¨ë“  ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ"""
    r = get_redis()
    sessions = set()
    if r:
        try:
            keys = r.keys("emotion:*")
            for key in keys:
                key_str = key.decode() if isinstance(key, bytes) else key
                parts = key_str.split(":")
                if len(parts) >= 2:
                    sessions.add(parts[1])
        except Exception:
            pass
    return {"sessions": list(sessions)}


@app.get("/emotion/timeseries")
async def get_emotion_timeseries(session_id: str, emotion: str, limit: int = 100):
    """ê°ì • ì‹œê³„ì—´ ë°ì´í„° ì¡°íšŒ"""
    r = get_redis()
    data = []
    if r:
        key = f"emotion:{session_id}:{emotion}"
        try:
            if _ts_available:
                res = r.execute_command("TS.RANGE", key, 0, int(time.time() * 1000))
                if isinstance(res, list):
                    data = res[-limit:]
            else:
                res = r.zrevrange(key, 0, limit - 1, withscores=True)
                data = [[int(m.decode() if isinstance(m, bytes) else m), s] for m, s in res]
        except Exception:
            pass
    return {"session_id": session_id, "emotion": emotion, "points": data}


@app.get("/emotion/stats")
async def get_emotion_stats(session_id: str):
    """ê°ì • í†µê³„ ì¡°íšŒ"""
    r = get_redis()
    emotions = ["happy", "sad", "angry", "surprise", "fear", "disgust", "neutral"]
    stats = {}
    
    for emotion in emotions:
        stats[emotion] = {"count": 0, "avg": 0, "min": 0, "max": 0}
        if not r:
            continue
        
        key = f"emotion:{session_id}:{emotion}"
        try:
            res = r.zrange(key, 0, -1, withscores=True)
            if res:
                values = [float(score) for _, score in res]
                stats[emotion] = {
                    "count": len(values),
                    "avg": sum(values) / len(values),
                    "min": min(values),
                    "max": max(values)
                }
        except Exception:
            pass
    
    return {"session_id": session_id, "stats": stats}


# ========== Service Status ==========

@app.get("/api/status")
async def get_status():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    return {
        "status": "running",
        "services": {
            "llm": LLM_AVAILABLE,
            "tts": TTS_AVAILABLE,
            "rag": RAG_AVAILABLE,
            "emotion": EMOTION_AVAILABLE,
            "redis": REDIS_AVAILABLE
        },
        "active_sessions": len(state.sessions),
        "active_connections": len(state.pcs)
    }


# ========== ì„œë²„ ì¢…ë£Œ ì²˜ë¦¬ ==========

@app.on_event("shutdown")
async def on_shutdown():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    coros = [pc.close() for pc in state.pcs]
    await asyncio.gather(*coros, return_exceptions=True)
    state.pcs.clear()


# ========== ë©”ì¸ ì‹¤í–‰ ==========

if __name__ == "__main__":
    import uvicorn
    
    print("\n" + "=" * 60)
    print("ğŸ¯ AI ëª¨ì˜ë©´ì ‘ í†µí•© ì‹œìŠ¤í…œ")
    print("=" * 60)
    print(f"  â€¢ LLM ëª¨ë¸: {DEFAULT_LLM_MODEL}")
    print(f"  â€¢ ì„œë¹„ìŠ¤ ìƒíƒœ:")
    print(f"    - LLM: {'âœ… í™œì„±í™”' if LLM_AVAILABLE else 'âŒ ë¹„í™œì„±í™”'}")
    print(f"    - TTS: {'âœ… í™œì„±í™”' if TTS_AVAILABLE else 'âŒ ë¹„í™œì„±í™”'}")
    print(f"    - RAG: {'âœ… í™œì„±í™”' if RAG_AVAILABLE else 'âŒ ë¹„í™œì„±í™”'}")
    print(f"    - ê°ì •ë¶„ì„: {'âœ… í™œì„±í™”' if EMOTION_AVAILABLE else 'âŒ ë¹„í™œì„±í™”'}")
    print(f"    - Redis: {'âœ… í™œì„±í™”' if REDIS_AVAILABLE else 'âŒ ë¹„í™œì„±í™”'}")
    print("=" * 60)
    print("  ğŸŒ http://localhost:8000 ì—ì„œ ì ‘ì†í•˜ì„¸ìš”")
    print("=" * 60 + "\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)
