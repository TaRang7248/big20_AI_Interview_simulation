"""
AI ëª¨ì˜ë©´ì ‘ í†µí•© ì‹œìŠ¤í…œ
========================
ê¸°ëŠ¥ í†µí•©:
1. LLM ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± (Ollama/Llama3)
2. TTS ì„œë¹„ìŠ¤ (Hume AI)
3. STT ì„œë¹„ìŠ¤ (Deepgram)
4. í™”ìƒ ë©´ì ‘ + ê°ì • ë¶„ì„ (DeepFace + WebRTC)
5. ì´ë ¥ì„œ RAG (PostgreSQL + PGVector)
6. STAR ê¸°ë²• ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„±

ì‹¤í–‰ ë°©ë²•:
    uvicorn integrated_interview_server:app --host 0.0.0.0 --port 8000 --reload
"""

import os
import sys
import asyncio
import time
import uuid
import json
from datetime import datetime
from typing import Optional, Dict, List, Set, Any
from collections import Counter
import re

# FastAPI ë° ì›¹ í”„ë ˆì„ì›Œí¬
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Request, UploadFile, File, Form
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import shutil

# WebRTC
from aiortc import RTCPeerConnection, RTCSessionDescription
from aiortc.contrib.media import MediaBlackhole

# í™˜ê²½ ì„¤ì •
from dotenv import load_dotenv

# ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)
sys.path.append(root_dir)
sys.path.append(current_dir)

load_dotenv()

# ========== ì„¤ì • ==========
DEFAULT_LLM_MODEL = os.getenv("LLM_MODEL", "llama3")
DEFAULT_LLM_TEMPERATURE = float(os.getenv("LLM_TEMPERATURE", "0.7"))
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

# ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì •
UPLOAD_DIR = os.path.join(current_dir, "uploads")
os.makedirs(UPLOAD_DIR, exist_ok=True)

# ========== FastAPI ì•± ì´ˆê¸°í™” ==========
app = FastAPI(
    title="AI ëª¨ì˜ë©´ì ‘ í†µí•© ì‹œìŠ¤í…œ",
    description="TTS, STT, LLM, í™”ìƒ ë©´ì ‘, ê°ì • ë¶„ì„ì„ í†µí•©í•œ AI ë©´ì ‘ ì‹œìŠ¤í…œ",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ë§ˆìš´íŠ¸
static_dir = os.path.join(current_dir, "static")
if os.path.exists(static_dir):
    app.mount("/static", StaticFiles(directory=static_dir), name="static")

# ========== ì™¸ë¶€ ì„œë¹„ìŠ¤ ì„í¬íŠ¸ ==========
# TTS ì„œë¹„ìŠ¤
try:
    from hume_tts_service import HumeTTSService, HumeInterviewerVoice, create_tts_router
    tts_router = create_tts_router()
    app.include_router(tts_router)
    TTS_AVAILABLE = True
    print("âœ… Hume TTS ì„œë¹„ìŠ¤ í™œì„±í™”ë¨")
except ImportError as e:
    TTS_AVAILABLE = False
    print(f"âš ï¸ Hume TTS ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”: {e}")

# RAG ì„œë¹„ìŠ¤
try:
    from resume_rag import ResumeRAG
    RAG_AVAILABLE = True
    print("âœ… Resume RAG ì„œë¹„ìŠ¤ í™œì„±í™”ë¨")
except ImportError as e:
    RAG_AVAILABLE = False
    print(f"âš ï¸ Resume RAG ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”: {e}")

# LLM ì„œë¹„ìŠ¤
try:
    from langchain_ollama import ChatOllama
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    LLM_AVAILABLE = True
    print("âœ… LLM ì„œë¹„ìŠ¤ í™œì„±í™”ë¨")
except ImportError as e:
    LLM_AVAILABLE = False
    print(f"âš ï¸ LLM ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”: {e}")

# ê°ì • ë¶„ì„
try:
    from deepface import DeepFace
    import numpy as np
    EMOTION_AVAILABLE = True
    print("âœ… ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤ í™œì„±í™”ë¨")
except ImportError as e:
    EMOTION_AVAILABLE = False
    print(f"âš ï¸ ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”: {e}")

# Redis
try:
    import redis
    REDIS_AVAILABLE = True
    print("âœ… Redis ì„œë¹„ìŠ¤ í™œì„±í™”ë¨")
except ImportError:
    REDIS_AVAILABLE = False
    print("âš ï¸ Redis ì„œë¹„ìŠ¤ ë¹„í™œì„±í™”")


# ========== ì „ì—­ ìƒíƒœ ê´€ë¦¬ ==========
class InterviewState:
    """ë©´ì ‘ ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬"""
    def __init__(self):
        self.sessions: Dict[str, Dict] = {}
        self.pcs: Set[RTCPeerConnection] = set()
        self.pc_sessions: Dict[RTCPeerConnection, str] = {}
        self.last_emotion: Optional[Dict] = None
        self.emotion_lock = asyncio.Lock()
        
    def create_session(self, session_id: str = None) -> str:
        """ìƒˆ ë©´ì ‘ ì„¸ì…˜ ìƒì„±"""
        if not session_id:
            session_id = uuid.uuid4().hex
        
        self.sessions[session_id] = {
            "id": session_id,
            "created_at": datetime.now().isoformat(),
            "status": "initialized",
            "chat_history": [],
            "emotions": [],
            "answers": [],
            "current_question_idx": 0,
            "interview_mode": "text",  # text, voice, video
            "resume_uploaded": False,
            "resume_path": None,
            "resume_filename": None,
            "retriever": None  # ì„¸ì…˜ë³„ RAG retriever
        }
        return session_id
    
    def get_session(self, session_id: str) -> Optional[Dict]:
        return self.sessions.get(session_id)
    
    def update_session(self, session_id: str, data: Dict):
        if session_id in self.sessions:
            self.sessions[session_id].update(data)

state = InterviewState()


# ========== LLM ë©´ì ‘ê´€ ì„œë¹„ìŠ¤ ==========
class AIInterviewer:
    """AI ë©´ì ‘ê´€ - ì§ˆë¬¸ ì€í–‰ ê¸°ë°˜ ì§ˆë¬¸ + LLM ê¸°ë°˜ ë‹µë³€ ë¶„ì„/í‰ê°€"""
    
    # LLM ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ (ì§ˆë¬¸ ìƒì„±ì´ ì•„ë‹Œ ë‹µë³€ í‰ê°€ìš©)
    EVALUATION_PROMPT = """ë‹¹ì‹ ì€ IT ê¸°ì—…ì˜ 30ë…„ì°¨ ìˆ˜ì„ ê°œë°œì ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ì§€ì›ìì˜ ë‹µë³€ì„ ë¶„ì„í•˜ê³  í‰ê°€í•´ì£¼ì„¸ìš”.

[í‰ê°€ ê¸°ì¤€]
1. êµ¬ì²´ì„± (1-5ì ): ë‹µë³€ì´ êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ ìˆ˜ì¹˜ë¥¼ í¬í•¨í•˜ëŠ”ê°€?
2. ë…¼ë¦¬ì„± (1-5ì ): ë‹µë³€ì˜ ë…¼ë¦¬ì  íë¦„ì´ ì¼ê´€ì„± ìˆëŠ”ê°€?
3. ê¸°ìˆ  ì´í•´ë„ (1-5ì ): ê¸°ìˆ ì  ê°œë…ì— ëŒ€í•œ ì´í•´ê°€ ì •í™•í•œê°€?
4. STAR ê¸°ë²• (1-5ì ): ìƒí™©-ê³¼ì œ-í–‰ë™-ê²°ê³¼ êµ¬ì¡°ë¡œ ë‹µë³€í–ˆëŠ”ê°€?
5. ì „ë‹¬ë ¥ (1-5ì ): ë‹µë³€ì´ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?

[ì¶œë ¥ í˜•ì‹ - ë°˜ë“œì‹œ JSONìœ¼ë¡œ ì‘ë‹µ]
{{
    "scores": {{
        "specificity": ìˆ«ì,
        "logic": ìˆ«ì,
        "technical": ìˆ«ì,
        "star": ìˆ«ì,
        "communication": ìˆ«ì
    }},
    "total_score": ìˆ«ì(25ì  ë§Œì ),
    "strengths": ["ê°•ì 1", "ê°•ì 2"],
    "improvements": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
    "brief_feedback": "í•œ ì¤„ í”¼ë“œë°±"
}}"""

    # ì§ˆë¬¸ ì€í–‰ - ì¹´í…Œê³ ë¦¬ë³„ ì§ˆë¬¸ ëª©ë¡
    QUESTION_BANK = {
        "intro": [
            "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë©´ì ‘ì„ ì§„í–‰í•˜ê²Œ ëœ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ë¨¼ì € ê°„ë‹¨í•œ ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
        ],
        "motivation": [
            "ì§€ì›í•˜ì‹  í¬ì§€ì…˜ì— ê´€ì‹¬ì„ ê°–ê²Œ ëœ ê³„ê¸°ê°€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ìš°ë¦¬ íšŒì‚¬ì— ì§€ì›í•˜ê²Œ ëœ ì´ìœ ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”.",
        ],
        "strength": [
            "ë³¸ì¸ì˜ ê°€ì¥ í° ê¸°ìˆ ì  ê°•ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹œë‚˜ìš”?",
            "ë‹¤ë¥¸ ì§€ì›ìì™€ ë¹„êµí–ˆì„ ë•Œ ë³¸ì¸ë§Œì˜ ì°¨ë³„ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        ],
        "project": [
            "ê°€ì¥ ë„ì „ì ì´ì—ˆë˜ í”„ë¡œì íŠ¸ ê²½í—˜ì— ëŒ€í•´ ë§ì”€í•´ì£¼ì„¸ìš”.",
            "ìµœê·¼ì— ì§„í–‰í•œ í”„ë¡œì íŠ¸ì—ì„œ ë§¡ì•˜ë˜ ì—­í• ê³¼ ê¸°ì—¬ë„ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "í”„ë¡œì íŠ¸ ì§„í–‰ ì¤‘ ê°€ì¥ ì–´ë ¤ì› ë˜ ê¸°ìˆ ì  ë¬¸ì œì™€ í•´ê²° ê³¼ì •ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        ],
        "teamwork": [
            "íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì´ ë°œìƒí–ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ì…¨ë‚˜ìš”?",
            "íŒ€ì›ê³¼ì˜ í˜‘ì—… ê²½í—˜ ì¤‘ ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
        ],
        "technical": [
            "ì‚¬ìš©í•˜ì‹œëŠ” ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "ìµœê·¼ì— í•™ìŠµí•˜ê³  ìˆëŠ” ê¸°ìˆ ì´ ìˆë‹¤ë©´ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì½”ë“œ í’ˆì§ˆì„ ìœ„í•´ ì–´ë–¤ ë…¸ë ¥ì„ í•˜ì‹œë‚˜ìš”?",
        ],
        "problem_solving": [
            "ì˜ˆìƒì¹˜ ëª»í•œ ë²„ê·¸ë‚˜ ì¥ì• ê°€ ë°œìƒí–ˆì„ ë•Œ ì–´ë–»ê²Œ ëŒ€ì²˜í•˜ì‹œë‚˜ìš”?",
            "ê¸°ìˆ ì ìœ¼ë¡œ ê°€ì¥ ì–´ë ¤ì› ë˜ ë¬¸ì œì™€ í•´ê²° ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        ],
        "growth": [
            "ì•ìœ¼ë¡œì˜ ì»¤ë¦¬ì–´ ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
            "5ë…„ í›„ ì–´ë–¤ ê°œë°œìê°€ ë˜ì–´ìˆì„ ê²ƒ ê°™ë‚˜ìš”?",
        ],
        "closing": [
            "ë§ˆì§€ë§‰ìœ¼ë¡œ ì €í¬ íšŒì‚¬ì— ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?",
        ]
    }
    
    # ë©´ì ‘ ì§„í–‰ ìˆœì„œ
    INTERVIEW_FLOW = ["intro", "motivation", "strength", "project", "teamwork", 
                       "technical", "problem_solving", "growth", "closing"]

    def __init__(self):
        self.llm = None
        self.rag = None
        self.retriever = None
        self.tts_service = None
        
        self._init_services()
    
    def _init_services(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        # LLM ì´ˆê¸°í™” (í‰ê°€/ë¶„ì„ìš©)
        if LLM_AVAILABLE:
            try:
                self.llm = ChatOllama(
                    model=DEFAULT_LLM_MODEL, 
                    temperature=0.3  # í‰ê°€ëŠ” ë‚®ì€ temperature
                )
                print(f"âœ… LLM ì´ˆê¸°í™” ì™„ë£Œ (í‰ê°€ìš©): {DEFAULT_LLM_MODEL}")
            except Exception as e:
                print(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # RAG ì´ˆê¸°í™”
        if RAG_AVAILABLE:
            try:
                connection_string = os.getenv("POSTGRES_CONNECTION_STRING")
                if connection_string:
                    self.rag = ResumeRAG(connection_string=connection_string)
                    self.retriever = self.rag.get_retriever()
                    print("âœ… RAG ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ RAG ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # TTS ì´ˆê¸°í™”
        if TTS_AVAILABLE:
            try:
                self.tts_service = HumeInterviewerVoice()
                print("âœ… TTS ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ TTS ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def get_initial_greeting(self) -> str:
        """ì´ˆê¸° ì¸ì‚¬ë§ ë°˜í™˜"""
        return self.QUESTION_BANK["intro"][0]
    
    def get_next_question(self, session_id: str) -> str:
        """ì§ˆë¬¸ ì€í–‰ì—ì„œ ë‹¤ìŒ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°"""
        session = state.get_session(session_id)
        if not session:
            return self.get_initial_greeting()
        
        current_idx = session.get("current_question_idx", 0)
        flow_idx = session.get("flow_idx", 0)
        
        # ë©´ì ‘ ìˆœì„œì— ë”°ë¼ ì§ˆë¬¸ ì„ íƒ
        if flow_idx >= len(self.INTERVIEW_FLOW):
            return "ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤. ë¦¬í¬íŠ¸ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”."
        
        category = self.INTERVIEW_FLOW[flow_idx]
        questions = self.QUESTION_BANK.get(category, [])
        
        if not questions:
            return "ë‹¤ìŒ ì§ˆë¬¸ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."
        
        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ì§ˆë¬¸ ì„ íƒ (ìˆœí™˜)
        question = questions[current_idx % len(questions)]
        
        # ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ì´ë™
        state.update_session(session_id, {
            "flow_idx": flow_idx + 1,
            "current_question_idx": 0,
            "current_category": category
        })
        
        return question
    
    async def evaluate_answer(
        self, 
        session_id: str, 
        question: str,
        answer: str
    ) -> Dict:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ í‰ê°€"""
        if not self.llm:
            # LLM ì—†ìœ¼ë©´ ê¸°ë³¸ í‰ê°€ ë°˜í™˜
            return {
                "scores": {
                    "specificity": 3,
                    "logic": 3,
                    "technical": 3,
                    "star": 3,
                    "communication": 3
                },
                "total_score": 15,
                "strengths": ["ë‹µë³€ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤."],
                "improvements": ["ë” êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ë³´ì„¸ìš”."],
                "brief_feedback": "ê´œì°®ì€ ë‹µë³€ì…ë‹ˆë‹¤."
            }
        
        try:
            # RAG ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            session = state.get_session(session_id)
            resume_context = ""
            if session:
                session_retriever = session.get("retriever") or self.retriever
                if session_retriever:
                    try:
                        docs = session_retriever.invoke(answer)
                        if docs:
                            resume_context = "\n".join([d.page_content for d in docs[:2]])
                    except Exception:
                        pass
            
            # í‰ê°€ ìš”ì²­
            messages = [
                SystemMessage(content=self.EVALUATION_PROMPT),
                HumanMessage(content=f"""
[ì§ˆë¬¸]
{question}

[ì§€ì›ì ë‹µë³€]
{answer}

{f'[ì°¸ê³ : ì´ë ¥ì„œ ë‚´ìš©]{chr(10)}{resume_context}' if resume_context else ''}

ìœ„ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
""")
            ]
            
            response = self.llm.invoke(messages)
            response_text = response.content
            
            # JSON íŒŒì‹± ì‹œë„
            import json
            # JSON ë¸”ë¡ ì¶”ì¶œ
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                evaluation = json.loads(json_match.group())
                return evaluation
            else:
                raise ValueError("JSON í˜•ì‹ ì‘ë‹µ ì—†ìŒ")
                
        except Exception as e:
            print(f"í‰ê°€ ì˜¤ë¥˜: {e}")
            return {
                "scores": {
                    "specificity": 3,
                    "logic": 3,
                    "technical": 3,
                    "star": 3,
                    "communication": 3
                },
                "total_score": 15,
                "strengths": ["ë‹µë³€ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤."],
                "improvements": ["ë” êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ë³´ì„¸ìš”."],
                "brief_feedback": "ë‹µë³€ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤."
            }
    
    async def generate_response(
        self, 
        session_id: str, 
        user_input: str,
        use_rag: bool = True
    ) -> str:
        """ì‚¬ìš©ì ë‹µë³€ì„ ì €ì¥í•˜ê³  ë‹¤ìŒ ì§ˆë¬¸ ë°˜í™˜ (ì§ˆë¬¸ ì€í–‰ ê¸°ë°˜)"""
        session = state.get_session(session_id)
        if not session:
            return "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
        chat_history = session.get("chat_history", [])
        evaluations = session.get("evaluations", [])
        
        # í˜„ì¬ ì§ˆë¬¸ ì €ì¥ (ë§ˆì§€ë§‰ AI ë©”ì‹œì§€)
        last_question = ""
        for msg in reversed(chat_history):
            if msg["role"] == "assistant":
                last_question = msg["content"]
                break
        
        # ì‚¬ìš©ì ë‹µë³€ ì €ì¥
        chat_history.append({"role": "user", "content": user_input})
        
        # ë‹¤ìŒ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
        next_question = self.get_next_question(session_id)
        chat_history.append({"role": "assistant", "content": next_question})
        
        state.update_session(session_id, {"chat_history": chat_history})
        
        return next_question
    
    async def generate_speech(self, text: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
        if self.tts_service:
            try:
                return await self.tts_service.speak(text)
            except Exception as e:
                print(f"TTS ì˜¤ë¥˜: {e}")
        return None


# AI ë©´ì ‘ê´€ ì¸ìŠ¤í„´ìŠ¤
interviewer = AIInterviewer()


# ========== ë©´ì ‘ ë¦¬í¬íŠ¸ ìƒì„± ==========
class InterviewReportGenerator:
    """STAR ê¸°ë²• ê¸°ë°˜ ë©´ì ‘ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    STAR_KEYWORDS = {
        'situation': ['ìƒí™©', 'ë°°ê²½', 'ë‹¹ì‹œ', 'ê·¸ë•Œ', 'í™˜ê²½', 'ìƒíƒœ', 'ë¬¸ì œ', 'ì´ìŠˆ', 'ê³¼ì œ'],
        'task': ['ëª©í‘œ', 'ê³¼ì œ', 'ì„ë¬´', 'ì—­í• ', 'ë‹´ë‹¹', 'ì±…ì„', 'í•´ì•¼ í• ', 'ëª©ì ', 'ë¯¸ì…˜'],
        'action': ['í–‰ë™', 'ìˆ˜í–‰', 'ì‹¤í–‰', 'ì²˜ë¦¬', 'í•´ê²°', 'ê°œë°œ', 'êµ¬í˜„', 'ì ìš©', 'ì§„í–‰', 'ì‹œë„', 'ë…¸ë ¥'],
        'result': ['ê²°ê³¼', 'ì„±ê³¼', 'ë‹¬ì„±', 'ì™„ë£Œ', 'ê°œì„ ', 'í–¥ìƒ', 'ì¦ê°€', 'ê°ì†Œ', 'íš¨ê³¼', 'ì„±ê³µ']
    }
    
    TECH_KEYWORDS = [
        'python', 'java', 'javascript', 'react', 'vue', 'django', 'flask', 'spring',
        'aws', 'azure', 'docker', 'kubernetes', 'sql', 'mongodb', 'postgresql',
        'git', 'ci/cd', 'api', 'rest', 'machine learning', 'deep learning',
        'tensorflow', 'pytorch', 'pandas', 'LLM', 'RAG', 'LangChain', 'FastAPI'
    ]
    
    def __init__(self, llm=None):
        self.llm = llm or interviewer.llm
    
    def analyze_star_structure(self, answers: List[str]) -> Dict:
        """STAR ê¸°ë²• ë¶„ì„"""
        star_analysis = {key: {'count': 0, 'examples': []} for key in self.STAR_KEYWORDS}
        
        for answer in answers:
            answer_lower = answer.lower()
            for element, keywords in self.STAR_KEYWORDS.items():
                for keyword in keywords:
                    if keyword in answer_lower:
                        star_analysis[element]['count'] += 1
                        break
        
        return star_analysis
    
    def extract_keywords(self, answers: List[str]) -> Dict:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        all_text = ' '.join(answers).lower()
        
        found_tech = []
        for kw in self.TECH_KEYWORDS:
            if kw.lower() in all_text:
                count = all_text.count(kw.lower())
                found_tech.append((kw, count))
        
        found_tech.sort(key=lambda x: x[1], reverse=True)
        
        korean_words = re.findall(r'[ê°€-í£]{2,}', all_text)
        word_freq = Counter(korean_words)
        
        stopwords = ['ê·¸ë˜ì„œ', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ìˆìŠµë‹ˆë‹¤', 'í–ˆìŠµë‹ˆë‹¤', 'í•©ë‹ˆë‹¤']
        for sw in stopwords:
            word_freq.pop(sw, None)
        
        return {
            'tech_keywords': found_tech[:10],
            'general_keywords': word_freq.most_common(15)
        }
    
    def calculate_metrics(self, answers: List[str]) -> Dict:
        """ë‹µë³€ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if not answers:
            return {'total': 0, 'avg_length': 0}
        
        return {
            'total': len(answers),
            'avg_length': round(sum(len(a) for a in answers) / len(answers), 1),
            'total_chars': sum(len(a) for a in answers)
        }
    
    def generate_report(
        self, 
        session_id: str, 
        emotion_stats: Optional[Dict] = None
    ) -> Dict:
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        session = state.get_session(session_id)
        if not session:
            return {"error": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        chat_history = session.get("chat_history", [])
        answers = [msg["content"] for msg in chat_history if msg["role"] == "user"]
        
        star_analysis = self.analyze_star_structure(answers)
        keywords = self.extract_keywords(answers)
        metrics = self.calculate_metrics(answers)
        
        report = {
            "session_id": session_id,
            "generated_at": datetime.now().isoformat(),
            "metrics": metrics,
            "star_analysis": {
                key: {"count": val["count"]} 
                for key, val in star_analysis.items()
            },
            "keywords": keywords,
            "emotion_stats": emotion_stats,
            "feedback": self._generate_feedback(star_analysis, metrics, keywords)
        }
        
        return report
    
    def _generate_feedback(self, star_analysis: Dict, metrics: Dict, keywords: Dict) -> List[str]:
        """í”¼ë“œë°± ìƒì„±"""
        feedback = []
        
        # STAR ë¶„ì„ í”¼ë“œë°±
        weak_elements = [k for k, v in star_analysis.items() if v['count'] < 2]
        if weak_elements:
            element_names = {
                'situation': 'ìƒí™©(S)', 'task': 'ê³¼ì œ(T)',
                'action': 'í–‰ë™(A)', 'result': 'ê²°ê³¼(R)'
            }
            weak_names = [element_names[e] for e in weak_elements]
            feedback.append(f"ğŸ“ STAR ê¸°ë²•ì—ì„œ {', '.join(weak_names)} ìš”ì†Œë¥¼ ë” ë³´ì™„í•˜ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.")
        
        # ë‹µë³€ ê¸¸ì´ í”¼ë“œë°±
        if metrics.get('avg_length', 0) < 50:
            feedback.append("ğŸ’¡ ë‹µë³€ì„ ë” êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ ì‘ì„±í•´ë³´ì„¸ìš”.")
        
        # ê¸°ìˆ  í‚¤ì›Œë“œ í”¼ë“œë°±
        if not keywords.get('tech_keywords'):
            feedback.append("ğŸ”§ ê¸°ìˆ ì ì¸ ìš©ì–´ì™€ ë„êµ¬ë¥¼ ë” í™œìš©í•´ë³´ì„¸ìš”.")
        
        if not feedback:
            feedback.append("âœ… ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ë‹µë³€ êµ¬ì¡°ë¥¼ ë³´ì—¬ì£¼ì…¨ìŠµë‹ˆë‹¤!")
        
        return feedback


# ========== ê°ì • ë¶„ì„ ==========
_redis_client: Optional[redis.Redis] = None
_ts_available: Optional[bool] = None

def get_redis() -> Optional[redis.Redis]:
    """Redis í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    global _redis_client
    if not REDIS_AVAILABLE:
        return None
    if _redis_client is None:
        try:
            _redis_client = redis.from_url(REDIS_URL)
        except Exception:
            return None
    return _redis_client

def push_timeseries(key: str, ts_ms: int, value: float, labels: Dict[str, str]):
    """ì‹œê³„ì—´ ë°ì´í„° ì €ì¥"""
    global _ts_available
    r = get_redis()
    if not r:
        return
    
    try:
        if _ts_available is not False:
            args = ["TS.ADD", key, ts_ms, value, "LABELS"]
            for k, v in labels.items():
                args.extend([k, v])
            r.execute_command(*args)
            _ts_available = True
            return
    except Exception:
        _ts_available = False
    
    try:
        r.zadd(key, {str(ts_ms): float(value)})
    except Exception:
        pass

async def analyze_emotions(track, session_id: str):
    """ì˜ìƒ í”„ë ˆì„ ê°ì • ë¶„ì„"""
    if not EMOTION_AVAILABLE:
        return
    
    sample_period = 1.0
    last_ts = 0.0
    
    try:
        while True:
            frame = await track.recv()
            now = time.monotonic()
            
            if now - last_ts < sample_period:
                continue
            last_ts = now
            
            try:
                img = frame.to_ndarray(format="bgr24")
            except Exception:
                continue
            
            try:
                res = DeepFace.analyze(img, actions=["emotion"], enforce_detection=False)
                item = res[0] if isinstance(res, list) else res
                scores = item.get("emotion", {})
                
                keys_map = {
                    "happy": "happy", "sad": "sad", "angry": "angry",
                    "surprise": "surprise", "fear": "fear", 
                    "disgust": "disgust", "neutral": "neutral"
                }
                raw = {k: float(scores.get(src, 0.0)) for k, src in keys_map.items()}
                total = sum(raw.values()) or 1.0
                probabilities = {k: (v / total) for k, v in raw.items()}
                
                data = {
                    "dominant_emotion": item.get("dominant_emotion"),
                    "probabilities": probabilities,
                    "raw_scores": raw
                }
                
                async with state.emotion_lock:
                    state.last_emotion = data
                
                # Redis ì €ì¥
                ts_ms = int(time.time() * 1000)
                for emo, prob in probabilities.items():
                    key = f"emotion:{session_id}:{emo}"
                    push_timeseries(key, ts_ms, prob, {"session_id": session_id})
                    
            except Exception:
                pass
                
    except Exception:
        pass


# ========== API ëª¨ë¸ ==========
class ChatRequest(BaseModel):
    session_id: str
    message: str
    use_rag: bool = True

class ChatResponse(BaseModel):
    session_id: str
    response: str
    audio_url: Optional[str] = None

class SessionInfo(BaseModel):
    session_id: str
    status: str
    created_at: str
    message_count: int

class Offer(BaseModel):
    sdp: str
    type: str


# ========== API ì—”ë“œí¬ì¸íŠ¸ ==========

@app.get("/", response_class=HTMLResponse)
async def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return """
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="utf-8">
        <title>AI ëª¨ì˜ë©´ì ‘ ì‹œìŠ¤í…œ</title>
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            body { 
                font-family: 'Segoe UI', system-ui, sans-serif;
                background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
                min-height: 100vh;
                color: #fff;
                display: flex;
                align-items: center;
                justify-content: center;
            }
            .container {
                text-align: center;
                padding: 40px;
                max-width: 800px;
            }
            h1 {
                font-size: 48px;
                background: linear-gradient(90deg, #00d9ff, #00ff88);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                margin-bottom: 20px;
            }
            p { color: #8892b0; margin-bottom: 40px; font-size: 18px; }
            .main-cta {
                display: block;
                background: linear-gradient(135deg, #00d9ff, #00ff88);
                color: #1a1a2e;
                text-decoration: none;
                font-size: 24px;
                font-weight: 700;
                padding: 24px 48px;
                border-radius: 16px;
                margin-bottom: 40px;
                transition: all 0.3s;
                box-shadow: 0 10px 40px rgba(0,217,255,0.3);
            }
            .main-cta:hover {
                transform: translateY(-5px);
                box-shadow: 0 20px 60px rgba(0,217,255,0.4);
            }
            .features {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                gap: 16px;
                margin-bottom: 30px;
            }
            .feature {
                background: rgba(255,255,255,0.05);
                border: 1px solid rgba(255,255,255,0.1);
                border-radius: 12px;
                padding: 20px;
            }
            .feature .icon { font-size: 32px; margin-bottom: 10px; }
            .feature h4 { font-size: 14px; margin-bottom: 5px; }
            .feature p { font-size: 12px; color: #8892b0; margin: 0; }
            .sub-links {
                display: flex;
                gap: 16px;
                justify-content: center;
                margin-top: 30px;
            }
            .sub-link {
                color: #8892b0;
                text-decoration: none;
                font-size: 14px;
                padding: 8px 16px;
                border: 1px solid rgba(255,255,255,0.1);
                border-radius: 8px;
                transition: all 0.3s;
            }
            .sub-link:hover { border-color: #00d9ff; color: #00d9ff; }
            .status { margin-top: 30px; font-size: 14px; color: #666; }
            .status span { color: #00ff88; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ¯ AI ëª¨ì˜ë©´ì ‘ ì‹œìŠ¤í…œ</h1>
            <p>LLM ê¸°ë°˜ ë©´ì ‘ í‰ê°€ + ì‹¤ì‹œê°„ ê°ì • ë¶„ì„ì„ í†µí•œ ìŠ¤ë§ˆíŠ¸ ë©´ì ‘ íŠ¸ë ˆì´ë‹</p>
            
            <a href="/static/integrated_interview.html" class="main-cta">
                ğŸ¥ AI í™”ìƒ ë©´ì ‘ ì‹œì‘í•˜ê¸°
            </a>
            
            <div class="features">
                <div class="feature">
                    <div class="icon">ğŸ“„</div>
                    <h4>ì´ë ¥ì„œ RAG</h4>
                    <p>ì´ë ¥ì„œ ê¸°ë°˜ ë§ì¶¤ ì§ˆë¬¸</p>
                </div>
                <div class="feature">
                    <div class="icon">ğŸ¤</div>
                    <h4>TTS ìŒì„±</h4>
                    <p>ìì—°ìŠ¤ëŸ¬ìš´ AI ë©´ì ‘ê´€</p>
                </div>
                <div class="feature">
                    <div class="icon">ğŸ“Š</div>
                    <h4>ì‹¤ì‹œê°„ í‰ê°€</h4>
                    <p>LLM ê¸°ë°˜ ë‹µë³€ ë¶„ì„</p>
                </div>
                <div class="feature">
                    <div class="icon">ğŸ˜Š</div>
                    <h4>ê°ì • ë¶„ì„</h4>
                    <p>í‘œì • ê¸°ë°˜ ê°ì • ì¸¡ì •</p>
                </div>
            </div>
            
            <div class="sub-links">
                <a href="/static/dashboard.html" class="sub-link">ğŸ“Š ê°ì • ëŒ€ì‹œë³´ë“œ</a>
                <a href="/docs" class="sub-link">ğŸ“š API ë¬¸ì„œ</a>
            </div>
            
            <div class="status">
                ì„œë¹„ìŠ¤ ìƒíƒœ: 
                <span>LLM """ + ("âœ…" if LLM_AVAILABLE else "âŒ") + """</span> | 
                <span>TTS """ + ("âœ…" if TTS_AVAILABLE else "âŒ") + """</span> | 
                <span>RAG """ + ("âœ…" if RAG_AVAILABLE else "âŒ") + """</span> | 
                <span>ê°ì •ë¶„ì„ """ + ("âœ…" if EMOTION_AVAILABLE else "âŒ") + """</span>
            </div>
        </div>
    </body>
    </html>
    """


@app.get("/interview")
async def interview_redirect():
    """ì±„íŒ… ë©´ì ‘ â†’ í™”ìƒ ë©´ì ‘ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸"""
    from fastapi.responses import RedirectResponse
    return RedirectResponse(url="/static/integrated_interview.html")


# ========== Resume Upload API ==========

class ResumeUploadResponse(BaseModel):
    success: bool
    message: str
    session_id: str
    filename: Optional[str] = None
    chunks_created: Optional[int] = None

@app.post("/api/resume/upload", response_model=ResumeUploadResponse)
async def upload_resume(
    file: UploadFile = File(...),
    session_id: Optional[str] = Form(None)
):
    """
    ì´ë ¥ì„œ PDF íŒŒì¼ ì—…ë¡œë“œ ë° RAG ì¸ë±ì‹±
    """
    # íŒŒì¼ í˜•ì‹ ê²€ì¦
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    # íŒŒì¼ í¬ê¸° ê²€ì¦ (10MB ì œí•œ)
    contents = await file.read()
    if len(contents) > 10 * 1024 * 1024:
        raise HTTPException(status_code=400, detail="íŒŒì¼ í¬ê¸°ëŠ” 10MBë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì„¸ì…˜ ìƒì„± ë˜ëŠ” ì¡°íšŒ
    if not session_id:
        session_id = state.create_session()
    else:
        session = state.get_session(session_id)
        if not session:
            session_id = state.create_session(session_id)
    
    # íŒŒì¼ ì €ì¥
    safe_filename = f"{session_id}_{uuid.uuid4().hex[:8]}.pdf"
    file_path = os.path.join(UPLOAD_DIR, safe_filename)
    
    try:
        with open(file_path, "wb") as f:
            f.write(contents)
        print(f"âœ… ì´ë ¥ì„œ ì €ì¥ ì™„ë£Œ: {file_path}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    # RAG ì¸ë±ì‹±
    chunks_created = 0
    if RAG_AVAILABLE:
        try:
            # ì„¸ì…˜ë³„ ê³ ìœ  ì»¬ë ‰ì…˜ ì´ë¦„ ì‚¬ìš©
            collection_name = f"resume_{session_id[:16]}"
            connection_string = os.getenv("POSTGRES_CONNECTION_STRING")
            
            if connection_string:
                # ìƒˆ RAG ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì„¸ì…˜ë³„)
                session_rag = ResumeRAG(
                    connection_string=connection_string,
                    collection_name=collection_name
                )
                
                # PDF ì¸ë±ì‹±
                print(f"ğŸ“š ì´ë ¥ì„œ ì¸ë±ì‹± ì‹œì‘: {file_path}")
                session_rag.load_and_index_pdf(file_path)
                
                # ì„¸ì…˜ì— retriever ì €ì¥
                retriever = session_rag.get_retriever()
                state.update_session(session_id, {
                    "resume_uploaded": True,
                    "resume_path": file_path,
                    "resume_filename": file.filename,
                    "retriever": retriever
                })
                
                # ì²­í¬ ìˆ˜ ì¶”ì • (ë¡œê·¸ì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ëŒ€ëµì ìœ¼ë¡œ)
                chunks_created = 1  # ìµœì†Œ 1ê°œ ì´ìƒ
                print(f"âœ… RAG ì¸ë±ì‹± ì™„ë£Œ: {collection_name}")
            else:
                print("âš ï¸ POSTGRES_CONNECTION_STRING ë¯¸ì„¤ì •, RAG ë¹„í™œì„±í™”")
                state.update_session(session_id, {
                    "resume_uploaded": True,
                    "resume_path": file_path,
                    "resume_filename": file.filename
                })
        except Exception as e:
            print(f"âŒ RAG ì¸ë±ì‹± ì˜¤ë¥˜: {e}")
            # RAG ì‹¤íŒ¨í•´ë„ íŒŒì¼ì€ ì €ì¥ë˜ì—ˆìœ¼ë¯€ë¡œ ì„±ê³µ ë°˜í™˜
            state.update_session(session_id, {
                "resume_uploaded": True,
                "resume_path": file_path,
                "resume_filename": file.filename
            })
    else:
        # RAG ë¹„í™œì„±í™” ìƒíƒœì—ì„œë„ íŒŒì¼ ì •ë³´ ì €ì¥
        state.update_session(session_id, {
            "resume_uploaded": True,
            "resume_path": file_path,
            "resume_filename": file.filename
        })
    
    return ResumeUploadResponse(
        success=True,
        message="ì´ë ¥ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤." + (
            " RAG ì¸ë±ì‹±ì´ ì™„ë£Œë˜ì–´ ë©´ì ‘ ì§ˆë¬¸ì— ë°˜ì˜ë©ë‹ˆë‹¤." if RAG_AVAILABLE else ""
        ),
        session_id=session_id,
        filename=file.filename,
        chunks_created=chunks_created if chunks_created > 0 else None
    )


@app.get("/api/resume/status/{session_id}")
async def get_resume_status(session_id: str):
    """ì„¸ì…˜ì˜ ì´ë ¥ì„œ ì—…ë¡œë“œ ìƒíƒœ í™•ì¸"""
    session = state.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return {
        "session_id": session_id,
        "resume_uploaded": session.get("resume_uploaded", False),
        "resume_filename": session.get("resume_filename"),
        "rag_enabled": session.get("retriever") is not None
    }


@app.delete("/api/resume/{session_id}")
async def delete_resume(session_id: str):
    """ì„¸ì…˜ì˜ ì´ë ¥ì„œ ì‚­ì œ"""
    session = state.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    resume_path = session.get("resume_path")
    if resume_path and os.path.exists(resume_path):
        try:
            os.remove(resume_path)
            print(f"âœ… ì´ë ¥ì„œ ì‚­ì œ ì™„ë£Œ: {resume_path}")
        except Exception as e:
            print(f"âŒ ì´ë ¥ì„œ ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    state.update_session(session_id, {
        "resume_uploaded": False,
        "resume_path": None,
        "resume_filename": None,
        "retriever": None
    })
    
    return {"success": True, "message": "ì´ë ¥ì„œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."}


# ========== Session API ==========

@app.post("/api/session")
async def create_session():
    """ìƒˆ ë©´ì ‘ ì„¸ì…˜ ìƒì„±"""
    session_id = state.create_session()
    greeting = interviewer.get_initial_greeting()
    
    # ì´ˆê¸° ì¸ì‚¬ ì €ì¥
    state.update_session(session_id, {
        "status": "active",
        "chat_history": [{"role": "assistant", "content": greeting}]
    })
    
    return {
        "session_id": session_id,
        "greeting": greeting,
        "status": "active"
    }


@app.get("/api/session/{session_id}")
async def get_session(session_id: str):
    """ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
    session = state.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return SessionInfo(
        session_id=session["id"],
        status=session["status"],
        created_at=session["created_at"],
        message_count=len(session.get("chat_history", []))
    )


# ========== Chat API ==========

@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡ ë° AI ì‘ë‹µ ë°›ê¸°"""
    session = state.get_session(request.session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # AI ì‘ë‹µ ìƒì„±
    response = await interviewer.generate_response(
        request.session_id,
        request.message,
        request.use_rag
    )
    
    # TTS ìƒì„± (ì„ íƒì )
    audio_url = None
    if TTS_AVAILABLE and interviewer.tts_service:
        try:
            audio_file = await interviewer.generate_speech(response)
            if audio_file:
                audio_url = f"/audio/{os.path.basename(audio_file)}"
        except Exception as e:
            print(f"TTS ìƒì„± ì˜¤ë¥˜: {e}")
    
    return ChatResponse(
        session_id=request.session_id,
        response=response,
        audio_url=audio_url
    )


# ========== Report API ==========

@app.get("/api/report/{session_id}")
async def get_report(session_id: str):
    """ë©´ì ‘ ë¦¬í¬íŠ¸ ìƒì„±"""
    session = state.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    generator = InterviewReportGenerator()
    
    # ê°ì • í†µê³„ ì¡°íšŒ (ìˆëŠ” ê²½ìš°)
    emotion_stats = None
    if state.last_emotion:
        emotion_stats = state.last_emotion
    
    report = generator.generate_report(session_id, emotion_stats)
    
    # ì„¸ì…˜ì˜ í‰ê°€ ê²°ê³¼ í¬í•¨
    evaluations = session.get("evaluations", [])
    if evaluations:
        # í‰ê·  ì ìˆ˜ ê³„ì‚°
        avg_scores = {
            "specificity": 0, "logic": 0, "technical": 0, "star": 0, "communication": 0
        }
        for ev in evaluations:
            for key in avg_scores:
                avg_scores[key] += ev.get("scores", {}).get(key, 0)
        
        if len(evaluations) > 0:
            for key in avg_scores:
                avg_scores[key] = round(avg_scores[key] / len(evaluations), 1)
        
        report["llm_evaluation"] = {
            "answer_count": len(evaluations),
            "average_scores": avg_scores,
            "total_average": round(sum(avg_scores.values()) / 5, 1),
            "all_evaluations": evaluations
        }
    
    return report


# ========== Evaluate API (LLM ê¸°ë°˜ ë‹µë³€ í‰ê°€) ==========

class EvaluateRequest(BaseModel):
    session_id: str
    question: str
    answer: str

class EvaluateResponse(BaseModel):
    session_id: str
    scores: Dict[str, int]
    total_score: int
    strengths: List[str]
    improvements: List[str]
    brief_feedback: str

@app.post("/api/evaluate", response_model=EvaluateResponse)
async def evaluate_answer(request: EvaluateRequest):
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ í‰ê°€
    
    - ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë°›ì•„ 5ê°€ì§€ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€
    - ì„¸ì…˜ì— í‰ê°€ ê²°ê³¼ ì €ì¥
    """
    session = state.get_session(request.session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # LLM í‰ê°€ ìˆ˜í–‰
    evaluation = await interviewer.evaluate_answer(
        request.session_id,
        request.question,
        request.answer
    )
    
    # ì„¸ì…˜ì— í‰ê°€ ì €ì¥
    evaluations = session.get("evaluations", [])
    evaluations.append({
        "question": request.question,
        "answer": request.answer,
        **evaluation
    })
    state.update_session(request.session_id, {"evaluations": evaluations})
    
    return EvaluateResponse(
        session_id=request.session_id,
        scores=evaluation.get("scores", {}),
        total_score=evaluation.get("total_score", 0),
        strengths=evaluation.get("strengths", []),
        improvements=evaluation.get("improvements", []),
        brief_feedback=evaluation.get("brief_feedback", "")
    )


@app.get("/api/evaluations/{session_id}")
async def get_evaluations(session_id: str):
    """ì„¸ì…˜ì˜ ëª¨ë“  í‰ê°€ ê²°ê³¼ ì¡°íšŒ"""
    session = state.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    evaluations = session.get("evaluations", [])
    
    # í†µê³„ ê³„ì‚°
    if evaluations:
        avg_scores = {"specificity": 0, "logic": 0, "technical": 0, "star": 0, "communication": 0}
        for ev in evaluations:
            for key in avg_scores:
                avg_scores[key] += ev.get("scores", {}).get(key, 0)
        for key in avg_scores:
            avg_scores[key] = round(avg_scores[key] / len(evaluations), 1)
        
        return {
            "session_id": session_id,
            "total_answers": len(evaluations),
            "average_scores": avg_scores,
            "total_average": round(sum(avg_scores.values()) / 5, 1),
            "evaluations": evaluations
        }
    
    return {
        "session_id": session_id,
        "total_answers": 0,
        "average_scores": {},
        "evaluations": []
    }


# ========== WebRTC/Video API ==========

@app.post("/offer")
async def webrtc_offer(offer: Offer):
    """WebRTC offer ì²˜ë¦¬"""
    import traceback
    try:
        pc = RTCPeerConnection()
        state.pcs.add(pc)
        session_id = state.create_session()
        state.pc_sessions[pc] = session_id
        
        @pc.on("iceconnectionstatechange")
        async def on_ice_state_change():
            if pc.iceConnectionState in ("failed", "closed", "disconnected"):
                await pc.close()
                state.pcs.discard(pc)
        
        @pc.on("track")
        async def on_track(track):
            if track.kind == "video":
                pc.addTrack(track)
                asyncio.create_task(analyze_emotions(track, session_id))
            else:
                bh = MediaBlackhole()
                asyncio.create_task(_consume_audio(track, bh))
        
        await pc.setRemoteDescription(RTCSessionDescription(sdp=offer.sdp, type=offer.type))
        answer = await pc.createAnswer()
        await pc.setLocalDescription(answer)
        
        return {
            "sdp": pc.localDescription.sdp,
            "type": pc.localDescription.type,
            "session_id": session_id
        }
    except Exception as e:
        error_detail = traceback.format_exc()
        print(f"[/offer ERROR] {error_detail}")
        return JSONResponse(status_code=500, content={"error": str(e)})


async def _consume_audio(track, sink: MediaBlackhole):
    """ì˜¤ë””ì˜¤ íŠ¸ë™ ì†Œë¹„"""
    try:
        while True:
            frame = await track.recv()
            sink.write(frame)
    except Exception:
        pass


# ========== Emotion API ==========

@app.get("/emotion")
async def get_emotion():
    """í˜„ì¬ ê°ì • ìƒíƒœ ì¡°íšŒ"""
    async with state.emotion_lock:
        if state.last_emotion is None:
            return {"status": "no_data"}
        return state.last_emotion


@app.get("/emotion/sessions")
async def get_emotion_sessions():
    """ëª¨ë“  ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ"""
    r = get_redis()
    sessions = set()
    if r:
        try:
            keys = r.keys("emotion:*")
            for key in keys:
                key_str = key.decode() if isinstance(key, bytes) else key
                parts = key_str.split(":")
                if len(parts) >= 2:
                    sessions.add(parts[1])
        except Exception:
            pass
    return {"sessions": list(sessions)}


@app.get("/emotion/timeseries")
async def get_emotion_timeseries(session_id: str, emotion: str, limit: int = 100):
    """ê°ì • ì‹œê³„ì—´ ë°ì´í„° ì¡°íšŒ"""
    r = get_redis()
    data = []
    if r:
        key = f"emotion:{session_id}:{emotion}"
        try:
            if _ts_available:
                res = r.execute_command("TS.RANGE", key, 0, int(time.time() * 1000))
                if isinstance(res, list):
                    data = res[-limit:]
            else:
                res = r.zrevrange(key, 0, limit - 1, withscores=True)
                data = [[int(m.decode() if isinstance(m, bytes) else m), s] for m, s in res]
        except Exception:
            pass
    return {"session_id": session_id, "emotion": emotion, "points": data}


@app.get("/emotion/stats")
async def get_emotion_stats(session_id: str):
    """ê°ì • í†µê³„ ì¡°íšŒ"""
    r = get_redis()
    emotions = ["happy", "sad", "angry", "surprise", "fear", "disgust", "neutral"]
    stats = {}
    
    for emotion in emotions:
        stats[emotion] = {"count": 0, "avg": 0, "min": 0, "max": 0}
        if not r:
            continue
        
        key = f"emotion:{session_id}:{emotion}"
        try:
            res = r.zrange(key, 0, -1, withscores=True)
            if res:
                values = [float(score) for _, score in res]
                stats[emotion] = {
                    "count": len(values),
                    "avg": sum(values) / len(values),
                    "min": min(values),
                    "max": max(values)
                }
        except Exception:
            pass
    
    return {"session_id": session_id, "stats": stats}


# ========== Service Status ==========

@app.get("/api/status")
async def get_status():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    return {
        "status": "running",
        "services": {
            "llm": LLM_AVAILABLE,
            "tts": TTS_AVAILABLE,
            "rag": RAG_AVAILABLE,
            "emotion": EMOTION_AVAILABLE,
            "redis": REDIS_AVAILABLE
        },
        "active_sessions": len(state.sessions),
        "active_connections": len(state.pcs)
    }


# ========== ì„œë²„ ì¢…ë£Œ ì²˜ë¦¬ ==========

@app.on_event("shutdown")
async def on_shutdown():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    coros = [pc.close() for pc in state.pcs]
    await asyncio.gather(*coros, return_exceptions=True)
    state.pcs.clear()


# ========== ë©”ì¸ ì‹¤í–‰ ==========

if __name__ == "__main__":
    import uvicorn
    
    print("\n" + "=" * 60)
    print("ğŸ¯ AI ëª¨ì˜ë©´ì ‘ í†µí•© ì‹œìŠ¤í…œ")
    print("=" * 60)
    print(f"  â€¢ LLM ëª¨ë¸: {DEFAULT_LLM_MODEL}")
    print(f"  â€¢ ì„œë¹„ìŠ¤ ìƒíƒœ:")
    print(f"    - LLM: {'âœ… í™œì„±í™”' if LLM_AVAILABLE else 'âŒ ë¹„í™œì„±í™”'}")
    print(f"    - TTS: {'âœ… í™œì„±í™”' if TTS_AVAILABLE else 'âŒ ë¹„í™œì„±í™”'}")
    print(f"    - RAG: {'âœ… í™œì„±í™”' if RAG_AVAILABLE else 'âŒ ë¹„í™œì„±í™”'}")
    print(f"    - ê°ì •ë¶„ì„: {'âœ… í™œì„±í™”' if EMOTION_AVAILABLE else 'âŒ ë¹„í™œì„±í™”'}")
    print(f"    - Redis: {'âœ… í™œì„±í™”' if REDIS_AVAILABLE else 'âŒ ë¹„í™œì„±í™”'}")
    print("=" * 60)
    print("  ğŸŒ http://localhost:8000 ì—ì„œ ì ‘ì†í•˜ì„¸ìš”")
    print("=" * 60 + "\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)
