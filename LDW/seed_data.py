import os
import json
from typing import List, Dict

# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import PGVector
from langchain_core.documents import Document
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# DB ì—°ê²° ì •ë³´ ë° ì»¬ë ‰ì…˜ ì„¤ì •
CONNECTION_STRING = os.getenv("POSTGRES_CONNECTION_STRING", "postgresql+psycopg2://postgres:password@localhost:5432/interview_db")
COLLECTION_NAME = "interview_questions"

def load_json_data(file_path: str) -> List[Dict]:
    """JSON íŒŒì¼ì„ ì½ì–´ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
        
    # ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ ì•ˆì— ë˜ ë¦¬ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°([[...]])ë§Œ í‰íƒ„í™” ìˆ˜í–‰
    if data and isinstance(data, list) and isinstance(data[0], list):
        return [item for sublist in data for item in sublist]
    return data

def seed_database(json_data: List[Dict]):
    """ë°ì´í„°ë¥¼ ë²¡í„°í™”í•˜ì—¬ PostgreSQLì— ì €ì¥í•©ë‹ˆë‹¤."""
    
    print(f"ğŸ”„ ë°ì´í„° ì ì¬ ì‹œì‘... (ì´ {len(json_data)}ê°œ)")
    
    # 2. ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    
    # 3. Document ê°ì²´ë¡œ ë³€í™˜
    documents = []
    for item in json_data:
        # JSON íŒŒì¼ì˜ ì‹¤ì œ í‚¤ì¸ 'question'ê³¼ 'answer'ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
        question = item.get("question", "")
        answer = item.get("answer", "")
        
        if not question or not answer:
            continue

        # ê²€ìƒ‰ íš¨ìœ¨ì„ ìœ„í•´ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê²°í•©í•œ í…ìŠ¤íŠ¸ êµ¬ì„±
        page_content = f"Question: {question}\nAnswer: {answer}"
        
        # ë©”íƒ€ë°ì´í„° êµ¬ì„±
        metadata = {
            "category": "Deep Learning",
            "original_question": question,
            "id": item.get("id")
        }
        
        doc = Document(page_content=page_content, metadata=metadata)
        documents.append(doc)

    if not documents:
        print("âš ï¸ ì ì¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 4. PGVectorë¥¼ í†µí•´ DBì— ì €ì¥
    # pre_delete_collection=TrueëŠ” ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ì €ì¥í•¨ (ì´ˆê¸°í™” ìš©ë„)
    PGVector.from_documents(
        embedding=embeddings,
        documents=documents,
        collection_name=COLLECTION_NAME,
        connection_string=CONNECTION_STRING,
        pre_delete_collection=True 
    )
    
    print("âœ… ë°ì´í„° ì ì¬ ì™„ë£Œ! PostgreSQLì— ë²¡í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    # íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì ˆëŒ€ ê²½ë¡œê°€ ë§ëŠ”ì§€ í™•ì¸ í•„ìš”)
    file_path = r"C:\big20\big20_AI_Interview_simulation\LDW\data\data.json"
    
    if os.path.exists(file_path):
        print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘: {file_path}")
        data_to_seed = load_json_data(file_path)
        seed_database(data_to_seed)
    else:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")