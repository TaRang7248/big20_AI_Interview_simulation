{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b626759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tj\\AppData\\Local\\Temp\\ipykernel_5432\\3603946416.py:20: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  vectorstore = PGVector(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 질문: ai\n",
      "--------------------------------------------------\n",
      "[유사도 점수: 0.2754]\n",
      "내용:\n",
      "Question: AI가 생성한 예술 작품의 가치를 사용자가 신뢰하게 만들기 위해 서비스 기획 단계에서 고려해야 할 '설명 가능한 AI(XAI)' 요소는?\n",
      "Answer: AI가 작품을 추천한 근거를 '색감 유사도', '화풍의 역사적 연관성', '사용자의 과거 선호 패턴' 등 직관적인 키워드로 시각화하여 제시하겠습니다. '이 작품이 추천된 이유' 버튼을 제공하여, AI가 분석한 작품의 특징 벡터를 레이더 차트 등으로 보여줌으로써 알고리즘의 투명성을 높이겠습니다. 또한 추천 근거에 대해 사용자가 '맞아요/아니에요'로 피드백할 수 있는 인터페이스를 두어 모델의 설명력을 지속적으로 개선하겠습니다. 기술적으로는 SHAP이나 LIME 같은 XAI 기법을 적용하여 각 입력 특징이 추천 결과에 기여한 정도를 정량적으로 산출하겠습니다. 이러한 투명성 확보는 사용자 신뢰를 높일 뿐 아니라, 추천 품질에 대한 내부 품질 모니터링 도구로도 활용할 수 있습니다.\n",
      "메타데이터: {'category': 'Deep Learning', 'original_question': \"AI가 생성한 예술 작품의 가치를 사용자가 신뢰하게 만들기 위해 서비스 기획 단계에서 고려해야 할 '설명 가능한 AI(XAI)' 요소는?\", 'id': 3066}\n",
      "--------------------------------------------------\n",
      "[유사도 점수: 0.2521]\n",
      "내용:\n",
      "Question: AI 툴 사용을 어떻게 하면 더 자할 수 있을까요?\n",
      "Answer: AI 툴을 고도로 활용하기 위해서는 생성된 결과를 맹신하기보다 AI를 '지치지 않는 가상 파트너'로 인식하고, 사용자가 해결하려는 문제의 도메인 지식과 기술적 원리를 바탕으로 결과의 진위를 냉철하게 검증하는 '질문과 비판의 역량'이 가장 중요합니다. AI는 방대한 데이터를 기반으로 빠르게 코드를 생성하지만 프로젝트의 특수한 현실 제약이나 보안 가이드라인까지 완벽히 이해하지는 못하므로, 생성된 로직의 복잡도와 성능 트레이드오프를 사용자가 직접 분석하고 튜닝하는 판단이 수반되어야 합니다. 또한 구체적인 페르소나와 제약 조건을 명시한 '프롬프트 엔지니어링'을 통해 AI의 출력 범위를 정교하게 제어하고, 한 번에 모든 것을 요구하기보다 작은 단위로 쪼개어 단계적으로 협업하는 전략적 접근이 효율적입니다. 실무적으로는 반복적인 보일러플레이트 코드 작성이나 단위 테스트 생성에는 AI를 적극 활용하되, 핵심 아키텍처 설계나 데이터 무결성 보장과 같은 고차원적인 의사결정은 인간의 판단력을 중심으로 유지하는 역할 분담이 필요합니다. 끊임없이 진화하는 AI 모델의 특성을 인지하고 최신 툴들의 강점과 한계를 주기적으로 테스트하여 우리 팀의 워크플로우에 최적화된 도구 세트를 구축하는 태도가 요구됩니다. 결국 AI 툴 활용 능력의 본질은 AI가 주는 생산성의 속도 위에 인간의 전문성이 주는 품질의 정확성을 결합하여 최고의 퍼포먼스를 내는 데 있습니다.\n",
      "메타데이터: {'category': 'Deep Learning', 'original_question': 'AI 툴 사용을 어떻게 하면 더 자할 수 있을까요?', 'id': 467}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import PGVector\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# DB 연결 정보 (저장할 때와 동일해야 합니다)\n",
    "CONNECTION_STRING = os.getenv(\"POSTGRES_CONNECTION_STRING\", \"postgresql+psycopg2://postgres:password@localhost:5432/interview_db\")\n",
    "COLLECTION_NAME = \"interview_questions\"\n",
    "\n",
    "def query_interview_data(query_text: str):\n",
    "    \"\"\"사용자 질문에 대해 가장 유사한 답변을 DB에서 찾아옵니다.\"\"\"\n",
    "    \n",
    "    # 2. 임베딩 모델 초기화 (저장할 때 사용한 모델과 동일해야 함)\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    \n",
    "    # 3. 벡터스토어 로드 (이미 생성된 컬렉션에 연결)\n",
    "    vectorstore = PGVector(\n",
    "        connection_string=CONNECTION_STRING,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n🔍 질문: {query_text}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 4. 유사도 검색 실행 (가장 유사한 2개 결과 가져오기)\n",
    "    # k는 가져올 결과의 개수입니다.\n",
    "    results = vectorstore.similarity_search_with_relevance_scores(query_text, k=2)\n",
    "\n",
    "    if not results:\n",
    "        print(\"❌ 검색 결과가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    for doc, score in results:\n",
    "        print(f\"[유사도 점수: {score:.4f}]\")\n",
    "        print(f\"내용:\\n{doc.page_content}\")\n",
    "        print(f\"메타데이터: {doc.metadata}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 테스트하고 싶은 질문을 입력하세요.\n",
    "    # 데이터셋에 있는 \"딥러닝이란 무엇인가요?\"와 유사한 질문을 던져봅니다.\n",
    "    test_query = \"ai\"\n",
    "    \n",
    "    query_interview_data(test_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
