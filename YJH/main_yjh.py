import sys
import os
import uuid
import traceback
import shutil # íŒŒì¼ ì €ì¥ìš©

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))

from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware # <--- ì´ê±° ì¶”ê°€!
from fastapi import Form  # [í•„ìˆ˜] Form ë°ì´í„° ìˆ˜ì‹ ìš©
from pydantic import BaseModel
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI
import json

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
from YJH.agents.interview_graph import app as interview_graph
from YJH.services.voice_service import transcribe_audio
from YJH.services.tts_service import generate_audio
from YJH.database import get_db, SessionLocal
# [ìˆ˜ì •] EvaluationReport ëª¨ë¸ ì¶”ê°€ ì„í¬íŠ¸
from YJH.models import InterviewSession, Transcript, EvaluationReport
# [ìˆ˜ì •] ë¦¬í¬íŠ¸ ìƒì„± ì„œë¹„ìŠ¤ ì¶”ê°€ ì„í¬íŠ¸
from YJH.services.report_service import generate_interview_report
# [ì¶”ê°€] ë¹„ë””ì˜¤ ë©´ì ‘(Video Interview)
from YJH.services.vision_service import analyze_face_emotion
# [ì¶”ê°€] ì—…ë¡œë“œ API ì¶”ê°€ ë° RAG ì—°ë™ ì„í¬íŠ¸
from YJH.services.rag_service import process_resume_pdf, get_relevant_context
from YJH.services.transcript_service import save_transcript # [â˜…ì¶”ê°€] ë°©ê¸ˆ ë§Œë“  ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°

# 1. FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="AI Interview Agent (YJH)",
    description="LangGraph + RAG + DB + Voice + Report (Full Version)",
    version="1.0.0"
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì • (app ìƒì„± ë°”ë¡œ ì•„ë˜ì— ì¶”ê°€)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ì£¼ì†Œ í—ˆìš© (ë³´ì•ˆìƒ ë¡œì»¬ ê°œë°œìš©)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 2. ë°ì´í„° ëª¨ë¸ ì •ì˜
class ChatRequest(BaseModel):
    user_input: str
    thread_id: str = "session_1"

class ChatResponse(BaseModel):
    response: str
    current_phase: str
    question_count: int



# 3. í—¬ìŠ¤ ì²´í¬
@app.get("/")
async def health_check():
    return {"status": "ok", "message": "AI ë©´ì ‘ê´€(Voice+DB+Report) ì¤€ë¹„ ì™„ë£Œ."}

# 4. í…ìŠ¤íŠ¸ ëŒ€í™” ì—”ë“œí¬ì¸íŠ¸
@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """í…ìŠ¤íŠ¸ë¡œ ëŒ€í™”í•˜ê³  DBì— ì €ì¥í•©ë‹ˆë‹¤."""
    db = SessionLocal() # DB ì„¸ì…˜ ì—´ê¸°
    try:
        # [ì €ì¥] ì‚¬ìš©ì ì…ë ¥
        save_transcript(db, request.thread_id, "human", request.user_input)

        # LangGraph ì‹¤í–‰
        config = {"configurable": {"thread_id": request.thread_id}}
        inputs = {"messages": [HumanMessage(content=request.user_input)]}
        
        result = interview_graph.invoke(inputs, config=config)
        last_message = result["messages"][-1]
        
        # [ì €ì¥] AI ì‘ë‹µ
        save_transcript(db, request.thread_id, "ai", last_message.content)

        return ChatResponse(
            response=last_message.content,
            current_phase=result.get("phase", "unknown"),
            question_count=result.get("question_count", 0)
        )
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close() # DB ì„¸ì…˜ ë‹«ê¸°

# 5. ìŒì„± ëŒ€í™” (Audio -> Audio) ì—”ë“œí¬ì¸íŠ¸
@app.post("/chat/voice/audio")
async def chat_voice_audio_endpoint(
    file: UploadFile = File(...), 
    thread_id: str = "voice_session_final_test", # # ê¸°ë³¸ê°’ í†µì¼
    current_emotion: str = Form("neutral") # [ì‹ ê·œ] í”„ë¡ íŠ¸ì—ì„œ ë³´ë‚¸ ê°ì • ë°›ê¸°
):
    """
    [Full Duplex] ìŒì„± íŒŒì¼ ì—…ë¡œë“œ -> STT -> LangGraph -> TTS -> ìŒì„± íŒŒì¼ ë°˜í™˜
    """
    db = SessionLocal()
    try:
        # 1. STT ë³€í™˜ (Deepgram)
        audio_bytes = await file.read()
        user_text = await transcribe_audio(audio_bytes, mimetype=file.content_type)
        print(f"ğŸ¤ User(STT): {user_text}")

        if not user_text.strip():
            raise HTTPException(status_code=400, detail="ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # [ì €ì¥] ì‚¬ìš©ì ì…ë ¥
        save_transcript(db, thread_id, "human", user_text, emotion=current_emotion)

        # ---------------------------------------------------------
        # [RAG í•µì‹¬ ë¡œì§] ì´ë ¥ì„œì—ì„œ ê´€ë ¨ ë‚´ìš© ê²€ìƒ‰
        # ì‚¬ìš©ìì˜ ë°œì–¸(user_text)ê³¼ ê´€ë ¨ëœ ì´ë ¥ì„œ ë‚´ìš©ì„ ì°¾ì•„ì˜µë‹ˆë‹¤.
        # ì˜ˆ: ì‚¬ìš©ìê°€ "í”„ë¡œì íŠ¸ ê²½í—˜ ë§í•´ë³¼ê²Œ" -> í”„ë¡œì íŠ¸ ê´€ë ¨ ì´ë ¥ì„œ ë‚´ìš© ê²€ìƒ‰
        retrieved_context = get_relevant_context(thread_id, user_text)
        
        final_input_text = user_text
        if retrieved_context:
            print(f"ğŸ“š [RAG ê²€ìƒ‰ ì„±ê³µ] ì´ë ¥ì„œ ë‚´ìš© ì°¸ê³ í•¨ (ê¸¸ì´: {len(retrieved_context)})")
            
            # [ìˆ˜ì •] í”„ë¡¬í”„íŠ¸ë¥¼ í›¨ì”¬ ê°•ë ¥í•˜ê²Œ(Strict) ë³€ê²½í•©ë‹ˆë‹¤.
            final_input_text = f"""
            [System Instruction]
            You are a strict technical interviewer evaluating a candidate based on their Resume.
            
            âš ï¸ CRITICAL RULES:
            1. You MUST generate a follow-up question based **ONLY** on the [Resume Context] provided below.
            2. DO NOT ask generic questions or questions about topics not mentioned in the resume (e.g., Do NOT ask about NLP, AI, or Deep Learning unless the resume explicitly lists them).
            3. The candidate is a **Backend Developer** (Java, Python, FastAPI, Redis, AWS). Ask specifically about these technologies.
            4. If the candidate mentioned "Migration from Java to Python", ask about the challenges or trade-offs of that specific experience.

            [Resume Context]
            {retrieved_context}

            [User Emotion]
            The candidate is currently feeling: '{current_emotion}'.
            (If the emotion is 'fear' or 'sad', be a bit more encouraging. If 'happy', keep the momentum.)
            
            [Candidate's Last Response]
            "{user_text}"
            
            Based on the context above, ask a deep technical question related to their project experience.
            """
        else:
            print("âš ï¸ [RAG ê²€ìƒ‰ ì‹¤íŒ¨] ê´€ë ¨ ì´ë ¥ì„œ ë‚´ìš© ì—†ìŒ")
            # ì´ë ¥ì„œ ë‚´ìš©ì´ ì—†ì„ ë•Œë„ ëŒ€ë¹„
            final_input_text = f"""
            User Answer: "{user_text}"
            
            You are a technical interviewer. The user introduced themselves as a Backend Developer.
            Ask a standard backend question about Database, API design, or System Architecture.
            """
        # ---------------------------------------------------------

        # 2. LangGraph ì‹¤í–‰ (ì£¼ì…ëœ í…ìŠ¤íŠ¸ ì „ë‹¬)
        config = {"configurable": {"thread_id": thread_id}}
        inputs = {
            "messages": [HumanMessage(content=final_input_text)] # ìˆ˜ì •ëœ ì…ë ¥ ì‚¬ìš©
        }
        
        result = interview_graph.invoke(inputs, config=config)
        ai_text = result["messages"][-1].content
        print(f"ğŸ¤– AI(Logic): {ai_text}")

        # [ì €ì¥] AI ì‘ë‹µ
        save_transcript(db, thread_id, "ai", ai_text)

        # 3. TTS ë³€í™˜ (OpenAI)
        output_filename = f"response_{uuid.uuid4()}.mp3"
        audio_path = await generate_audio(ai_text, output_file=output_filename)

        # 4. íŒŒì¼ ë°˜í™˜
        return FileResponse(audio_path, media_type="audio/mpeg", filename="ai_response.mp3")

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close()


# 6. [ìˆ˜ì •ë¨] ë©´ì ‘ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„± API (ID íƒ€ì… ì—ëŸ¬ í•´ê²° ë²„ì „)
@app.post("/report/{thread_id}")
async def create_report_endpoint(thread_id: str):
    """
    thread_id(ë¬¸ìì—´)ë¡œ session_id(ìˆ«ì)ë¥¼ ì°¾ì€ ë’¤, ëŒ€í™” ë‚´ìš©ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    print(f"ğŸ“Š [ë¦¬í¬íŠ¸ ìƒì„± ìš”ì²­] Thread ID: {thread_id}")
    
    db = SessionLocal()
    try:
        # 1. [í•µì‹¬ ìˆ˜ì •] ë¬¸ìì—´ ID(thread_id)ë¡œ DBì˜ ìˆ«ì ID(session.id)ë¥¼ ë¨¼ì € ì°¾ìŠµë‹ˆë‹¤.
        session = db.query(InterviewSession).filter(InterviewSession.thread_id == thread_id).first()
        
        if not session:
            print("âš ï¸ í•´ë‹¹ thread_idë¥¼ ê°€ì§„ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {
                "total_score": 0,
                "feedback_summary": "ì €ì¥ëœ ì„¸ì…˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. (ë©´ì ‘ì´ ì‹œì‘ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤)",
                "details": []
            }

        # 2. ì°¾ì€ ìˆ«ì ID (session.id)ë¡œ ëŒ€í™” ë‚´ìš© ì¡°íšŒ
        transcripts = db.query(Transcript).filter(Transcript.session_id == session.id).order_by(Transcript.id).all()
        
        if not transcripts:
            print("âš ï¸ ëŒ€í™” ê¸°ë¡ ì—†ìŒ")
            return {
                "total_score": 0,
                "feedback_summary": "ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.",
                "details": []
            }

        # 3. ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        full_conversation = ""
        for t in transcripts:
            role = "ë©´ì ‘ê´€(AI)" if t.sender == "ai" else "ì§€ì›ì"
            full_conversation += f"[{role}]: {t.content}\n"

        print(f"ğŸ“ ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_conversation)}ì")
        
        if len(full_conversation) < 50:
             return {
                "total_score": 0,
                "feedback_summary": "ë©´ì ‘ ë°ì´í„°ê°€ ë„ˆë¬´ ë¶€ì¡±í•˜ì—¬ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "details": []
            }

        # 4. LLMì—ê²Œ ì±„ì  ìš”ì²­ (GPT-4o)
        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        
        system_prompt = """
        ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ë² í…Œë‘ ê¸°ìˆ  ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
        ì•„ë˜ [ëŒ€í™” ê¸°ë¡]ì„ ë¶„ì„í•˜ì—¬ ë©´ì ‘ ê²°ê³¼ ë¦¬í¬íŠ¸ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
        
        [í•„ìˆ˜ ì¶œë ¥ í˜•ì‹]
        ë°˜ë“œì‹œ ì•„ë˜ JSON êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ë”°ë¥´ì„¸ìš”. (Markdown backticks ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥)
        {
            "total_score": 85,
            "feedback_summary": "ì§€ì›ìëŠ” ... ì ì´ í›Œë¥­í–ˆìœ¼ë‚˜, ... ì— ëŒ€í•œ ì„¤ëª…ì´ ë¶€ì¡±í–ˆìŠµë‹ˆë‹¤. (ì „ë°˜ì ì¸ ì´í‰ì„ 3~4ë¬¸ì¥ìœ¼ë¡œ ì„œìˆ )",
            "details": [
                {"category": "ì§ë¬´ ì—­ëŸ‰(Hard Skill)", "score": 80, "comment": "Redis ìºì‹± ì „ëµì— ëŒ€í•œ ì„¤ëª…ì´ ë…¼ë¦¬ì ì„"},
                {"category": "ì˜ì‚¬ì†Œí†µ(Soft Skill)", "score": 90, "comment": "ì§ˆë¬¸ì˜ ìš”ì§€ë¥¼ ì˜ íŒŒì•…í•˜ê³  ë‘ê´„ì‹ìœ¼ë¡œ ë‹µë³€í•¨"},
                {"category": "ë¬¸ì œ í•´ê²°ë ¥", "score": 85, "comment": "ë§ˆì´ê·¸ë ˆì´ì…˜ ê³¼ì •ì˜ íŠ¸ëŸ¬ë¸” ìŠˆíŒ… ê²½í—˜ì´ êµ¬ì²´ì ì„"}
            ]
        }
        """

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"[ëŒ€í™” ê¸°ë¡]\n{full_conversation}")
        ]

        response = llm.invoke(messages)
        
        # 5. JSON íŒŒì‹± ë° ë°˜í™˜
        content = response.content.replace("```json", "").replace("```", "").strip()
        try:
            report_json = json.loads(content)
            print("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì„±ê³µ!")
            return report_json
        except json.JSONDecodeError:
            print("âŒ LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨")
            return {
                "total_score": 0,
                "feedback_summary": "ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "details": []
            }

    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "total_score": 0,
            "feedback_summary": f"ì„œë²„ ì—ëŸ¬ ë°œìƒ: {str(e)}",
            "details": []
        }
    finally:
        db.close()



# [ì‹ ê·œ] ë¹„ì „(ì–¼êµ´) ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸
@app.post("/analyze/face")
async def analyze_face_endpoint(file: UploadFile = File(...)):
    """
    ë©´ì ‘ìì˜ ìŠ¤ëƒ…ìƒ·(ì´ë¯¸ì§€)ì„ ë°›ì•„ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤. (DeepFace)
    """
    try:
        image_bytes = await file.read()
        result = analyze_face_emotion(image_bytes)
        
        print(f"ğŸ‘ï¸ [Vision ë¶„ì„ ê²°ê³¼]: {result.get('dominant_emotion')}")
        
        return {
            "status": "success", 
            "analysis": result
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}



# [ì‹ ê·œ] ì´ë ¥ì„œ PDF ì—…ë¡œë“œ API
@app.post("/upload/resume")
async def upload_resume(
    file: UploadFile = File(...), 
    thread_id: str = "voice_session_final_test"
):
    """
    PDF ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  RAGìš© ë²¡í„° DBë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        # 1. íŒŒì¼ ì„ì‹œ ì €ì¥
        upload_dir = "uploads"
        os.makedirs(upload_dir, exist_ok=True)
        file_path = os.path.join(upload_dir, f"{thread_id}_{file.filename}")
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
            
        # 2. RAG ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì„ë² ë”©)
        success = process_resume_pdf(thread_id, file_path)
        
        if not success:
            raise HTTPException(status_code=500, detail="ì´ë ¥ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            
        return {"status": "success", "message": "ì´ë ¥ì„œ ë¶„ì„ ì™„ë£Œ! ì´ì œ ë§ì¶¤í˜• ì§ˆë¬¸ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."}

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))