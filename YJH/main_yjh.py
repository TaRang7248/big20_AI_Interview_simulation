# YJH ê°œì¸ ì‘ì—…ìš© FastAPI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ (ì„ì‹œ)


import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆ import ì—ëŸ¬ ë°©ì§€
sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain_core.messages import HumanMessage
from YJH.agents.interview_graph import app as interview_graph
from fastapi import UploadFile, File
from YJH.services.voice_service import transcribe_audio
from fastapi.responses import FileResponse
from YJH.services.tts_service import generate_audio
import uuid


# 1. FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="AI Interview Agent (YJH)",
    description="LangGraphì™€ RAGê°€ ì ìš©ëœ ëª¨ì˜ë©´ì ‘ ì—ì´ì „íŠ¸ API",
    version="1.0.0"
)

# 2. ìš”ì²­/ì‘ë‹µ ë°ì´í„° ëª¨ë¸ ì •ì˜ (Pydantic)
class ChatRequest(BaseModel):
    user_input: str
    thread_id: str = "session_1"  # ëŒ€í™” ë§¥ë½ ìœ ì§€ë¥¼ ìœ„í•œ ì„¸ì…˜ ID

class ChatResponse(BaseModel):
    response: str
    current_phase: str
    question_count: int

# 3. í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def health_check():
    return {"status": "ok", "message": "AI ë©´ì ‘ê´€ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤."}

# 4. ë©´ì ‘ ëŒ€í™” ì—”ë“œí¬ì¸íŠ¸ (í•µì‹¬)
@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """
    ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°›ì•„ ì—ì´ì „íŠ¸(LangGraph)ë¥¼ ì‹¤í–‰í•˜ê³ ,
    ë‹¤ìŒ ì§ˆë¬¸ì´ë‚˜ ë°˜ì‘ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # LangGraphì— ì „ë‹¬í•  ì´ˆê¸° ìƒíƒœ êµ¬ì„±
        # thread_idë¥¼ í†µí•´ ì´ì „ ëŒ€í™” ê¸°ì–µ(Memory)ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        config = {"configurable": {"thread_id": request.thread_id}}
        
        # ê·¸ë˜í”„ ì‹¤í–‰ (invoke)
        # messages í‚¤ì— ì‚¬ìš©ìì˜ ì…ë ¥ì„ HumanMessageë¡œ í¬ì¥í•´ì„œ ë„£ìŠµë‹ˆë‹¤.
        # ì£¼ì˜: interview_graph.pyì˜ State ì •ì˜ì— ë”°ë¼ í•„ìš”í•œ ì´ˆê¸°ê°’ì„ ë„£ì–´ì¤ë‹ˆë‹¤.
        inputs = {
            "messages": [HumanMessage(content=request.user_input)],
            # phaseë‚˜ question_countëŠ” ê·¸ë˜í”„ ë‚´ë¶€ ë©”ëª¨ë¦¬ì— ìˆë‹¤ë©´ ìƒëµ ê°€ëŠ¥í•˜ì§€ë§Œ,
            # ì²« ì‹œì‘ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ê¸°ë³¸ê°’ì„ ì„¤ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
            "phase": "technical_interview", 
            "question_count": 0
        }

        # ê·¸ë˜í”„ ì‹¤í–‰!
        # stream=Falseë¡œ í•˜ì—¬ ê²°ê³¼ë¥¼ í•œ ë²ˆì— ë°›ìŠµë‹ˆë‹¤. (ì‹¤ì œ ì„œë¹„ìŠ¤ëŠ” stream ê¶Œì¥)
        result = interview_graph.invoke(inputs, config=config)
        
        # ê²°ê³¼ íŒŒì‹±
        # LangGraphì˜ ê²°ê³¼ì¸ result['messages']ì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ AIì˜ ì‘ë‹µì…ë‹ˆë‹¤.
        last_message = result["messages"][-1]
        
        return ChatResponse(
            response=last_message.content,
            current_phase=result.get("phase", "unknown"),
            question_count=result.get("question_count", 0)
        )

    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ìƒì„¸ ë¡œê·¸ ì¶œë ¥ (ê°œë°œìš©)
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    # ë¡œì»¬ ê°œë°œìš© ì„œë²„ ì‹¤í–‰
    uvicorn.run("YJH.main_yjh:app", host="0.0.0.0", port=8000, reload=True)



# [ì‹ ê·œ ì¶”ê°€ 26.02.02] ìŒì„± ëŒ€í™” ì—”ë“œí¬ì¸íŠ¸
@app.post("/chat/voice", response_model=ChatResponse)
async def chat_voice_endpoint(
    file: UploadFile = File(...), 
    thread_id: str = "voice_session_1"
):
    """
    ì‚¬ìš©ìì˜ ìŒì„± íŒŒì¼(.wav, .m4a, .mp3, .webm ë“±)ì„ ë°›ì•„
    STT -> LangGraph(Agent) -> í…ìŠ¤íŠ¸ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # 1. ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸°
        audio_bytes = await file.read()
        
        # 2. STT ë³€í™˜ (Deepgram)
        # íŒŒì¼ì˜ content_type(ì˜ˆ: audio/mpeg)ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
        user_text = await transcribe_audio(audio_bytes, mimetype=file.content_type)
        
        if not user_text.strip():
            return ChatResponse(
                response="ìŒì„±ì´ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?",
                current_phase="error",
                question_count=0
            )

        print(f"ğŸ¤ [STT ì¸ì‹ ê²°ê³¼]: {user_text}") # ë¡œê·¸ í™•ì¸ìš©

        # 3. LangGraph ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)
        config = {"configurable": {"thread_id": thread_id}}
        inputs = {
            "messages": [HumanMessage(content=user_text)],
            "phase": "technical_interview",
            "question_count": 0 # ì‹¤ì œë¡œëŠ” DBì—ì„œ ë¶ˆëŸ¬ì™€ì•¼ í•¨
        }
        
        result = interview_graph.invoke(inputs, config=config)
        last_message = result["messages"][-1]
        
        return ChatResponse(
            response=last_message.content,
            current_phase=result.get("phase", "unknown"),
            question_count=result.get("question_count", 0)
        )

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))



# [ì‹ ê·œ ì¶”ê°€ 26.02.02] ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ìì²´ë¥¼ ë°˜í™˜
@app.post("/chat/voice/audio") # ê¸°ì¡´ /chat/voice ì™€ êµ¬ë¶„í•˜ê¸° ìœ„í•´ ê²½ë¡œ ë³€ê²½ ê°€ëŠ¥
async def chat_voice_audio_endpoint(
    file: UploadFile = File(...), 
    thread_id: str = "voice_session_1"
):
    """
    [NEW] ìŒì„± -> STT -> LLM -> TTS -> ìŒì„± íŒŒì¼ ë°˜í™˜ (Full Duplex)
    """
    try:
        # 1. STT ë³€í™˜
        audio_bytes = await file.read()
        user_text = await transcribe_audio(audio_bytes, mimetype=file.content_type)
        print(f"ğŸ¤ User: {user_text}")

        if not user_text.strip():
            raise HTTPException(status_code=400, detail="ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # 2. LangGraph ì¶”ë¡ 
        config = {"configurable": {"thread_id": thread_id}}
        inputs = {
            "messages": [HumanMessage(content=user_text)],
            # ê³„ì† ë™ì¼í•œ ìê¸°ì†Œê°œ ì§ˆë¬¸ì´ ë°˜ë³µë˜ì–´ ì£¼ì„ì²˜ë¦¬
            # "phase": "intro", # ìˆ˜ì •, intro ìì—°ìŠ¤ëŸ¬ìš´ ë¼í¬(26.02.02) [ì••ë°• ë©´ì ‘ ëª¨ë“œ, ì½”ë”© í…ŒìŠ¤íŠ¸ ëª¨ë“œ, í”¼ë“œë°± ëª¨ë“œ] ì—ì´ì „íŠ¸ ì¸ê²© êµì²´ ê°€ëŠ¥
            # "question_count": 0 
        }
        
        result = interview_graph.invoke(inputs, config=config)
        ai_text = result["messages"][-1].content
        print(f"ğŸ¤– AI: {ai_text}")

        # 3. TTS ë³€í™˜ (í…ìŠ¤íŠ¸ -> ì˜¤ë””ì˜¤)
        # íŒŒì¼ëª…ì´ ê²¹ì¹˜ì§€ ì•Šê²Œ UUID ì‚¬ìš©
        output_filename = f"response_{uuid.uuid4()}.mp3"
        audio_path = await generate_audio(ai_text, output_file=output_filename)

        # 4. ì˜¤ë””ì˜¤ íŒŒì¼ ë°˜í™˜ (ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ ì¬ìƒ ê°€ëŠ¥)
        return FileResponse(audio_path, media_type="audio/mpeg", filename="ai_response.mp3")

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))