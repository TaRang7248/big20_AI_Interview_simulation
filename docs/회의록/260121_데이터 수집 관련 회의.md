# 26.01.21(수) 데이터 수집 관련 회의

---
## 데이터 수집 방법 / 자료구조
- 어떻게 가공 할건지
- 어떤 데이터가 있는지 (Dictionary 형태)
- 컬럼 4개 형태 구성

    1. 기업명
    2. 인재상(회사 추구 방향)
    3. 기업ID
    4. 기업정보(산업)

## 데이터 추출
* JSON 형식 (JSON 안에 JSON)
    * 기업 ID를 PK 로 구성

* 기업 선별 기준 → (50개)
    * 코스닥 상장 기업 (TOP100)
    * 직무랑 상관없이 뽑아도 될듯?
    * 인재상 구체적으로 제시된 기업

## 루브릭
* 스코어(Score) 컬럼 형태 저장
    * 모든 질문 / 답변 + 음성 / 영상

* 질문 Table / 대답 Table + 스코어 테이블

## 질문생성
* ‘DB 참고해서 질문 생성하라’ (LLM 프롬프트)
* 초기질문만 중복회피 → 이후는 LLM에게 맡기는 방식으로

* (예시) 질문 1개 ⇒ 모범답안 1개 ⇒ COS유사도 방식 ⇒ 관계(각도) * 로만 따짐
* 기업 정보 뽑아서 직무별 질문 100개 만들어줘 (수집, 현실적 데이터 필요)
    * 예시제시 후 LLM 에게 맡겨 생성


## 질문 데이터 수집
* 직무랑 연결되는 테이블 → 질문 Table(전부 담겨있게) → 질문 Table + 대답 Table 묶어서

    1. 기본 질문 (300개)
    2. 산업별 질문 (300개)
    3. 기업별 질문 (300개)

* 공통적인 프롬프트 제시
* DB에 데이터 Dataframe(Pandas) / JSON 방식으로 
* 한 팀 4명 구성해서 위 각 질문 수집

* 재민님 수집 데이터 표본(foramt) 제시


## 질문 인재상
* 면접 하고나서 맨 마지막에 루브릭 넣어서 VectorDB 에 들어있는 인재상이 맞는지
    * 루브릭 필요
    * 데이터 수집할때, 수집 항목별로 어디에 사용될지 필요
    * vector DB, R DB( 데이터 모으고나서 활용하는 방법도 고려 )

---
## 데이터 수집 전략 개요
AI 모의면접 시스템은 질문 생성, 답변 평가, 피드백 제공(언어·비언어)까지 다루므로 텍스트·오디오·비디오·메타데이터를 균형 있게 수집해야 합니다. 최근 연구들은 자기소개서 기반 질문 생성, LLM을 활용한 도메인별 면접 시나리오, 시선·표정·음성 톤 등 비언어 신호 분석을 결합해 실제 면접에 가까운 경험을 제공하는 방향으로 설계됩니다.

## 핵심 데이터 타입과 우선순위
데이터 타입
용도
예시 소스
라벨링 포인트
텍스트(질문·답변·자기소개서)
질문 생성·답변 평가
공개 면접 질문, 기업 직무 JD, 합격자 에세이
난이도, 주제, 의도, 답변 품질(점수·코멘트)
오디오(음성)
발화 속도·억양·명료성
실사용자 녹음, 공개 스피치 코퍼스
발화 품질, 감정, 말더듬/충돌
비디오(표정·시선·제스처)
비언어 피드백
자발적 촬영 데이터
시선 유지, 표정 안정성, 자세·손 제스처
메타데이터(직무·경력·상황)
개인화·컨텍스트
설문·프로필 입력
직무/레벨, 면접 유형, 시간 제한


## 데이터 소스 설계
* 공개 질문·시나리오:
- 직무별(개발, 마케팅, 영업 등)·역량별(문제해결, 커뮤니케이션) 질문을 크롤링/정리하고, JD에서 요구 역량을 추출해 질문 템플릿을 생성합니다. LLM 기반 시스템은 도메인별 시나리오와 난이도 조절로 학습·평가에 유리합니다.


* 자기소개서·이력서 텍스트:
- 사용자로부터 수집해 키워드·경험·성과를 구조화하고, 연관 질문을 자동 생성하는 파이프라인을 만듭니다. 실제 연구에서도 자기소개서 분석을 통해 맞춤 질문을 생성하는 접근이 효과적입니다.


* 실사용 세션 로그:
- 모의면접 세션에서 질문→답변(텍스트/음성)→피드백→재시도 흐름을 전부 저장합니다. 비언어 신호(시선·표정·음성 톤)까지 수집·분석해 피드백에 반영하는 설계가 권장됩니다.


* 전문가 평가 데이터:
- HR/현업 면접관이 답변을 채점(예: 구조화, 명확성, 근거, 임팩트)하고 코멘트를 남기는 골드 라벨 세트를 구축합니다. LLM 기반 시스템 연구에서도 도메인 전문가의 설계·검증이 성능 안정화에 기여합니다.

---

## 수집·라벨링 파이프라인
1. 스키마 정의:
 질문: 주제, 의도, 난이도, 직무/역량 태그
 답변: 원문, 길이, 구조화 여부(S.T.A.R.), 사실성, 관련성, 임팩트
 비언어: 시선 비율, 표정 안정성, 말속도/피치, 중간 침묵
 피드백: 점수(1–5), 구체 코멘트, 개선 포인트, 재시도 결과


2. 반자동 라벨링:
 초안 라벨은 규칙/모델로 생성하고, 인간 검수로 품질을 보정합니다. 특히 비언어 라벨은 모델 추출치(예: 시선 유지 %)와 인간 판단(면접 적합성)을 함께 저장해 학습에 활용합니다.


3. 데이터 증강:
 텍스트: 질문 패러프레이즈, 시나리오 변형(난이도·컨텍스트)
 오디오: 속도·피치 변조, 잡음 추가(현실성)
 비디오: 조명·각도·배경 다양화
 증강은 모델의 견고성을 높이되, 라벨 일관성 검증을 포함합니다.


4. 품질 게이트:
**중복 제거, 개인정보 비식별화, 라벨 일치성 검사, 분포 균형(직무/난이도/언어 길이)**를 자동화합니다.

---

## 윤리·프라이버시·동의
* 명시적 동의 & 목적 고지:
 녹음·촬영·분석 범위(표정·시선·음성 톤 포함), 저장 기간, 삭제 요청 절차를 투명하게 고지합니다. 비언어 데이터까지 수집·분석하는 시스템 설계가 보고되는 만큼, 동의 문구에 구체 항목을 포함해야 합니다.


* 비식별화 & 최소 수집:
 이름·연락처·얼굴 원본 등 직접 식별자는 분리 저장/암호화하고, 학습에는 임베딩·특징량 중심으로 사용합니다.


* 편향 관리:
 직무·성별·연령·언어 스타일 편향을 점검하고, 평가 기준을 역량 중심으로 표준화합니다.


---


## 규모 확장 로드맵
* Phase 1—파일럿(100–500 세션):
 한 직무(예: CS 면접)로 범위를 좁혀 질문·평가 기준을 정교화합니다.


* Phase 2—다직무(5–10 직무):
 도메인별 질문 뱅크와 시나리오 템플릿을 확장하고, 비언어 피드백 모델을 공통 프레임으로 재학습합니다.


* Phase 3—개인화:
 자기소개서 기반 질문 생성·난이도 조절·실시간 피드백을 통합하고, 사용자별 학습 곡선(재시도 개선도)을 모델에 반영합니다.

---

## 저장 구조(예시)
* 세션: 사용자ID, 직무, 시나리오ID, 시간, 장치/환경
* 질문: 텍스트, 의도, 난이도, 태그(직무/역량)
* 답변: 텍스트/오디오/비디오 경로, 길이, 키포인트, 사실 검증 상태
* 비언어 특징: 시선 %, 표정 안정성 점수, 말속도/피치, 중간 침묵
* 평가: 점수(다차원), 코멘트, 개선 포인트, 재시도 결과
* 동의/프라이버시: 동의 버전, 비식별화 상태, 삭제 토큰

## 실전 팁
* 짧고 빈번한 세션 설계: 사용자가 자주 돌아오게 만들고, 재시도 데이터로 학습 곡선을 확보합니다.
* 피드백의 구체성: “구조화 부족”이 아니라 “S.T.A.R.의 Result가 수치·영향으로 약함”처럼 행동 가능한 문장으로 저장합니다.
* 오프라인 태깅 스프린트: 2–3명의 HR/현업이 일괄 채점해 골드셋을 만들고, 모델 튜닝의 기준점으로 사용합니다.
* 도메인별 템플릿: CS·마케팅·영업 등 직무별 질문 의도/평가 기준을 별도 템플릿으로 관리하면 확장성이 좋아집니다.

## 다음 단계 제안
* 목표 범위: 어떤 직무/면접 유형부터 시작할지, 비언어 분석을 1차에 포함할지 정하면 설계가 선명해져요.
* 샘플 확보: 초기 100–200 세션을 서울 지역 대학/부트캠프와 파일럿 협약으로 모으는 방법이 현실적입니다.
* 원하시면: 직무별 질문 뱅크 스키마와 라벨링 기준표를 함께 설계해 드릴게요—어떤 직무부터 시작할까요?
