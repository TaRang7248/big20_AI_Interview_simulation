# TASK-008 Plan: Emotion 분석 (DeepFace, 1fps)

## 1. 개요 및 목적 (Background)
본 작업은 **Playground(실험실)** 환경에서 DeepFace 모델을 활용한 **영상/이미지 기반 감정 분석 파이프라인**을 검증하는 것을 목적으로 한다.
현재 시스템은 **Phase 2 (API 최소 골격 / Playground 검증)** 단계에 있으며, 실제 면접 세션(실시간 스트리밍)에 적용하기 앞서 **"파일 업로드 → 프레임 추출 → DeepFace 추론 → 결과 표준화"** 로 이어지는 분석 코어의 동작과 성능을 검토해야 한다.

- **핵심 목표**: CPU 환경에서 구동 가능한 **1fps(초당 1프레임)** 단위의 저주기 감정 분석 프로세스 정립
- **도입 이유**: 면접자의 비언어적 태도(표정, 긴장도 등)를 정량 평가하기 위한 기반 데이터 확보

## 2. 범위 정의 (Scope)

### 2.1 이번 TASK에서 고려하는 것 (In-Scope)
- **DeepFace 기반 분석 로직 설계**: Provider 패턴에 맞춘 분석 로직 설계
- **프레임 추출 전략 수립**: 비디오 파일에서 **1초 단위(1fps)** 로 이미지를 샘플링하는 방식 검토
- **Playground API 명세 정의**: 파일 업로드 및 분석 요청을 처리할 엔드포인트 설계
- **입출력 데이터 구조(DTO) 설계**: 감정 분석 결과의 표준 JSON 포맷 정의
- **예외 처리 정책 수립**: 얼굴 미검출, 다중 얼굴 검출 등 예외 상황에 대한 처리 방안

### 2.2 이번 TASK에서 고려하지 않는 것 (Out-of-Scope)
- **실시간 웹캠 분석**: WebRTC 스트림 처리는 고려 대상이 아니며, 파일 처리만 대상으로 함
- **DB 저장**: 분석 결과에 대한 영구 저장은 고려하지 않음 (응답 반환 후 종료)
- **초고속/GPU 최적화**: CPU 기준 1fps 처리를 목표로 하며, 고성능 최적화는 추후 단계에서 고려
- **복합 추론**: 음성(Voice)이나 텍스트(STT)와 결합한 멀티모달 분석은 포함하지 않음

## 3. 입력 / 출력 개념 정의 (Input / Output)

### 3.1 입력 (Input)
- **소스**: 로컬 파일 업로드 (Multipart 방식)
- **포맷**: 일반적인 비디오 파일 (또는 이미지 파일)
- **제약**:
  - 용량 제한 검토 (예: 50MB 이내)
  - 길이 제한 검토 (예: 1분 이내, Playground 테스트 용도)

### 3.2 출력 (Output)
- **형태**: JSON 포맷의 시계열 리스트 (DTO 정의 필요)
- **구조 예시 (개념)**:
  ```json
  {
    "metadata": {
      "total_duration": 15.0,
      "total_frames_analyzed": 15,
      "model": "DeepFace/CPU"
    },
    "results": [
      {
        "timestamp": 0.0,
        "face_detected": true,
        "dominant_emotion": "neutral",
        "emotion_scores": { "neutral": 80.5, "fear": 2.1, "happy": 15.2, ... },
        "box": [x, y, w, h]
      },
      {
        "timestamp": 1.0,
        "face_detected": false,
        "dominant_emotion": null
      },
      ...
    ]
  }
  ```

## 4. 처리 흐름 (Processing Flow)

1.  **파일 수신**: 업로드된 파일을 임시 저장소에 저장하는 흐름 검토
2.  **메타데이터 확인**: 영상 길이, 해상도 등 선행 확인
3.  **프레임 샘플링 (1fps)**:
    - 영상 처리 라이브러리를 활용하여 **1초 간격**으로 프레임을 캡처하는 방식
    - 전체 프레임을 모두 분석하지 않고 샘플링된 프레임만 분석 고려
4.  **얼굴 검출 및 분석 (DeepFace)**:
    - 샘플링된 프레임에 대해 DeepFace 분석 기능 호출
    - 얼굴이 있는 경우: 감정 확률 분포 추출
    - 얼굴이 없는 경우: `face_detected: false` 마킹
5.  **결과 집계 및 반환**: 분석된 데이터를 시계열 리스트로 변환하여 API 응답으로 구성
6.  **정리**: 임시 파일 삭제 및 리소스 정리

## 5. 성능 및 운영 고려사항

- **1fps 선택 이유**:
  - DeepFace(특히 기본 백엔드)의 높은 CPU 연산 비용을 고려
  - 실시간 면접 평가에서 초 단위의 전반적인 태도가 더 중요하다는 가정
  - 시스템 부하와 데이터 유의미성 간의 균형점 모색
- **지연 리스크 (Latency)**:
  - 영상 길이에 비례하는 처리 시간 예상 (비동기 처리 또는 타임아웃 설정 검토 필요)
- **자원 사용**:
  - 분석 중 CPU 점유율 관리 방안 (동시 요청 수 제한 등) 검토 필요

## 6. 실패 / 예외 상황 정의

1.  **얼굴 미검출 (No Face Detected)**:
    - 에러가 아닌 정상 흐름으로 간주. 분석 결과에 미검출 상태 명시.
    - 전체 영상에서 얼굴이 한 번도 안 나오는 경우에 대한 처리 방안 검토 (경고 메시지와 함께 빈 결과 반환 등)
2.  **다중 얼굴 검출 (Multiple Faces)**:
    - 면접 특성상 **"주요 인물(가장 큰 얼굴)"** 만 분석 대상으로 삼는 정책 고려.
3.  **파일 손상 / 코덱 호환 불가**:
    - 적절한 클라이언트 에러(4xx) 응답 검토
4.  **DeepFace 로딩 실패 / 메모리 부족**:
    - 서버 내부 오류(500) 처리 및 로그 기록 방안 검토

## 7. 검증 전략 (Verification)

### 7.1 Playground 검증 시나리오
- **테스트 케이스**:
  1.  **정상 영상 (10초)**: 정상적으로 약 10개의 결과 항목이 산출되는지 확인
  2.  **얼굴 없는 영상**: 에러 없이 `face_detected: false` 리스트가 생성되는지 확인
  3.  **이미지 파일**: 단일 프레임(0.0초) 결과가 생성되는지 확인
- **성공 기준**:
  - 검증 스크립트 실행 시 업로드 → 분석 → JSON 구조 검증이 통과되어야 함.
  - DeepFace 라이브러리가 정의된 환경 내에서 정상 구동되어야 함.

## 8. 로깅 및 추적 포인트

- **Agent 로그**:
  - 모델 가중치 로드 상태 확인
  - 프레임 추출 중 발생하는 라이브러리 경고/에러 기록
- **Runtime 로그**:
  - 요청별 처리 소요 시간 및 분석된 총 프레임 수
  - 예외 발생 시 스택 트레이스 (라이브러리 내부 오류 등) 기록

## 9. 승인 이후 예상 산출물 (Conceptual)

구현 단계(Phase 2 - Execution)에서 다음과 같은 파일들이 생성/수정될 것으로 예상됨 (현재는 계획만 수립):

1.  `packages/imh_providers/emotion/`
    - `interface.py` (기존 TASK-003에서 정의됨, 필요 시 보완)
    - `deepface_impl.py` (DeepFace 래퍼 구현체 예상)
    - `dto.py` (감정 분석 결과 DTO 예상)
2.  `IMH/routers/playground.py`
    - 파일 업로드 및 분석 요청 처리를 위한 엔드포인트 추가 예상
3.  `scripts/verify_task_008.py`
    - 검증용 스크립트 작성 예상
