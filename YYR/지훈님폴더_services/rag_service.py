# "ì´ë ¥ì„œ ì²˜ë¦¬ ì—”ì§„"
# ì´ë ¥ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³ , ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì €ì¥

import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

# [ë©”ëª¨ë¦¬ ì €ì¥ì†Œ] ì„¸ì…˜ë³„ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì„ì‹œ ì €ì¥ (ì‹¤ë¬´ì—ì„  Redisë‚˜ íŒŒì¼ ì €ì¥ ê¶Œì¥)
# êµ¬ì¡°: { "session_id": vectorstore_object }
vector_store_memory = {}

def process_resume_pdf(thread_id: str, file_path: str):
    """
    PDF ì´ë ¥ì„œë¥¼ ì½ì–´ì„œ ì²­í¬ë¡œ ë‚˜ëˆ„ê³ , ë²¡í„° DB(FAISS)ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    try:
        # 1. PDF ë¡œë“œ
        loader = PyPDFLoader(file_path)
        documents = loader.load()
        
        # 2. í…ìŠ¤íŠ¸ ë¶„í•  (ì²­í¬ ë‹¨ìœ„ë¡œ ìª¼ê°œê¸°)
        # ì´ë ¥ì„œëŠ” êµ¬ì¡°ê°€ ì¤‘ìš”í•˜ë¯€ë¡œ ì²­í¬ ì‚¬ì´ì¦ˆë¥¼ ì ì ˆíˆ ì¡°ì ˆ
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", " ", ""]
        )
        splits = text_splitter.split_documents(documents)
        
        # 3. ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„± (FAISS)
        embeddings = OpenAIEmbeddings()
        vectorstore = FAISS.from_documents(splits, embeddings)
        
        # 4. ë©”ëª¨ë¦¬ì— ì €ì¥ (ì„¸ì…˜ ID í‚¤ê°’)
        vector_store_memory[thread_id] = vectorstore
        
        print(f"ğŸ“„ [RAG] ì´ë ¥ì„œ ì²˜ë¦¬ ì™„ë£Œ: {len(splits)}ê°œ ì²­í¬ ìƒì„± (Session: {thread_id})")
        return True

    except Exception as e:
        print(f"âŒ [RAG Error] ì´ë ¥ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return False

def get_relevant_context(thread_id: str, query: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ í˜„ì¬ ëŒ€í™” ì£¼ì œì™€ ê´€ë ¨ëœ ì´ë ¥ì„œ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    if thread_id not in vector_store_memory:
        return "" # ë“±ë¡ëœ ì´ë ¥ì„œ ì—†ìŒ
    
    try:
        vectorstore = vector_store_memory[thread_id]
        # ìœ ì‚¬ë„ ê²€ìƒ‰ (ìƒìœ„ 3ê°œ ì²­í¬ ì¶”ì¶œ)
        results = vectorstore.similarity_search(query, k=3)
        
        # ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
        context_text = "\n\n".join([doc.page_content for doc in results])
        return context_text
        
    except Exception as e:
        print(f"âŒ [Retrieval Error]: {e}")
        return ""